{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from past.builtins import basestring\n",
    "from builtins import zip\n",
    "from builtins import map\n",
    "from builtins import str\n",
    "from builtins import range\n",
    "from past.utils import old_div\n",
    "import collections\n",
    "import cv2\n",
    "import gc\n",
    "import h5py\n",
    "import itertools\n",
    "import logging\n",
    "import numpy as np\n",
    "from numpy.fft import ifftshift\n",
    "import os\n",
    "import pylab as pl\n",
    "import tifffile\n",
    "from typing import List, Optional, Tuple\n",
    "from skimage.transform import resize as resize_sk\n",
    "from skimage.transform import warp as warp_sk\n",
    "\n",
    "from builtins import str\n",
    "from builtins import range\n",
    "from past.utils import old_div\n",
    "\n",
    "import cv2\n",
    "from functools import partial\n",
    "import h5py\n",
    "import logging\n",
    "from matplotlib import animation\n",
    "import numpy as np\n",
    "import os\n",
    "from PIL import Image  # $ pip install pillow\n",
    "import pylab as pl\n",
    "import scipy.ndimage\n",
    "import scipy\n",
    "from scipy.io import loadmat\n",
    "from skimage.transform import warp, AffineTransform\n",
    "from skimage.feature import match_template\n",
    "import sklearn\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import NMF, IncrementalPCA, FastICA\n",
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "import sys\n",
    "import tifffile\n",
    "from tqdm import tqdm\n",
    "from typing import Any, Dict, List, Tuple, Union\n",
    "import warnings\n",
    "from zipfile import ZipFile\n",
    "\n",
    "try:\n",
    "    cv2.setNumThreads(0)\n",
    "except:\n",
    "    pass\n",
    "\n",
    "from cv2 import dft as fftn\n",
    "from cv2 import idft as ifftn\n",
    "opencv = True\n",
    "\n",
    "try:\n",
    "    import pycuda.gpuarray as gpuarray\n",
    "    import pycuda.driver as cudadrv\n",
    "    import atexit\n",
    "    HAS_CUDA = True\n",
    "except ImportError:\n",
    "    HAS_CUDA = False\n",
    "\n",
    "try:\n",
    "    profile\n",
    "except:\n",
    "    def profile(a): return a\n",
    "\n",
    "    from builtins import str\n",
    "from builtins import range\n",
    "from past.utils import old_div\n",
    "\n",
    "import cv2\n",
    "import h5py\n",
    "import logging\n",
    "import numpy as np\n",
    "import os\n",
    "import pathlib\n",
    "import pylab as pl\n",
    "import scipy\n",
    "from scipy.sparse import spdiags, issparse, csc_matrix, csr_matrix\n",
    "import scipy.ndimage.morphology as morph\n",
    "from skimage.feature.peak import _get_high_intensity_peaks\n",
    "import tifffile\n",
    "from typing import List\n",
    "\n",
    "from builtins import str\n",
    "from builtins import range\n",
    "from past.utils import old_div\n",
    "\n",
    "import cv2\n",
    "import h5py\n",
    "import logging\n",
    "import numpy as np\n",
    "import os\n",
    "import pathlib\n",
    "import pylab as pl\n",
    "import scipy\n",
    "from scipy.sparse import spdiags, issparse, csc_matrix, csr_matrix\n",
    "import scipy.ndimage.morphology as morph\n",
    "from skimage.feature.peak import _get_high_intensity_peaks\n",
    "import tifffile\n",
    "from typing import List\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "The functions apply_shifts_dft, register_translation, _compute_error, _compute_phasediff, and _upsampled_dft are from\n",
    "SIMA (https://github.com/losonczylab/sima), licensed under the  GNU GENERAL PUBLIC LICENSE, Version 2, 1991.\n",
    "These same functions were adapted from sckikit-image, licensed as follows:\n",
    "\n",
    "Copyright (C) 2011, the scikit-image team\n",
    " All rights reserved.\n",
    "\n",
    " Redistribution and use in source and binary forms, with or without\n",
    " modification, are permitted provided that the following conditions are\n",
    " met:\n",
    "\n",
    "  1. Redistributions of source code must retain the above copyright\n",
    "     notice, this list of conditions and the following disclaimer.\n",
    "  2. Redistributions in binary form must reproduce the above copyright\n",
    "     notice, this list of conditions and the following disclaimer in\n",
    "     the documentation and/or other materials provided with the\n",
    "     distribution.\n",
    "  3. Neither the name of skimage nor the names of its contributors may be\n",
    "     used to endorse or promote products derived from this software without\n",
    "     specific prior written permission.\n",
    "\n",
    " THIS SOFTWARE IS PROVIDED BY THE AUTHOR ``AS IS'' AND ANY EXPRESS OR\n",
    " IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED\n",
    " WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE\n",
    " DISCLAIMED. IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR ANY DIRECT,\n",
    " INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES\n",
    " (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR\n",
    " SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION)\n",
    " HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT,\n",
    " STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING\n",
    " IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE\n",
    " POSSIBILITY OF SUCH DAMAGE.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "from past.builtins import basestring\n",
    "from builtins import zip\n",
    "from builtins import map\n",
    "from builtins import str\n",
    "from builtins import range\n",
    "from past.utils import old_div\n",
    "import collections\n",
    "import cv2\n",
    "import gc\n",
    "import h5py\n",
    "import itertools\n",
    "import logging\n",
    "import numpy as np\n",
    "from numpy.fft import ifftshift\n",
    "import os\n",
    "import pylab as pl\n",
    "import tifffile\n",
    "from typing import List, Optional, Tuple\n",
    "from skimage.transform import resize as resize_sk\n",
    "from skimage.transform import warp as warp_sk\n",
    "\n",
    "\n",
    "\n",
    "class MotionCorrect(object):\n",
    "    \"\"\"\n",
    "        class implementing motion correction operations\n",
    "       \"\"\"\n",
    "\n",
    "    def __init__(self, fname, min_mov=None, dview=None, max_shifts=(6, 6), niter_rig=1, splits_rig=14, num_splits_to_process_rig=None,\n",
    "                 strides=(96, 96), overlaps=(32, 32), splits_els=14, num_splits_to_process_els=None,\n",
    "                 upsample_factor_grid=4, max_deviation_rigid=3, shifts_opencv=True, nonneg_movie=True, gSig_filt=None,\n",
    "                 use_cuda=False, border_nan=True, pw_rigid=False, num_frames_split=80, var_name_hdf5='mov',is3D=False,\n",
    "                 indices=(slice(None), slice(None))):\n",
    "        \"\"\"\n",
    "        Constructor class for motion correction operations\n",
    "\n",
    "        Args:\n",
    "           fname: str\n",
    "               path to file to motion correct\n",
    "\n",
    "           min_mov: int16 or float32\n",
    "               estimated minimum value of the movie to produce an output that is positive\n",
    "\n",
    "           dview: ipyparallel view object list\n",
    "               to perform parallel computing, if NOne will operate in single thread\n",
    "\n",
    "           max_shifts: tuple\n",
    "               maximum allow rigid shift\n",
    "\n",
    "           niter_rig':int\n",
    "               maximum number of iterations rigid motion correction, in general is 1. 0\n",
    "               will quickly initialize a template with the first frames\n",
    "\n",
    "           splits_rig': int\n",
    "            for parallelization split the movies in  num_splits chuncks across time\n",
    "\n",
    "           num_splits_to_process_rig: list,\n",
    "               if none all the splits are processed and the movie is saved, otherwise at each iteration\n",
    "               num_splits_to_process_rig are considered\n",
    "\n",
    "           strides: tuple\n",
    "               intervals at which patches are laid out for motion correction\n",
    "\n",
    "           overlaps: tuple\n",
    "               overlap between pathes (size of patch strides+overlaps)\n",
    "\n",
    "           pw_rigig: bool, default: False\n",
    "               flag for performing motion correction when calling motion_correct\n",
    "\n",
    "           splits_els':list\n",
    "               for parallelization split the movies in  num_splits chuncks across time\n",
    "\n",
    "           num_splits_to_process_els: list,\n",
    "               if none all the splits are processed and the movie is saved  otherwise at each iteration\n",
    "                num_splits_to_process_els are considered\n",
    "\n",
    "           upsample_factor_grid:int,\n",
    "               upsample factor of shifts per patches to avoid smearing when merging patches\n",
    "\n",
    "           max_deviation_rigid:int\n",
    "               maximum deviation allowed for patch with respect to rigid shift\n",
    "\n",
    "           shifts_opencv: Bool\n",
    "               apply shifts fast way (but smoothing results)\n",
    "\n",
    "           nonneg_movie: boolean\n",
    "               make the SAVED movie and template mostly nonnegative by removing min_mov from movie\n",
    "\n",
    "           use_cuda : bool, optional\n",
    "               Use skcuda.fft (if available). Default: False\n",
    "\n",
    "           border_nan : bool or string, optional\n",
    "               Specifies how to deal with borders. (True, False, 'copy', 'min')\n",
    "\n",
    "           num_frames_split: int, default: 80\n",
    "               Number of frames in each batch. Used when cosntructing the options\n",
    "               through the params object\n",
    "\n",
    "           var_name_hdf5: str, default: 'mov'\n",
    "               If loading from hdf5, name of the variable to load\n",
    "\n",
    "            is3D: bool, default: False\n",
    "               Flag for 3D motion correction\n",
    "\n",
    "            indices: tuple(slice), default: (slice(None), slice(None))\n",
    "               Use that to apply motion correction only on a part of the FOV\n",
    "\n",
    "       Returns:\n",
    "           self\n",
    "\n",
    "        \"\"\"\n",
    "        if 'ndarray' in str(type(fname)):\n",
    "            logging.info('Creating file for motion correction \"tmp_mov_mot_corr.hdf5\"')\n",
    "            cm.movie(fname).save('./tmp_mov_mot_corr.hdf5')\n",
    "            fname = ['./tmp_mov_mot_corr.hdf5']\n",
    "\n",
    "        if type(fname) is not list:\n",
    "            fname = [fname]\n",
    "\n",
    "        self.fname = fname\n",
    "        self.dview = dview\n",
    "        self.max_shifts = max_shifts\n",
    "        self.niter_rig = niter_rig\n",
    "        self.splits_rig = splits_rig\n",
    "        self.num_splits_to_process_rig = num_splits_to_process_rig\n",
    "        self.strides = strides\n",
    "        self.overlaps = overlaps\n",
    "        self.splits_els = splits_els\n",
    "        self.num_splits_to_process_els = num_splits_to_process_els\n",
    "        self.upsample_factor_grid = upsample_factor_grid\n",
    "        self.max_deviation_rigid = max_deviation_rigid\n",
    "        self.shifts_opencv = bool(shifts_opencv)\n",
    "        self.min_mov = min_mov\n",
    "        self.nonneg_movie = nonneg_movie\n",
    "        self.gSig_filt = gSig_filt\n",
    "        self.use_cuda = bool(use_cuda)\n",
    "        self.border_nan = border_nan\n",
    "        self.pw_rigid = bool(pw_rigid)\n",
    "        self.var_name_hdf5 = var_name_hdf5\n",
    "        self.is3D = bool(is3D)\n",
    "        self.indices = indices\n",
    "        if self.use_cuda and not HAS_CUDA:\n",
    "            logging.debug(\"pycuda is unavailable. Falling back to default FFT.\")\n",
    "\n",
    "    def motion_correct(self, template=None, save_movie=False):\n",
    "        \"\"\"general function for performing all types of motion correction. The\n",
    "        function will perform either rigid or piecewise rigid motion correction\n",
    "        depending on the attribute self.pw_rigid and will perform high pass\n",
    "        spatial filtering for determining the motion (used in 1p data) if the\n",
    "        attribute self.gSig_filt is not None. A template can be passed, and the\n",
    "        output can be saved as a memory mapped file.\n",
    "\n",
    "        Args:\n",
    "            template: ndarray, default: None\n",
    "                template provided by user for motion correction\n",
    "\n",
    "            save_movie: bool, default: False\n",
    "                flag for saving motion corrected file(s) as memory mapped file(s)\n",
    "\n",
    "        Returns:\n",
    "            self\n",
    "        \"\"\"\n",
    "        # TODO: Review the docs here, and also why we would ever return self\n",
    "        #       from a method that is not a constructor\n",
    "        if self.min_mov is None:\n",
    "            if self.gSig_filt is None:\n",
    "                # self.min_mov = np.array([load(self.fname[0],\n",
    "                #                                  var_name_hdf5=self.var_name_hdf5,\n",
    "                #                                  subindices=slice(400))]).min()\n",
    "                iterator = load_iter(self.fname[0],\n",
    "                                                    var_name_hdf5=self.var_name_hdf5)\n",
    "                mi = np.inf\n",
    "                for _ in range(400):\n",
    "                    try:\n",
    "                        mi = min(mi, next(iterator).min()[()])\n",
    "                    except StopIteration:\n",
    "                        break\n",
    "                self.min_mov = mi\n",
    "            else:\n",
    "                self.min_mov = np.array([high_pass_filter_space(m_, self.gSig_filt)\n",
    "                    for m_ in load(self.fname[0], var_name_hdf5=self.var_name_hdf5,\n",
    "                                      subindices=slice(400))]).min()\n",
    "\n",
    "        if self.pw_rigid:\n",
    "            self.motion_correct_pwrigid(template=template, save_movie=save_movie)\n",
    "            if self.is3D:\n",
    "                # TODO - error at this point after saving\n",
    "                b0 = np.ceil(np.max([np.max(np.abs(self.x_shifts_els)),\n",
    "                                     np.max(np.abs(self.y_shifts_els)),\n",
    "                                     np.max(np.abs(self.z_shifts_els))]))\n",
    "            else:\n",
    "                b0 = np.ceil(np.maximum(np.max(np.abs(self.x_shifts_els)),\n",
    "                                    np.max(np.abs(self.y_shifts_els))))\n",
    "        else:\n",
    "            self.motion_correct_rigid(template=template, save_movie=save_movie)\n",
    "            b0 = np.ceil(np.max(np.abs(self.shifts_rig)))\n",
    "        self.border_to_0 = b0.astype(np.int)\n",
    "        self.mmap_file = self.fname_tot_els if self.pw_rigid else self.fname_tot_rig\n",
    "        return self\n",
    "\n",
    "    def motion_correct_rigid(self, template=None, save_movie=False) -> None:\n",
    "        \"\"\"\n",
    "        Perform rigid motion correction\n",
    "\n",
    "        Args:\n",
    "            template: ndarray 2D (or 3D)\n",
    "                if known, one can pass a template to register the frames to\n",
    "\n",
    "            save_movie_rigid:Bool\n",
    "                save the movies vs just get the template\n",
    "\n",
    "        Important Fields:\n",
    "            self.fname_tot_rig: name of the mmap file saved\n",
    "\n",
    "            self.total_template_rig: template updated by iterating  over the chunks\n",
    "\n",
    "            self.templates_rig: list of templates. one for each chunk\n",
    "\n",
    "            self.shifts_rig: shifts in x and y (and z if 3D) per frame\n",
    "        \"\"\"\n",
    "        logging.debug('Entering Rigid Motion Correction')\n",
    "        logging.debug(-self.min_mov)  # XXX why the minus?\n",
    "        self.total_template_rig = template\n",
    "        self.templates_rig:List = []\n",
    "        self.fname_tot_rig:List = []\n",
    "        self.shifts_rig:List = []\n",
    "\n",
    "        for fname_cur in self.fname:\n",
    "            _fname_tot_rig, _total_template_rig, _templates_rig, _shifts_rig = motion_correct_batch_rigid(\n",
    "                fname_cur,\n",
    "                self.max_shifts,\n",
    "                dview=self.dview,\n",
    "                splits=self.splits_rig,\n",
    "                num_splits_to_process=self.num_splits_to_process_rig,\n",
    "                num_iter=self.niter_rig,\n",
    "                template=self.total_template_rig,\n",
    "                shifts_opencv=self.shifts_opencv,\n",
    "                save_movie_rigid=save_movie,\n",
    "                add_to_movie=-self.min_mov,\n",
    "                nonneg_movie=self.nonneg_movie,\n",
    "                gSig_filt=self.gSig_filt,\n",
    "                use_cuda=self.use_cuda,\n",
    "                border_nan=self.border_nan,\n",
    "                var_name_hdf5=self.var_name_hdf5,\n",
    "                is3D=self.is3D,\n",
    "                indices=self.indices)\n",
    "            if template is None:\n",
    "                self.total_template_rig = _total_template_rig\n",
    "\n",
    "            self.templates_rig += _templates_rig\n",
    "            self.fname_tot_rig += [_fname_tot_rig]\n",
    "            self.shifts_rig += _shifts_rig\n",
    "\n",
    "    def motion_correct_pwrigid(self, save_movie:bool=True, template:np.ndarray=None, show_template:bool=False) -> None:\n",
    "        \"\"\"Perform pw-rigid motion correction\n",
    "\n",
    "        Args:\n",
    "            save_movie:Bool\n",
    "                save the movies vs just get the template\n",
    "\n",
    "            template: ndarray 2D (or 3D)\n",
    "                if known, one can pass a template to register the frames to\n",
    "\n",
    "            show_template: boolean\n",
    "                whether to show the updated template at each iteration\n",
    "\n",
    "        Important Fields:\n",
    "            self.fname_tot_els: name of the mmap file saved\n",
    "            self.templates_els: template updated by iterating  over the chunks\n",
    "            self.x_shifts_els: shifts in x per frame per patch\n",
    "            self.y_shifts_els: shifts in y per frame per patch\n",
    "            self.z_shifts_els: shifts in z per frame per patch (if 3D)\n",
    "            self.coord_shifts_els: coordinates associated to the patch for\n",
    "            values in x_shifts_els and y_shifts_els (and z_shifts_els if 3D)\n",
    "            self.total_template_els: list of templates. one for each chunk\n",
    "\n",
    "        Raises:\n",
    "            Exception: 'Error: Template contains NaNs, Please review the parameters'\n",
    "        \"\"\"\n",
    "\n",
    "        num_iter = 1\n",
    "        if template is None:\n",
    "            logging.info('Generating template by rigid motion correction')\n",
    "            self.motion_correct_rigid()\n",
    "            self.total_template_els = self.total_template_rig.copy()\n",
    "        else:\n",
    "            self.total_template_els = template\n",
    "\n",
    "        self.fname_tot_els:List = []\n",
    "        self.templates_els:List = []\n",
    "        self.x_shifts_els:List = []\n",
    "        self.y_shifts_els:List = []\n",
    "        if self.is3D:\n",
    "            self.z_shifts_els:List = []\n",
    "\n",
    "        self.coord_shifts_els:List = []\n",
    "        for name_cur in self.fname:\n",
    "            _fname_tot_els, new_template_els, _templates_els,\\\n",
    "                _x_shifts_els, _y_shifts_els, _z_shifts_els, _coord_shifts_els = motion_correct_batch_pwrigid(\n",
    "                    name_cur, self.max_shifts, self.strides, self.overlaps, -self.min_mov,\n",
    "                    dview=self.dview, upsample_factor_grid=self.upsample_factor_grid,\n",
    "                    max_deviation_rigid=self.max_deviation_rigid, splits=self.splits_els,\n",
    "                    num_splits_to_process=None, num_iter=num_iter, template=self.total_template_els,\n",
    "                    shifts_opencv=self.shifts_opencv, save_movie=save_movie, nonneg_movie=self.nonneg_movie, gSig_filt=self.gSig_filt,\n",
    "                    use_cuda=self.use_cuda, border_nan=self.border_nan, var_name_hdf5=self.var_name_hdf5, is3D=self.is3D,\n",
    "                    indices=self.indices)\n",
    "            if not self.is3D:\n",
    "                if show_template:\n",
    "                    pl.imshow(new_template_els)\n",
    "                    pl.pause(.5)\n",
    "            if np.isnan(np.sum(new_template_els)):\n",
    "                raise Exception(\n",
    "                    'Template contains NaNs, something went wrong. Reconsider the parameters')\n",
    "\n",
    "            if template is None:\n",
    "                self.total_template_els = new_template_els\n",
    "\n",
    "            self.fname_tot_els += [_fname_tot_els]\n",
    "            self.templates_els += _templates_els\n",
    "            self.x_shifts_els += _x_shifts_els\n",
    "            self.y_shifts_els += _y_shifts_els\n",
    "            if self.is3D:\n",
    "                self.z_shifts_els += _z_shifts_els\n",
    "            self.coord_shifts_els += _coord_shifts_els\n",
    "\n",
    "    def apply_shifts_movie(self, fname, rigid_shifts:bool=None, save_memmap:bool=False,\n",
    "                           save_base_name:str='MC', order:str='F', remove_min:bool=True):\n",
    "        \"\"\"\n",
    "        Applies shifts found by registering one file to a different file. Useful\n",
    "        for cases when shifts computed from a structural channel are applied to a\n",
    "        functional channel. Currently only application of shifts through openCV is\n",
    "        supported. Returns either cm.movie or the path to a memory mapped file.\n",
    "\n",
    "        Args:\n",
    "            fname: str of List[str]\n",
    "                name(s) of the movie to motion correct. It should not contain\n",
    "                nans. All the loadable formats from CaImAn are acceptable\n",
    "\n",
    "            rigid_shifts: bool (True)\n",
    "                apply rigid or pw-rigid shifts (must exist in the mc object)\n",
    "                deprectated (read directly from mc.pw_rigid)\n",
    "\n",
    "            save_memmap: bool (False)\n",
    "                flag for saving the resulting file in memory mapped form\n",
    "\n",
    "            save_base_name: str ['MC']\n",
    "                base name for memory mapped file name\n",
    "\n",
    "            order: 'F' or 'C' ['F']\n",
    "                order of resulting memory mapped file\n",
    "\n",
    "            remove_min: bool (True)\n",
    "                If minimum value is negative, subtract it from the data\n",
    "\n",
    "        Returns:\n",
    "            m_reg: caiman movie object\n",
    "                caiman movie object with applied shifts (not memory mapped)\n",
    "        \"\"\"\n",
    "\n",
    "        Y = load(fname).astype(np.float32)\n",
    "        if remove_min: \n",
    "            ymin = Y.min()\n",
    "            if ymin < 0:\n",
    "                Y -= Y.min()\n",
    "\n",
    "        if rigid_shifts is not None:\n",
    "            logging.warning('The rigid_shifts flag is deprecated and it is ' +\n",
    "                            'being ignored. The value is read directly from' +\n",
    "                            ' mc.pw_rigid and is current set to the opposite' +\n",
    "                            ' of {}'.format(self.pw_rigid))            \n",
    "        \n",
    "        if self.pw_rigid is False:\n",
    "            if self.is3D:\n",
    "                m_reg = [apply_shifts_dft(img, (sh[0], sh[1], sh[2]), 0,\n",
    "                                          is_freq=False, border_nan=self.border_nan)\n",
    "                         for img, sh in zip(Y, self.shifts_rig)]\n",
    "            elif self.shifts_opencv:\n",
    "                m_reg = [apply_shift_iteration(img, shift, border_nan=self.border_nan)\n",
    "                         for img, shift in zip(Y, self.shifts_rig)]\n",
    "            else:\n",
    "                m_reg = [apply_shifts_dft(img, (\n",
    "                    sh[0], sh[1]), 0, is_freq=False, border_nan=self.border_nan) for img, sh in zip(\n",
    "                    Y, self.shifts_rig)]\n",
    "        else:\n",
    "            if self.is3D:\n",
    "                xyz_grid = [(it[0], it[1], it[2]) for it in sliding_window_3d(\n",
    "                            Y[0], self.overlaps, self.strides)]\n",
    "                dims_grid = tuple(np.add(xyz_grid[-1], 1))\n",
    "                shifts_x = np.stack([np.reshape(_sh_, dims_grid, order='C').astype(\n",
    "                    np.float32) for _sh_ in self.x_shifts_els], axis=0)\n",
    "                shifts_y = np.stack([np.reshape(_sh_, dims_grid, order='C').astype(\n",
    "                    np.float32) for _sh_ in self.y_shifts_els], axis=0)\n",
    "                shifts_z = np.stack([np.reshape(_sh_, dims_grid, order='C').astype(\n",
    "                    np.float32) for _sh_ in self.z_shifts_els], axis=0)\n",
    "                dims = Y.shape[1:]\n",
    "                x_grid, y_grid, z_grid = np.meshgrid(np.arange(0., dims[1]).astype(\n",
    "                    np.float32), np.arange(0., dims[0]).astype(np.float32),\n",
    "                    np.arange(0., dims[2]).astype(np.float32))\n",
    "                m_reg = [warp_sk(img, np.stack((resize_sk(shiftX.astype(np.float32), dims) + y_grid,\n",
    "                                 resize_sk(shiftY.astype(np.float32), dims) + x_grid,\n",
    "                                 resize_sk(shiftZ.astype(np.float32), dims) + z_grid), axis=0),\n",
    "                                 order=3, mode='constant')\n",
    "                         for img, shiftX, shiftY, shiftZ in zip(Y, shifts_x, shifts_y, shifts_z)]\n",
    "                                 # borderValue=add_to_movie)\n",
    "            else:\n",
    "                xy_grid = [(it[0], it[1]) for it in sliding_window(Y[0], self.overlaps, self.strides)]\n",
    "                dims_grid = tuple(np.max(np.stack(xy_grid, axis=1), axis=1) - np.min(\n",
    "                    np.stack(xy_grid, axis=1), axis=1) + 1)\n",
    "                shifts_x = np.stack([np.reshape(_sh_, dims_grid, order='C').astype(\n",
    "                    np.float32) for _sh_ in self.x_shifts_els], axis=0)\n",
    "                shifts_y = np.stack([np.reshape(_sh_, dims_grid, order='C').astype(\n",
    "                    np.float32) for _sh_ in self.y_shifts_els], axis=0)\n",
    "                dims = Y.shape[1:]\n",
    "                x_grid, y_grid = np.meshgrid(np.arange(0., dims[1]).astype(\n",
    "                    np.float32), np.arange(0., dims[0]).astype(np.float32))\n",
    "                m_reg = [cv2.remap(img, -cv2.resize(shiftY, dims[::-1]) + x_grid,\n",
    "                                   -cv2.resize(shiftX, dims[::-1]) + y_grid,\n",
    "                                   cv2.INTER_CUBIC, borderMode=cv2.BORDER_REPLICATE)\n",
    "                         for img, shiftX, shiftY in zip(Y, shifts_x, shifts_y)]\n",
    "        m_reg = np.stack(m_reg, axis=0)\n",
    "        if save_memmap:\n",
    "            dims = m_reg.shape\n",
    "            fname_tot = memmap_frames_filename(save_base_name, dims[1:], dims[0], order)\n",
    "            big_mov = np.memmap(fname_tot, mode='w+', dtype=np.float32,\n",
    "                        shape=prepare_shape((np.prod(dims[1:]), dims[0])), order=order)\n",
    "            big_mov[:] = np.reshape(m_reg.transpose(1, 2, 0), (np.prod(dims[1:]), dims[0]), order='F')\n",
    "            big_mov.flush()\n",
    "            del big_mov\n",
    "            return fname_tot\n",
    "        else:\n",
    "            return cm.movie(m_reg)\n",
    "\n",
    "#%%\n",
    "def apply_shift_iteration(img, shift, border_nan:bool=False, border_type=cv2.BORDER_REFLECT):\n",
    "    # todo todocument\n",
    "\n",
    "    sh_x_n, sh_y_n = shift\n",
    "    w_i, h_i = img.shape\n",
    "    M = np.float32([[1, 0, sh_y_n], [0, 1, sh_x_n]])\n",
    "    min_, max_ = np.nanmin(img), np.nanmax(img)\n",
    "    img = np.clip(cv2.warpAffine(img, M, (h_i, w_i),\n",
    "                                 flags=cv2.INTER_CUBIC, borderMode=border_type), min_, max_)\n",
    "    if border_nan is not False:\n",
    "        max_w, max_h, min_w, min_h = 0, 0, 0, 0\n",
    "        max_h, max_w = np.ceil(np.maximum(\n",
    "            (max_h, max_w), shift)).astype(np.int)\n",
    "        min_h, min_w = np.floor(np.minimum(\n",
    "            (min_h, min_w), shift)).astype(np.int)\n",
    "        if border_nan is True:\n",
    "            img[:max_h, :] = np.nan\n",
    "            if min_h < 0:\n",
    "                img[min_h:, :] = np.nan\n",
    "            img[:, :max_w] = np.nan\n",
    "            if min_w < 0:\n",
    "                img[:, min_w:] = np.nan\n",
    "        elif border_nan == 'min':\n",
    "            img[:max_h, :] = min_\n",
    "            if min_h < 0:\n",
    "                img[min_h:, :] = min_\n",
    "            img[:, :max_w] = min_\n",
    "            if min_w < 0:\n",
    "                img[:, min_w:] = min_\n",
    "        elif border_nan == 'copy':\n",
    "            if max_h > 0:\n",
    "                img[:max_h] = img[max_h]\n",
    "            if min_h < 0:\n",
    "                img[min_h:] = img[min_h-1]\n",
    "            if max_w > 0:\n",
    "                img[:, :max_w] = img[:, max_w, np.newaxis]\n",
    "            if min_w < 0:\n",
    "                img[:, min_w:] = img[:, min_w-1, np.newaxis]\n",
    "\n",
    "    return img\n",
    "\n",
    "\n",
    "#%%\n",
    "def apply_shift_online(movie_iterable, xy_shifts, save_base_name=None, order='F'):\n",
    "    \"\"\"\n",
    "    Applies rigid shifts to a loaded movie. Useful when processing a dataset\n",
    "    with CaImAn online and you want to obtain the registered movie after\n",
    "    processing is finished or when operating with dual channels.\n",
    "    When save_base_name is None the registered file is returned as a caiman\n",
    "    movie. Otherwise a memory mapped file is saved.\n",
    "    Currently only rigid shifts are supported supported.\n",
    "\n",
    "    Args:\n",
    "        movie_iterable: cm.movie or np.array\n",
    "            Movie to be registered in T x X x Y format\n",
    "\n",
    "        xy_shifts: list\n",
    "            list of shifts to be applied\n",
    "\n",
    "        save_base_name: str or None\n",
    "            prefix for memory mapped file otherwise registered file is returned\n",
    "            to memory\n",
    "\n",
    "        order: 'F' or 'C'\n",
    "            order of memory mapped file\n",
    "\n",
    "    Returns:\n",
    "        name of registered memory mapped file if save_base_name is not None,\n",
    "        otherwise registered file\n",
    "    \"\"\"\n",
    "    # todo use for non rigid shifts\n",
    "\n",
    "    if len(movie_iterable) != len(xy_shifts):\n",
    "        raise Exception('Number of shifts does not match movie length!')\n",
    "    count = 0\n",
    "    new_mov = []\n",
    "    dims = (len(movie_iterable),) + movie_iterable[0].shape  # TODO: Refactor so length is either tracked separately or is last part of tuple\n",
    "\n",
    "    if save_base_name is not None:\n",
    "        fname_tot = memmap_frames_filename(save_base_name, dims[1:], dims[0], order)\n",
    "        big_mov = np.memmap(fname_tot, mode='w+', dtype=np.float32,\n",
    "                            shape=prepare_shape((np.prod(dims[1:]), dims[0])), order=order)\n",
    "\n",
    "    for page, shift in zip(movie_iterable, xy_shifts):\n",
    "        if 'tifffile' in str(type(movie_iterable[0])):\n",
    "            page = page.asarray()\n",
    "\n",
    "        img = np.array(page, dtype=np.float32)\n",
    "        new_img = apply_shift_iteration(img, shift)\n",
    "        if save_base_name is not None:\n",
    "            big_mov[:, count] = np.reshape(\n",
    "                new_img, np.prod(dims[1:]), order='F')\n",
    "        else:\n",
    "            new_mov.append(new_img)\n",
    "        count += 1\n",
    "\n",
    "    if save_base_name is not None:\n",
    "        big_mov.flush()\n",
    "        del big_mov\n",
    "        return fname_tot\n",
    "    else:\n",
    "        return np.array(new_mov)\n",
    "#%%\n",
    "\n",
    "def motion_correct_oneP_rigid(\n",
    "        filename,\n",
    "        gSig_filt,\n",
    "        max_shifts,\n",
    "        dview=None,\n",
    "        splits_rig=10,\n",
    "        save_movie=True,\n",
    "        border_nan=True):\n",
    "    '''Perform rigid motion correction on one photon imaging movies\n",
    "\n",
    "    Args:\n",
    "        filename: str\n",
    "            name of the file to correct\n",
    "        gSig_filt:\n",
    "            size of the filter. If algorithm does not work change this parameters\n",
    "        max_shifts: tuple of ints\n",
    "            max shifts in x and y allowed\n",
    "        dview:\n",
    "            handle to cluster\n",
    "        splits_rig: int\n",
    "            number of chunks for parallelizing motion correction (remember that it should hold that length_movie/num_splits_to_process_rig>100)\n",
    "        save_movie: bool\n",
    "            whether to save the movie in memory mapped format\n",
    "        border_nan : bool or string, optional\n",
    "            Specifies how to deal with borders. (True, False, 'copy', 'min')        \n",
    "\n",
    "    Returns:\n",
    "        Motion correction object\n",
    "    '''\n",
    "    min_mov = np.array([caiman.motion_correction.high_pass_filter_space(\n",
    "        m_, gSig_filt) for m_ in load(filename[0], subindices=range(400))]).min()\n",
    "    new_templ = None\n",
    "\n",
    "    # TODO: needinfo how the classes works\n",
    "    mc = MotionCorrect(\n",
    "        filename,\n",
    "        min_mov,\n",
    "        dview=dview,\n",
    "        max_shifts=max_shifts,\n",
    "        niter_rig=1,\n",
    "        splits_rig=splits_rig,\n",
    "        num_splits_to_process_rig=None,\n",
    "        shifts_opencv=True,\n",
    "        nonneg_movie=True,\n",
    "        gSig_filt=gSig_filt,\n",
    "        border_nan=border_nan,\n",
    "        is3D=False)\n",
    "\n",
    "    mc.motion_correct_rigid(save_movie=save_movie, template=new_templ)\n",
    "\n",
    "    return mc\n",
    "\n",
    "def motion_correct_oneP_nonrigid(\n",
    "        filename,\n",
    "        gSig_filt,\n",
    "        max_shifts,\n",
    "        strides,\n",
    "        overlaps,\n",
    "        splits_els,\n",
    "        upsample_factor_grid,\n",
    "        max_deviation_rigid,\n",
    "        dview=None,\n",
    "        splits_rig=10,\n",
    "        save_movie=True,\n",
    "        new_templ=None,\n",
    "        border_nan=True):\n",
    "    '''Perform rigid motion correction on one photon imaging movies\n",
    "\n",
    "    Args:\n",
    "        filename: str\n",
    "            name of the file to correct\n",
    "        gSig_filt:\n",
    "            size of the filter. If algorithm does not work change this parameters\n",
    "        max_shifts: tuple of ints\n",
    "            max shifts in x and y allowed\n",
    "        dview:\n",
    "            handle to cluster\n",
    "        splits_rig: int\n",
    "            number of chunks for parallelizing motion correction (remember that it should hold that length_movie/num_splits_to_process_rig>100)\n",
    "        save_movie: bool\n",
    "            whether to save the movie in memory mapped format\n",
    "        border_nan : bool or string, optional\n",
    "            specifies how to deal with borders. (True, False, 'copy', 'min')\n",
    "\n",
    "    Returns:\n",
    "        Motion correction object\n",
    "    '''\n",
    "\n",
    "    if new_templ is None:\n",
    "        min_mov = np.array([cm.motion_correction.high_pass_filter_space(\n",
    "            m_, gSig_filt) for m_ in load(filename, subindices=range(400))]).min()\n",
    "    else:\n",
    "        min_mov = np.min(new_templ)\n",
    "\n",
    "    # TODO: needinfo how the classes works\n",
    "    mc = MotionCorrect(\n",
    "        filename,\n",
    "        min_mov,\n",
    "        dview=dview,\n",
    "        max_shifts=max_shifts,\n",
    "        niter_rig=1,\n",
    "        splits_rig=splits_rig,\n",
    "        num_splits_to_process_rig=None,\n",
    "        shifts_opencv=True,\n",
    "        nonneg_movie=True,\n",
    "        gSig_filt=gSig_filt,\n",
    "        strides=strides,\n",
    "        overlaps=overlaps,\n",
    "        splits_els=splits_els,\n",
    "        upsample_factor_grid=upsample_factor_grid,\n",
    "        max_deviation_rigid=max_deviation_rigid,\n",
    "        border_nan=border_nan,\n",
    "        is3D=False)\n",
    "\n",
    "    mc.motion_correct_pwrigid(save_movie=True, template=new_templ)\n",
    "    return mc\n",
    "\n",
    "def motion_correct_online_multifile(list_files, add_to_movie, order='C', **kwargs):\n",
    "    # todo todocument\n",
    "\n",
    "    kwargs['order'] = order\n",
    "    all_names = []\n",
    "    all_shifts = []\n",
    "    all_xcorrs = []\n",
    "    all_templates = []\n",
    "    template = None\n",
    "    kwargs_ = kwargs.copy()\n",
    "    kwargs_['order'] = order\n",
    "    total_frames = 0\n",
    "    for file_ in list_files:\n",
    "        logging.info(('Processing:' + file_))\n",
    "        kwargs_['template'] = template\n",
    "        kwargs_['save_base_name'] = file_[:-4]\n",
    "        tffl = tifffile.TiffFile(file_)\n",
    "        shifts, xcorrs, template, fname_tot = motion_correct_online(\n",
    "            tffl, add_to_movie, **kwargs_)[0:4]\n",
    "        all_names.append(fname_tot)\n",
    "        all_shifts.append(shifts)\n",
    "        all_xcorrs.append(xcorrs)\n",
    "        all_templates.append(template)\n",
    "        total_frames = total_frames + len(shifts)\n",
    "\n",
    "    return all_names, all_shifts, all_xcorrs, all_templates\n",
    "\n",
    "\n",
    "#%%\n",
    "def motion_correct_online(movie_iterable, add_to_movie, max_shift_w=25, max_shift_h=25, save_base_name=None, order='C',\n",
    "                          init_frames_template=100, show_movie=False, bilateral_blur=False, template=None, min_count=1000,\n",
    "                          border_to_0=0, n_iter=1, remove_blanks=False, show_template=False, return_mov=False,\n",
    "                          use_median_as_template=False):\n",
    "    # todo todocument\n",
    "\n",
    "    shifts = []  # store the amount of shift in each frame\n",
    "    xcorrs = []\n",
    "    if remove_blanks and n_iter == 1:\n",
    "        raise Exception(\n",
    "            'In order to remove blanks you need at least two iterations n_iter=2')\n",
    "\n",
    "    if 'tifffile' in str(type(movie_iterable[0])):\n",
    "        if len(movie_iterable) == 1:\n",
    "            logging.warning(\n",
    "                '******** WARNING ****** NEED TO LOAD IN MEMORY SINCE SHAPE OF PAGE IS THE FULL MOVIE')\n",
    "            movie_iterable = movie_iterable.asarray()\n",
    "            init_mov = movie_iterable[:init_frames_template]\n",
    "        else:\n",
    "            init_mov = [m.asarray()\n",
    "                        for m in movie_iterable[:init_frames_template]]\n",
    "    else:\n",
    "        init_mov = movie_iterable[slice(0, init_frames_template, 1)]\n",
    "\n",
    "    dims = (len(movie_iterable),) + movie_iterable[0].shape # TODO: Refactor so length is either tracked separately or is last part of tuple\n",
    "    logging.debug(\"dimensions:\" + str(dims))\n",
    "\n",
    "    if use_median_as_template:\n",
    "        template = bin_median(movie_iterable)\n",
    "\n",
    "    if template is None:\n",
    "        template = bin_median(init_mov)\n",
    "        count = init_frames_template\n",
    "        if np.percentile(template, 1) + add_to_movie < - 10:\n",
    "            raise Exception(\n",
    "                'Movie too negative, You need to add a larger value to the movie (add_to_movie)')\n",
    "        template = np.array(template + add_to_movie, dtype=np.float32)\n",
    "    else:\n",
    "        if np.percentile(template, 1) < - 10:\n",
    "            raise Exception(\n",
    "                'Movie too negative, You need to add a larger value to the movie (add_to_movie)')\n",
    "        count = min_count\n",
    "\n",
    "    min_mov = 0\n",
    "    buffer_size_frames = 100\n",
    "    buffer_size_template = 100\n",
    "    buffer_frames:collections.deque = collections.deque(maxlen=buffer_size_frames)\n",
    "    buffer_templates:collections.deque = collections.deque(maxlen=buffer_size_template)\n",
    "    max_w, max_h, min_w, min_h = 0, 0, 0, 0\n",
    "\n",
    "    big_mov = None\n",
    "    if return_mov:\n",
    "        mov:Optional[List] = []\n",
    "    else:\n",
    "        mov = None\n",
    "\n",
    "    for n in range(n_iter):\n",
    "        if n > 0:\n",
    "            count = init_frames_template\n",
    "\n",
    "        if (save_base_name is not None) and (big_mov is None) and (n_iter == (n + 1)):\n",
    "\n",
    "            if remove_blanks:\n",
    "                dims = (dims[0], dims[1] + min_h -\n",
    "                        max_h, dims[2] + min_w - max_w)\n",
    "\n",
    "            fname_tot:Optional[str] = memmap_frames_filename(save_base_name, dims[1:], dims[0], order)\n",
    "            big_mov = np.memmap(fname_tot, mode='w+', dtype=np.float32,\n",
    "                                shape=prepare_shape((np.prod(dims[1:]), dims[0])), order=order)\n",
    "\n",
    "        else:\n",
    "            fname_tot = None\n",
    "\n",
    "        shifts_tmp = []\n",
    "        xcorr_tmp = []\n",
    "        for idx_frame, page in enumerate(movie_iterable):\n",
    "\n",
    "            if 'tifffile' in str(type(movie_iterable[0])):\n",
    "                page = page.asarray()\n",
    "\n",
    "            img = np.array(page, dtype=np.float32)\n",
    "            img = img + add_to_movie\n",
    "\n",
    "            new_img, template_tmp, shift, avg_corr = motion_correct_iteration(\n",
    "                img, template, count, max_shift_w=max_shift_w, max_shift_h=max_shift_h, bilateral_blur=bilateral_blur)\n",
    "\n",
    "            max_h, max_w = np.ceil(np.maximum(\n",
    "                (max_h, max_w), shift)).astype(np.int)\n",
    "            min_h, min_w = np.floor(np.minimum(\n",
    "                (min_h, min_w), shift)).astype(np.int)\n",
    "\n",
    "            if count < (buffer_size_frames + init_frames_template):\n",
    "                template_old = template\n",
    "                template = template_tmp\n",
    "            else:\n",
    "                template_old = template\n",
    "            buffer_frames.append(new_img)\n",
    "\n",
    "            if count % 100 == 0:\n",
    "                if count >= (buffer_size_frames + init_frames_template):\n",
    "                    buffer_templates.append(np.mean(buffer_frames, 0))\n",
    "                    template = np.median(buffer_templates, 0)\n",
    "\n",
    "                if show_template:\n",
    "                    pl.cla()\n",
    "                    pl.imshow(template, cmap='gray', vmin=250,\n",
    "                              vmax=350, interpolation='none')\n",
    "                    pl.pause(.001)\n",
    "\n",
    "                logging.debug('Relative change in template:' + str(\n",
    "                    old_div(np.sum(np.abs(template - template_old)), np.sum(np.abs(template)))))\n",
    "                logging.debug('Iteration:' + str(count))\n",
    "\n",
    "            if border_to_0 > 0:\n",
    "                new_img[:border_to_0, :] = min_mov\n",
    "                new_img[:, :border_to_0] = min_mov\n",
    "                new_img[:, -border_to_0:] = min_mov\n",
    "                new_img[-border_to_0:, :] = min_mov\n",
    "\n",
    "            shifts_tmp.append(shift)\n",
    "            xcorr_tmp.append(avg_corr)\n",
    "\n",
    "            if remove_blanks and n > 0 and (n_iter == (n + 1)):\n",
    "\n",
    "                new_img = new_img[max_h:, :]\n",
    "                if min_h < 0:\n",
    "                    new_img = new_img[:min_h, :]\n",
    "                new_img = new_img[:, max_w:]\n",
    "                if min_w < 0:\n",
    "                    new_img = new_img[:, :min_w]\n",
    "\n",
    "            if (save_base_name is not None) and (n_iter == (n + 1)):\n",
    "                big_mov[:, idx_frame] = np.reshape(new_img, np.prod(dims[1:]), order='F') # type: ignore\n",
    "                                                                                          # mypy cannot prove that big_mov is not still None\n",
    "\n",
    "            if mov is not None and (n_iter == (n + 1)):\n",
    "                mov.append(new_img)\n",
    "\n",
    "            if show_movie:\n",
    "                cv2.imshow('frame', old_div(new_img, 500))\n",
    "                logging.info(shift)\n",
    "                if not np.any(np.remainder(shift, 1) == (0, 0)):\n",
    "                    cv2.waitKey(int(1. / 500 * 1000))\n",
    "\n",
    "            count += 1\n",
    "        shifts.append(shifts_tmp)\n",
    "        xcorrs.append(xcorr_tmp)\n",
    "\n",
    "    if save_base_name is not None:\n",
    "        logging.debug('Flushing memory')\n",
    "        big_mov.flush() # type: ignore # mypy cannot prove big_mov is not still None\n",
    "        del big_mov\n",
    "        gc.collect()\n",
    "\n",
    "    if mov is not None:\n",
    "        mov = np.dstack(mov).transpose([2, 0, 1])\n",
    "\n",
    "    return shifts, xcorrs, template, fname_tot, mov\n",
    "\n",
    "\n",
    "#%%\n",
    "def motion_correct_iteration(img, template, frame_num, max_shift_w=25,\n",
    "                             max_shift_h=25, bilateral_blur=False, diameter=10, sigmaColor=10000, sigmaSpace=0):\n",
    "    # todo todocument\n",
    "    h_i, w_i = template.shape\n",
    "    ms_h = max_shift_h\n",
    "    ms_w = max_shift_w\n",
    "\n",
    "    if bilateral_blur:\n",
    "        img = cv2.bilateralFilter(img, diameter, sigmaColor, sigmaSpace)\n",
    "    templ_crop = template[max_shift_h:h_i - max_shift_h,\n",
    "                          max_shift_w:w_i - max_shift_w].astype(np.float32)\n",
    "    res = cv2.matchTemplate(img, templ_crop, cv2.TM_CCORR_NORMED)\n",
    "\n",
    "    top_left = cv2.minMaxLoc(res)[3]\n",
    "    avg_corr = np.max(res)\n",
    "    sh_y, sh_x = top_left\n",
    "\n",
    "    if (0 < top_left[1] < 2 * ms_h - 1) & (0 < top_left[0] < 2 * ms_w - 1):\n",
    "        # if max is internal, check for subpixel shift using gaussian\n",
    "        # peak registration\n",
    "        log_xm1_y = np.log(res[sh_x - 1, sh_y])\n",
    "        log_xp1_y = np.log(res[sh_x + 1, sh_y])\n",
    "        log_x_ym1 = np.log(res[sh_x, sh_y - 1])\n",
    "        log_x_yp1 = np.log(res[sh_x, sh_y + 1])\n",
    "        four_log_xy = 4 * np.log(res[sh_x, sh_y])\n",
    "\n",
    "        sh_x_n = -(sh_x - ms_h + old_div((log_xm1_y - log_xp1_y),\n",
    "                                         (2 * log_xm1_y - four_log_xy + 2 * log_xp1_y)))\n",
    "        sh_y_n = -(sh_y - ms_w + old_div((log_x_ym1 - log_x_yp1),\n",
    "                                         (2 * log_x_ym1 - four_log_xy + 2 * log_x_yp1)))\n",
    "    else:\n",
    "        sh_x_n = -(sh_x - ms_h)\n",
    "        sh_y_n = -(sh_y - ms_w)\n",
    "\n",
    "    M = np.float32([[1, 0, sh_y_n], [0, 1, sh_x_n]])\n",
    "    min_, max_ = np.min(img), np.max(img)\n",
    "    new_img = np.clip(cv2.warpAffine(\n",
    "        img, M, (w_i, h_i), flags=cv2.INTER_CUBIC, borderMode=cv2.BORDER_REFLECT), min_, max_)\n",
    "\n",
    "    new_templ = template * frame_num / \\\n",
    "        (frame_num + 1) + 1. / (frame_num + 1) * new_img\n",
    "    shift = [sh_x_n, sh_y_n]\n",
    "\n",
    "    return new_img, new_templ, shift, avg_corr\n",
    "\n",
    "#%%\n",
    "\n",
    "\n",
    "def motion_correct_iteration_fast(img, template, max_shift_w=10, max_shift_h=10):\n",
    "    \"\"\" For using in online realtime scenarios \"\"\"\n",
    "    h_i, w_i = template.shape\n",
    "    ms_h = max_shift_h\n",
    "    ms_w = max_shift_w\n",
    "\n",
    "    templ_crop = template[max_shift_h:h_i - max_shift_h,\n",
    "                          max_shift_w:w_i - max_shift_w].astype(np.float32)\n",
    "\n",
    "    res = cv2.matchTemplate(img, templ_crop, cv2.TM_CCORR_NORMED)\n",
    "    top_left = cv2.minMaxLoc(res)[3]\n",
    "\n",
    "    sh_y, sh_x = top_left\n",
    "\n",
    "    if (0 < top_left[1] < 2 * ms_h - 1) & (0 < top_left[0] < 2 * ms_w - 1):\n",
    "        # if max is internal, check for subpixel shift using gaussian\n",
    "        # peak registration\n",
    "        log_xm1_y = np.log(res[sh_x - 1, sh_y])\n",
    "        log_xp1_y = np.log(res[sh_x + 1, sh_y])\n",
    "        log_x_ym1 = np.log(res[sh_x, sh_y - 1])\n",
    "        log_x_yp1 = np.log(res[sh_x, sh_y + 1])\n",
    "        four_log_xy = 4 * np.log(res[sh_x, sh_y])\n",
    "\n",
    "        sh_x_n = -(sh_x - ms_h + old_div((log_xm1_y - log_xp1_y),\n",
    "                                         (2 * log_xm1_y - four_log_xy + 2 * log_xp1_y)))\n",
    "        sh_y_n = -(sh_y - ms_w + old_div((log_x_ym1 - log_x_yp1),\n",
    "                                         (2 * log_x_ym1 - four_log_xy + 2 * log_x_yp1)))\n",
    "    else:\n",
    "        sh_x_n = -(sh_x - ms_h)\n",
    "        sh_y_n = -(sh_y - ms_w)\n",
    "\n",
    "    M = np.float32([[1, 0, sh_y_n], [0, 1, sh_x_n]])\n",
    "\n",
    "    new_img = cv2.warpAffine(\n",
    "        img, M, (w_i, h_i), flags=cv2.INTER_CUBIC, borderMode=cv2.BORDER_REFLECT)\n",
    "\n",
    "    shift = [sh_x_n, sh_y_n]\n",
    "\n",
    "    return new_img, shift\n",
    "\n",
    "#%%\n",
    "\n",
    "\n",
    "def bin_median(mat, window=10, exclude_nans=True):\n",
    "    \"\"\" compute median of 3D array in along axis o by binning values\n",
    "\n",
    "    Args:\n",
    "        mat: ndarray\n",
    "            input 3D matrix, time along first dimension\n",
    "\n",
    "        window: int\n",
    "            number of frames in a bin\n",
    "\n",
    "    Returns:\n",
    "        img:\n",
    "            median image\n",
    "\n",
    "    Raises:\n",
    "        Exception 'Path to template does not exist:'+template\n",
    "    \"\"\"\n",
    "\n",
    "    T, d1, d2 = np.shape(mat)\n",
    "    if T < window:\n",
    "        window = T\n",
    "    num_windows = np.int(old_div(T, window))\n",
    "    num_frames = num_windows * window\n",
    "    if exclude_nans:\n",
    "        img = np.nanmedian(np.nanmean(np.reshape(\n",
    "            mat[:num_frames], (window, num_windows, d1, d2)), axis=0), axis=0)\n",
    "    else:\n",
    "        img = np.median(np.mean(np.reshape(\n",
    "            mat[:num_frames], (window, num_windows, d1, d2)), axis=0), axis=0)\n",
    "\n",
    "    return img\n",
    "\n",
    "def bin_median_3d(mat, window=10, exclude_nans=True):\n",
    "    \"\"\" compute median of 4D array in along axis o by binning values\n",
    "\n",
    "    Args:\n",
    "        mat: ndarray\n",
    "            input 4D matrix, (T, h, w, z)\n",
    "\n",
    "        window: int\n",
    "            number of frames in a bin\n",
    "\n",
    "    Returns:\n",
    "        img:\n",
    "            median image\n",
    "\n",
    "    Raises:\n",
    "        Exception 'Path to template does not exist:'+template\n",
    "    \"\"\"\n",
    "\n",
    "    T, d1, d2, d3 = np.shape(mat)\n",
    "    if T < window:\n",
    "        window = T\n",
    "    num_windows = np.int(old_div(T, window))\n",
    "    num_frames = num_windows * window\n",
    "    if exclude_nans:\n",
    "        img = np.nanmedian(np.nanmean(np.reshape(\n",
    "            mat[:num_frames], (window, num_windows, d1, d2, d3)), axis=0), axis=0)\n",
    "    else:\n",
    "        img = np.median(np.mean(np.reshape(\n",
    "            mat[:num_frames], (window, num_windows, d1, d2, d3)), axis=0), axis=0)\n",
    "\n",
    "    return img\n",
    "\n",
    "def process_movie_parallel(arg_in):\n",
    "    #todo: todocument\n",
    "    fname, fr, margins_out, template, max_shift_w, max_shift_h, remove_blanks, apply_smooth, save_hdf5 = arg_in\n",
    "\n",
    "    if template is not None:\n",
    "        if isinstance(template, basestring):\n",
    "            if os.path.exists(template):\n",
    "                template = load(template, fr=1)\n",
    "            else:\n",
    "                raise Exception('Path to template does not exist:' + template)\n",
    "\n",
    "    type_input = str(type(fname))\n",
    "    if 'movie' in type_input:\n",
    "        #        logging.info((type(fname)))\n",
    "        Yr = fname\n",
    "\n",
    "    elif 'ndarray' in type_input:\n",
    "        Yr = cm.movie(np.array(fname, dtype=np.float32), fr=fr)\n",
    "    elif isinstance(fname, basestring):\n",
    "        Yr = load(fname, fr=fr)\n",
    "    else:\n",
    "        raise Exception('Unknown input type:' + type_input)\n",
    "\n",
    "    if Yr.ndim > 1:\n",
    "        #        logging.info('loaded')\n",
    "        if apply_smooth:\n",
    "            #            logging.info('applying smoothing')\n",
    "            Yr = Yr.bilateral_blur_2D(\n",
    "                diameter=10, sigmaColor=10000, sigmaSpace=0)\n",
    "\n",
    "#        print('Remove BL')\n",
    "        if margins_out != 0:\n",
    "            Yr = Yr[:, margins_out:-margins_out, margins_out:-\n",
    "                    margins_out]  # borders create troubles\n",
    "\n",
    "#        logging.info('motion correcting')\n",
    "\n",
    "        Yr, shifts, xcorrs, template = Yr.motion_correct(max_shift_w=max_shift_w, max_shift_h=max_shift_h,\n",
    "                                                         method='opencv', template=template, remove_blanks=remove_blanks)\n",
    "\n",
    "        if ('movie' in type_input) or ('ndarray' in type_input):\n",
    "            #            logging.debug('Returning Values')\n",
    "            return Yr, shifts, xcorrs, template\n",
    "\n",
    "        else:\n",
    "\n",
    "            #            logging.debug('median computing')\n",
    "            template = Yr.bin_median()\n",
    "#            logging.debug('saving')\n",
    "            idx_dot = len(fname.split('.')[-1])\n",
    "            if save_hdf5:\n",
    "                Yr.save(fname[:-idx_dot] + 'hdf5')\n",
    "#            logging.debug('saving 2')\n",
    "            np.savez(fname[:-idx_dot] + 'npz', shifts=shifts,\n",
    "                     xcorrs=xcorrs, template=template)\n",
    "#            logging.debug('deleting')\n",
    "            del Yr\n",
    "#            logging.debug('done!')\n",
    "            return fname[:-idx_dot]\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "\n",
    "#%%\n",
    "def motion_correct_parallel(file_names, fr=10, template=None, margins_out=0,\n",
    "                            max_shift_w=5, max_shift_h=5, remove_blanks=False, apply_smooth=False, dview=None, save_hdf5=True):\n",
    "    \"\"\"motion correct many movies usingthe ipyparallel cluster\n",
    "\n",
    "    Args:\n",
    "        file_names: list of strings\n",
    "            names of he files to be motion corrected\n",
    "\n",
    "        fr: double\n",
    "            fr parameters for calcblitz movie\n",
    "\n",
    "        margins_out: int\n",
    "            number of pixels to remove from the borders\n",
    "\n",
    "    Returns:\n",
    "        base file names of the motion corrected files:List[str]\n",
    "\n",
    "    Raises:\n",
    "        Exception\n",
    "    \"\"\"\n",
    "    args_in = []\n",
    "    for file_idx, f in enumerate(file_names):\n",
    "        if type(template) is list:\n",
    "            args_in.append((f, fr, margins_out, template[file_idx], max_shift_w, max_shift_h,\n",
    "                            remove_blanks, apply_smooth, save_hdf5))\n",
    "        else:\n",
    "            args_in.append((f, fr, margins_out, template, max_shift_w,\n",
    "                            max_shift_h, remove_blanks, apply_smooth, save_hdf5))\n",
    "\n",
    "    try:\n",
    "        if dview is not None:\n",
    "            if 'multiprocessing' in str(type(dview)):\n",
    "                file_res = dview.map_async(\n",
    "                    process_movie_parallel, args_in).get(4294967)\n",
    "            else:\n",
    "                file_res = dview.map_sync(process_movie_parallel, args_in)\n",
    "                dview.results.clear()\n",
    "        else:\n",
    "            file_res = list(map(process_movie_parallel, args_in))\n",
    "\n",
    "    except:\n",
    "        try:\n",
    "            if (dview is not None) and 'multiprocessing' not in str(type(dview)):\n",
    "                dview.results.clear()\n",
    "\n",
    "        except UnboundLocalError:\n",
    "            logging.error('could not close client')\n",
    "\n",
    "        raise\n",
    "\n",
    "    return file_res\n",
    "\n",
    "#%%\n",
    "\n",
    "\n",
    "def _upsampled_dft(data, upsampled_region_size,\n",
    "                   upsample_factor=1, axis_offsets=None):\n",
    "    \"\"\"\n",
    "    adapted from SIMA (https://github.com/losonczylab) and the scikit-image (http://scikit-image.org/) package.\n",
    "\n",
    "    Unless otherwise specified by LICENSE.txt files in individual\n",
    "    directories, all code is\n",
    "\n",
    "    Copyright (C) 2011, the scikit-image team\n",
    "    All rights reserved.\n",
    "\n",
    "    Redistribution and use in source and binary forms, with or without\n",
    "    modification, are permitted provided that the following conditions are\n",
    "    met:\n",
    "\n",
    "     1. Redistributions of source code must retain the above copyright\n",
    "        notice, this list of conditions and the following disclaimer.\n",
    "     2. Redistributions in binary form must reproduce the above copyright\n",
    "        notice, this list of conditions and the following disclaimer in\n",
    "        the documentation and/or other materials provided with the\n",
    "        distribution.\n",
    "     3. Neither the name of skimage nor the names of its contributors may be\n",
    "        used to endorse or promote products derived from this software without\n",
    "        specific prior written permission.\n",
    "\n",
    "    THIS SOFTWARE IS PROVIDED BY THE AUTHOR ``AS IS'' AND ANY EXPRESS OR\n",
    "    IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED\n",
    "    WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE\n",
    "    DISCLAIMED. IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR ANY DIRECT,\n",
    "    INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES\n",
    "    (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR\n",
    "    SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION)\n",
    "    HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT,\n",
    "    STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING\n",
    "    IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE\n",
    "    POSSIBILITY OF SUCH DAMAGE.\n",
    "\n",
    "    Upsampled DFT by matrix multiplication.\n",
    "\n",
    "    This code is intended to provide the same result as if the following\n",
    "    operations were performed:\n",
    "        - Embed the array \"data\" in an array that is ``upsample_factor`` times\n",
    "          larger in each dimension.  ifftshift to bring the center of the\n",
    "          image to (1,1).\n",
    "        - Take the FFT of the larger array.\n",
    "        - Extract an ``[upsampled_region_size]`` region of the result, starting\n",
    "          with the ``[axis_offsets+1]`` element.\n",
    "\n",
    "    It achieves this result by computing the DFT in the output array without\n",
    "    the need to zeropad. Much faster and memory efficient than the zero-padded\n",
    "    FFT approach if ``upsampled_region_size`` is much smaller than\n",
    "    ``data.size * upsample_factor``.\n",
    "\n",
    "    Args:\n",
    "        data : 2D ndarray\n",
    "            The input data array (DFT of original data) to upsample.\n",
    "\n",
    "        upsampled_region_size : integer or tuple of integers, optional\n",
    "            The size of the region to be sampled.  If one integer is provided, it\n",
    "            is duplicated up to the dimensionality of ``data``.\n",
    "\n",
    "        upsample_factor : integer, optional\n",
    "            The upsampling factor.  Defaults to 1.\n",
    "\n",
    "        axis_offsets : tuple of integers, optional\n",
    "            The offsets of the region to be sampled.  Defaults to None (uses\n",
    "            image center)\n",
    "\n",
    "    Returns:\n",
    "        output : 2D ndarray\n",
    "                The upsampled DFT of the specified region.\n",
    "    \"\"\"\n",
    "    # if people pass in an integer, expand it to a list of equal-sized sections\n",
    "    if not hasattr(upsampled_region_size, \"__iter__\"):\n",
    "        upsampled_region_size = [upsampled_region_size, ] * data.ndim\n",
    "    else:\n",
    "        if len(upsampled_region_size) != data.ndim:\n",
    "            raise ValueError(\"shape of upsampled region sizes must be equal \"\n",
    "                             \"to input data's number of dimensions.\")\n",
    "\n",
    "    if axis_offsets is None:\n",
    "        axis_offsets = [0, ] * data.ndim\n",
    "    else:\n",
    "        if len(axis_offsets) != data.ndim:\n",
    "            raise ValueError(\"number of axis offsets must be equal to input \"\n",
    "                             \"data's number of dimensions.\")\n",
    "\n",
    "    col_kernel = np.exp(\n",
    "        (-1j * 2 * np.pi / (data.shape[1] * upsample_factor)) *\n",
    "        (ifftshift(np.arange(data.shape[1]))[:, None] -\n",
    "         np.floor(old_div(data.shape[1], 2))).dot(\n",
    "             np.arange(upsampled_region_size[1])[None, :] - axis_offsets[1])\n",
    "    )\n",
    "    row_kernel = np.exp(\n",
    "        (-1j * 2 * np.pi / (data.shape[0] * upsample_factor)) *\n",
    "        (np.arange(upsampled_region_size[0])[:, None] - axis_offsets[0]).dot(\n",
    "            ifftshift(np.arange(data.shape[0]))[None, :] -\n",
    "            np.floor(old_div(data.shape[0], 2)))\n",
    "    )\n",
    "\n",
    "    if data.ndim > 2:\n",
    "        pln_kernel = np.exp(\n",
    "        (-1j * 2 * np.pi / (data.shape[2] * upsample_factor)) *\n",
    "        (np.arange(upsampled_region_size[2])[:, None] - axis_offsets[2]).dot(\n",
    "                ifftshift(np.arange(data.shape[2]))[None, :] -\n",
    "                np.floor(old_div(data.shape[2], 2))))\n",
    "\n",
    "    # output = np.tensordot(np.tensordot(row_kernel,data,axes=[1,0]),col_kernel,axes=[1,0])\n",
    "    output = np.tensordot(row_kernel, data, axes = [1,0])\n",
    "    output = np.tensordot(output, col_kernel, axes = [1,0])\n",
    "\n",
    "    if data.ndim > 2:\n",
    "        output = np.tensordot(output, pln_kernel, axes = [1,1])\n",
    "    #output = row_kernel.dot(data).dot(col_kernel)\n",
    "    return output\n",
    "\n",
    "\n",
    "def _compute_phasediff(cross_correlation_max):\n",
    "    \"\"\"\n",
    "    Compute global phase difference between the two images (should be zero if images are non-negative).\n",
    "\n",
    "    Args:\n",
    "        cross_correlation_max : complex\n",
    "            The complex value of the cross correlation at its maximum point.\n",
    "    \"\"\"\n",
    "    return np.arctan2(cross_correlation_max.imag, cross_correlation_max.real)\n",
    "\n",
    "\n",
    "def _compute_error(cross_correlation_max, src_amp, target_amp):\n",
    "    \"\"\"\n",
    "    Compute RMS error metric between ``src_image`` and ``target_image``.\n",
    "\n",
    "    Args:\n",
    "        cross_correlation_max : complex\n",
    "            The complex value of the cross correlation at its maximum point.\n",
    "\n",
    "        src_amp : float\n",
    "            The normalized average image intensity of the source image\n",
    "\n",
    "        target_amp : float\n",
    "            The normalized average image intensity of the target image\n",
    "    \"\"\"\n",
    "    error = 1.0 - cross_correlation_max * cross_correlation_max.conj() /\\\n",
    "        (src_amp * target_amp)\n",
    "    return np.sqrt(np.abs(error))\n",
    "\n",
    "def init_cuda_process():\n",
    "    \"\"\"\n",
    "    Initialize a PyCUDA context at global scope so that it can be accessed\n",
    "    from processes when using multithreading\n",
    "    \"\"\"\n",
    "    global cudactx\n",
    "\n",
    "    cudadrv.init()\n",
    "    dev = cudadrv.Device(0)\n",
    "    cudactx = dev.make_context() # type: ignore\n",
    "    atexit.register(cudactx.pop) # type: ignore\n",
    "\n",
    "\n",
    "def close_cuda_process(n):\n",
    "    \"\"\"\n",
    "    Cleanup cuda process\n",
    "    \"\"\"\n",
    "\n",
    "    global cudactx\n",
    "\n",
    "    import skcuda.misc as cudamisc\n",
    "    try:\n",
    "        cudamisc.done_context(cudactx) # type: ignore\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "#%%\n",
    "\n",
    "def register_translation_3d(src_image, target_image, upsample_factor = 1,\n",
    "                            space = \"real\", shifts_lb = None, shifts_ub = None,\n",
    "                            max_shifts = [10,10,10]):\n",
    "\n",
    "    \"\"\"\n",
    "    Simple script for registering translation in 3D using an FFT approach.\n",
    "    \n",
    "    Args:\n",
    "        src_image : ndarray\n",
    "            Reference image.\n",
    "\n",
    "        target_image : ndarray\n",
    "            Image to register.  Must be same dimensionality as ``src_image``.\n",
    "\n",
    "        upsample_factor : int, optional\n",
    "            Upsampling factor. Images will be registered to within\n",
    "            ``1 / upsample_factor`` of a pixel. For example\n",
    "            ``upsample_factor == 20`` means the images will be registered\n",
    "            within 1/20th of a pixel.  Default is 1 (no upsampling)\n",
    "\n",
    "        space : string, one of \"real\" or \"fourier\"\n",
    "            Defines how the algorithm interprets input data.  \"real\" means data\n",
    "            will be FFT'd to compute the correlation, while \"fourier\" data will\n",
    "            bypass FFT of input data.  Case insensitive.\n",
    "\n",
    "    Returns:\n",
    "        shifts : ndarray\n",
    "            Shift vector (in pixels) required to register ``target_image`` with\n",
    "            ``src_image``.  Axis ordering is consistent with numpy (e.g. Z, Y, X)\n",
    "\n",
    "        error : float\n",
    "            Translation invariant normalized RMS error between ``src_image`` and\n",
    "            ``target_image``.\n",
    "\n",
    "        phasediff : float\n",
    "            Global phase difference between the two images (should be\n",
    "            zero if images are non-negative).\n",
    "\n",
    "    Raises:\n",
    "     NotImplementedError \"Error: register_translation_3d only supports \"\n",
    "                                  \"subpixel registration for 3D images\"\n",
    "\n",
    "     ValueError \"Error: images must really be same size for \"\n",
    "                         \"register_translation_3d\"\n",
    "\n",
    "     ValueError \"Error: register_translation_3d only knows the \\\"real\\\" \"\n",
    "                         \"and \\\"fourier\\\" values for the ``space`` argument.\"\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    # images must be the same shape\n",
    "    if src_image.shape != target_image.shape:\n",
    "        raise ValueError(\"Error: images must really be same size for \"\n",
    "                         \"register_translation_3d\")\n",
    "\n",
    "    # only 3D data makes sense right now\n",
    "    if src_image.ndim != 3 and upsample_factor > 1:\n",
    "        raise NotImplementedError(\"Error: register_translation_3d only supports \"\n",
    "                                  \"subpixel registration for 3D images\")\n",
    "\n",
    "    # assume complex data is already in Fourier space\n",
    "    if space.lower() == 'fourier':\n",
    "        src_freq = src_image\n",
    "        target_freq = target_image\n",
    "    # real data needs to be fft'd.\n",
    "    elif space.lower() == 'real':\n",
    "        src_image_cpx = np.array(\n",
    "            src_image, dtype=np.complex64, copy=False)\n",
    "        target_image_cpx = np.array(\n",
    "            target_image, dtype=np.complex64, copy=False)\n",
    "        src_freq = np.fft.fftn(src_image_cpx)\n",
    "        target_freq = np.fft.fftn(target_image_cpx)\n",
    "    else:\n",
    "        raise ValueError(\"Error: register_translation_3d only knows the \\\"real\\\" \"\n",
    "                         \"and \\\"fourier\\\" values for the ``space`` argument.\")\n",
    "\n",
    "    shape = src_freq.shape\n",
    "    image_product = src_freq * target_freq.conj()\n",
    "    cross_correlation = np.fft.ifftn(image_product)\n",
    "#    cross_correlation = ifftn(image_product) # TODO CHECK why this line is different\n",
    "    new_cross_corr = np.abs(cross_correlation)\n",
    "\n",
    "    CCmax = cross_correlation.max()\n",
    "\n",
    "    del cross_correlation\n",
    "\n",
    "    if (shifts_lb is not None) or (shifts_ub is not None):\n",
    "\n",
    "        if (shifts_lb[0] < 0) and (shifts_ub[0] >= 0):\n",
    "            new_cross_corr[shifts_ub[0]:shifts_lb[0], :, :] = 0\n",
    "        else:\n",
    "            new_cross_corr[:shifts_lb[0], :, :] = 0\n",
    "            new_cross_corr[shifts_ub[0]:, :, :] = 0\n",
    "\n",
    "        if (shifts_lb[1] < 0) and (shifts_ub[1] >= 0):\n",
    "            new_cross_corr[:, shifts_ub[1]:shifts_lb[1], :] = 0\n",
    "        else:\n",
    "            new_cross_corr[:, :shifts_lb[1], :] = 0\n",
    "            new_cross_corr[:, shifts_ub[1]:, :] = 0\n",
    "\n",
    "        if (shifts_lb[2] < 0) and (shifts_ub[2] >= 0):\n",
    "            new_cross_corr[:, :, shifts_ub[2]:shifts_lb[2]] = 0\n",
    "        else:\n",
    "            new_cross_corr[:, :, :shifts_lb[2]] = 0\n",
    "            new_cross_corr[:, :, shifts_ub[2]:] = 0\n",
    "    else:\n",
    "        new_cross_corr[max_shifts[0]:-max_shifts[0], :, :] = 0\n",
    "        new_cross_corr[:, max_shifts[1]:-max_shifts[1], :] = 0\n",
    "        new_cross_corr[:, :, max_shifts[2]:-max_shifts[2]] = 0\n",
    "\n",
    "    maxima = np.unravel_index(np.argmax(new_cross_corr), new_cross_corr.shape)\n",
    "    midpoints = np.array([np.fix(axis_size//2) for axis_size in shape])\n",
    "\n",
    "#    maxima = np.unravel_index(np.argmax(new_cross_corr),cross_correlation.shape)\n",
    "#    midpoints = np.array([np.fix(old_div(axis_size, 2)) for axis_size in shape])\n",
    "\n",
    "    shifts = np.array(maxima, dtype=np.float32)\n",
    "    shifts[shifts > midpoints] -= np.array(shape)[shifts > midpoints]\n",
    "\n",
    "\n",
    "    if upsample_factor > 1:\n",
    "\n",
    "        shifts = old_div(np.round(shifts * upsample_factor), upsample_factor)\n",
    "        upsampled_region_size = np.ceil(upsample_factor * 1.5)\n",
    "        # Center of output array at dftshift + 1\n",
    "        dftshift = np.fix(old_div(upsampled_region_size, 2.0))\n",
    "        upsample_factor = np.array(upsample_factor, dtype=np.float64)\n",
    "        normalization = (src_freq.size * upsample_factor ** 2)\n",
    "        # Matrix multiply DFT around the current shift estimate\n",
    "        sample_region_offset = dftshift - shifts * upsample_factor\n",
    "\n",
    "        cross_correlation = _upsampled_dft(image_product.conj(),\n",
    "                                           upsampled_region_size,\n",
    "                                           upsample_factor,\n",
    "                                           sample_region_offset).conj()\n",
    "        cross_correlation /= normalization\n",
    "        # Locate maximum and map back to original pixel grid\n",
    "        maxima = np.array(np.unravel_index(\n",
    "            np.argmax(np.abs(cross_correlation)),\n",
    "            cross_correlation.shape),\n",
    "            dtype=np.float64)\n",
    "        maxima -= dftshift\n",
    "        shifts = shifts + old_div(maxima, upsample_factor)\n",
    "        CCmax = cross_correlation.max()\n",
    "\n",
    "    for dim in range(src_freq.ndim):\n",
    "        if shape[dim] == 1:\n",
    "            shifts[dim] = 0\n",
    "\n",
    "    return shifts, src_freq, _compute_phasediff(CCmax)\n",
    "\n",
    "#%%\n",
    "\n",
    "def register_translation(src_image, target_image, upsample_factor=1,\n",
    "                         space=\"real\", shifts_lb=None, shifts_ub=None, max_shifts=(10, 10),\n",
    "                         use_cuda=False):\n",
    "    \"\"\"\n",
    "\n",
    "    adapted from SIMA (https://github.com/losonczylab) and the\n",
    "    scikit-image (http://scikit-image.org/) package.\n",
    "\n",
    "\n",
    "    Unless otherwise specified by LICENSE.txt files in individual\n",
    "    directories, all code is\n",
    "\n",
    "    Copyright (C) 2011, the scikit-image team\n",
    "    All rights reserved.\n",
    "\n",
    "    Redistribution and use in source and binary forms, with or without\n",
    "    modification, are permitted provided that the following conditions are\n",
    "    met:\n",
    "\n",
    "     1. Redistributions of source code must retain the above copyright\n",
    "        notice, this list of conditions and the following disclaimer.\n",
    "     2. Redistributions in binary form must reproduce the above copyright\n",
    "        notice, this list of conditions and the following disclaimer in\n",
    "        the documentation and/or other materials provided with the\n",
    "        distribution.\n",
    "     3. Neither the name of skimage nor the names of its contributors may be\n",
    "        used to endorse or promote products derived from this software without\n",
    "        specific prior written permission.\n",
    "\n",
    "    THIS SOFTWARE IS PROVIDED BY THE AUTHOR ``AS IS'' AND ANY EXPRESS OR\n",
    "    IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED\n",
    "    WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE\n",
    "    DISCLAIMED. IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR ANY DIRECT,\n",
    "    INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES\n",
    "    (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR\n",
    "    SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION)\n",
    "    HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT,\n",
    "    STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING\n",
    "    IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE\n",
    "    POSSIBILITY OF SUCH DAMAGE.\n",
    "    Efficient subpixel image translation registration by cross-correlation.\n",
    "\n",
    "    This code gives the same precision as the FFT upsampled cross-correlation\n",
    "    in a fraction of the computation time and with reduced memory requirements.\n",
    "    It obtains an initial estimate of the cross-correlation peak by an FFT and\n",
    "    then refines the shift estimation by upsampling the DFT only in a small\n",
    "    neighborhood of that estimate by means of a matrix-multiply DFT.\n",
    "\n",
    "    Args:\n",
    "        src_image : ndarray\n",
    "            Reference image.\n",
    "\n",
    "        target_image : ndarray\n",
    "            Image to register.  Must be same dimensionality as ``src_image``.\n",
    "\n",
    "        upsample_factor : int, optional\n",
    "            Upsampling factor. Images will be registered to within\n",
    "            ``1 / upsample_factor`` of a pixel. For example\n",
    "            ``upsample_factor == 20`` means the images will be registered\n",
    "            within 1/20th of a pixel.  Default is 1 (no upsampling)\n",
    "\n",
    "        space : string, one of \"real\" or \"fourier\"\n",
    "            Defines how the algorithm interprets input data.  \"real\" means data\n",
    "            will be FFT'd to compute the correlation, while \"fourier\" data will\n",
    "            bypass FFT of input data.  Case insensitive.\n",
    "\n",
    "        use_cuda : bool, optional\n",
    "            Use skcuda.fft (if available). Default: False\n",
    "\n",
    "    Returns:\n",
    "        shifts : ndarray\n",
    "            Shift vector (in pixels) required to register ``target_image`` with\n",
    "            ``src_image``.  Axis ordering is consistent with numpy (e.g. Z, Y, X)\n",
    "\n",
    "        error : float\n",
    "            Translation invariant normalized RMS error between ``src_image`` and\n",
    "            ``target_image``.\n",
    "\n",
    "        phasediff : float\n",
    "            Global phase difference between the two images (should be\n",
    "            zero if images are non-negative).\n",
    "\n",
    "    Raises:\n",
    "     NotImplementedError \"Error: register_translation only supports \"\n",
    "                                  \"subpixel registration for 2D images\"\n",
    "\n",
    "     ValueError \"Error: images must really be same size for \"\n",
    "                         \"register_translation\"\n",
    "\n",
    "     ValueError \"Error: register_translation only knows the \\\"real\\\" \"\n",
    "                         \"and \\\"fourier\\\" values for the ``space`` argument.\"\n",
    "\n",
    "    References:\n",
    "    .. [1] Manuel Guizar-Sicairos, Samuel T. Thurman, and James R. Fienup,\n",
    "           \"Efficient subpixel image registration algorithms,\"\n",
    "           Optics Letters 33, 156-158 (2008).\n",
    "    \"\"\"\n",
    "    # images must be the same shape\n",
    "    if src_image.shape != target_image.shape:\n",
    "        raise ValueError(\"Error: images must really be same size for \"\n",
    "                         \"register_translation\")\n",
    "\n",
    "    # only 2D data makes sense right now\n",
    "    if src_image.ndim != 2 and upsample_factor > 1:\n",
    "        raise NotImplementedError(\"Error: register_translation only supports \"\n",
    "                                  \"subpixel registration for 2D images\")\n",
    "\n",
    "    if HAS_CUDA and use_cuda:\n",
    "        from skcuda.fft import Plan\n",
    "        from skcuda.fft import fft as cudafft\n",
    "        from skcuda.fft import ifft as cudaifft\n",
    "        try:\n",
    "            cudactx # type: ignore\n",
    "        except NameError:\n",
    "            init_cuda_process()\n",
    "\n",
    "    # assume complex data is already in Fourier space\n",
    "    if space.lower() == 'fourier':\n",
    "        src_freq = src_image\n",
    "        target_freq = target_image\n",
    "    # real data needs to be fft'd.\n",
    "    elif space.lower() == 'real':\n",
    "        if HAS_CUDA and use_cuda:\n",
    "            # src_image_cpx = np.array(src_image, dtype=np.complex128, copy=False)\n",
    "            # target_image_cpx = np.array(target_image, dtype=np.complex128, copy=False)\n",
    "\n",
    "            image_gpu = gpuarray.to_gpu(np.stack((src_image, target_image)).astype(np.complex128))\n",
    "            freq_gpu = gpuarray.empty((2, src_image.shape[0], src_image.shape[1]), dtype=np.complex128)\n",
    "            # src_image_gpu = gpuarray.to_gpu(src_image_cpx)\n",
    "            # src_freq_gpu = gpuarray.empty(src_image_cpx.shape, np.complex128)\n",
    "\n",
    "            # target_image_gpu = gpuarray.to_gpu(target_image_cpx)\n",
    "            # target_freq_gpu = gpuarray.empty(target_image_cpx.shape, np.complex128)\n",
    "\n",
    "            plan = Plan(src_image.shape, np.complex128, np.complex128, batch=2)\n",
    "            # cudafft(src_image_gpu, src_freq_gpu, plan, scale=True)\n",
    "            # cudafft(target_image_gpu, target_freq_gpu, plan, scale=True)\n",
    "            cudafft(image_gpu, freq_gpu, plan, scale=True)\n",
    "            # src_freq = src_freq_gpu.get()\n",
    "            # target_freq = target_freq_gpu.get()\n",
    "            freq = freq_gpu.get()\n",
    "            src_freq = freq[0, :, :]\n",
    "            target_freq = freq[1, :, :]\n",
    "\n",
    "            # del(src_image_gpu)\n",
    "            # del(src_freq_gpu)\n",
    "            # del(target_image_gpu)\n",
    "            # del(target_freq_gpu)\n",
    "            del(image_gpu)\n",
    "            del(freq_gpu)\n",
    "        elif opencv:\n",
    "            src_freq_1 = fftn(\n",
    "                src_image, flags=cv2.DFT_COMPLEX_OUTPUT + cv2.DFT_SCALE)\n",
    "            src_freq = src_freq_1[:, :, 0] + 1j * src_freq_1[:, :, 1]\n",
    "            src_freq = np.array(src_freq, dtype=np.complex128, copy=False)\n",
    "            target_freq_1 = fftn(\n",
    "                target_image, flags=cv2.DFT_COMPLEX_OUTPUT + cv2.DFT_SCALE)\n",
    "            target_freq = target_freq_1[:, :, 0] + 1j * target_freq_1[:, :, 1]\n",
    "            target_freq = np.array(\n",
    "                target_freq, dtype=np.complex128, copy=False)\n",
    "        else:\n",
    "            src_image_cpx = np.array(\n",
    "                src_image, dtype=np.complex128, copy=False)\n",
    "            target_image_cpx = np.array(\n",
    "                target_image, dtype=np.complex128, copy=False)\n",
    "            src_freq = np.fft.fftn(src_image_cpx)\n",
    "            target_freq = np.fft.fftn(target_image_cpx)\n",
    "\n",
    "    else:\n",
    "        raise ValueError(\"Error: register_translation only knows the \\\"real\\\" \"\n",
    "                         \"and \\\"fourier\\\" values for the ``space`` argument.\")\n",
    "\n",
    "    # Whole-pixel shift - Compute cross-correlation by an IFFT\n",
    "    shape = src_freq.shape\n",
    "    image_product = src_freq * target_freq.conj()\n",
    "    if HAS_CUDA and use_cuda:\n",
    "        image_product_gpu = gpuarray.to_gpu(image_product)\n",
    "        cross_correlation_gpu = gpuarray.empty(\n",
    "            image_product.shape, np.complex128)\n",
    "        iplan = Plan(image_product.shape, np.complex128, np.complex128)\n",
    "        cudaifft(image_product_gpu, cross_correlation_gpu, iplan, scale=True)\n",
    "        cross_correlation = cross_correlation_gpu.get()\n",
    "    elif opencv:\n",
    "\n",
    "        image_product_cv = np.dstack(\n",
    "            [np.real(image_product), np.imag(image_product)])\n",
    "        cross_correlation = fftn(\n",
    "            image_product_cv, flags=cv2.DFT_INVERSE + cv2.DFT_SCALE)\n",
    "        cross_correlation = cross_correlation[:,\n",
    "                                              :, 0] + 1j * cross_correlation[:, :, 1]\n",
    "    else:\n",
    "        cross_correlation = ifftn(image_product)\n",
    "\n",
    "    # Locate maximum\n",
    "    new_cross_corr = np.abs(cross_correlation)\n",
    "\n",
    "    if (shifts_lb is not None) or (shifts_ub is not None):\n",
    "\n",
    "        if (shifts_lb[0] < 0) and (shifts_ub[0] >= 0):\n",
    "            new_cross_corr[shifts_ub[0]:shifts_lb[0], :] = 0\n",
    "        else:\n",
    "            new_cross_corr[:shifts_lb[0], :] = 0\n",
    "            new_cross_corr[shifts_ub[0]:, :] = 0\n",
    "\n",
    "        if (shifts_lb[1] < 0) and (shifts_ub[1] >= 0):\n",
    "            new_cross_corr[:, shifts_ub[1]:shifts_lb[1]] = 0\n",
    "        else:\n",
    "            new_cross_corr[:, :shifts_lb[1]] = 0\n",
    "            new_cross_corr[:, shifts_ub[1]:] = 0\n",
    "    else:\n",
    "\n",
    "        new_cross_corr[max_shifts[0]:-max_shifts[0], :] = 0\n",
    "\n",
    "        new_cross_corr[:, max_shifts[1]:-max_shifts[1]] = 0\n",
    "\n",
    "    maxima = np.unravel_index(np.argmax(new_cross_corr),\n",
    "                              cross_correlation.shape)\n",
    "    midpoints = np.array([np.fix(old_div(axis_size, 2))\n",
    "                          for axis_size in shape])\n",
    "\n",
    "    shifts = np.array(maxima, dtype=np.float64)\n",
    "    shifts[shifts > midpoints] -= np.array(shape)[shifts > midpoints]\n",
    "\n",
    "    if upsample_factor == 1:\n",
    "\n",
    "        src_amp = old_div(np.sum(np.abs(src_freq) ** 2), src_freq.size)\n",
    "        target_amp = old_div(\n",
    "            np.sum(np.abs(target_freq) ** 2), target_freq.size)\n",
    "        CCmax = cross_correlation.max()\n",
    "    # If upsampling > 1, then refine estimate with matrix multiply DFT\n",
    "    else:\n",
    "        # Initial shift estimate in upsampled grid\n",
    "        shifts = old_div(np.round(shifts * upsample_factor), upsample_factor)\n",
    "        upsampled_region_size = np.ceil(upsample_factor * 1.5)\n",
    "        # Center of output array at dftshift + 1\n",
    "        dftshift = np.fix(old_div(upsampled_region_size, 2.0))\n",
    "        upsample_factor = np.array(upsample_factor, dtype=np.float64)\n",
    "        normalization = (src_freq.size * upsample_factor ** 2)\n",
    "        # Matrix multiply DFT around the current shift estimate\n",
    "        sample_region_offset = dftshift - shifts * upsample_factor\n",
    "\n",
    "        cross_correlation = _upsampled_dft(image_product.conj(),\n",
    "                                           upsampled_region_size,\n",
    "                                           upsample_factor,\n",
    "                                           sample_region_offset).conj()\n",
    "        cross_correlation /= normalization\n",
    "        # Locate maximum and map back to original pixel grid\n",
    "        maxima = np.array(np.unravel_index(\n",
    "            np.argmax(np.abs(cross_correlation)),\n",
    "            cross_correlation.shape),\n",
    "            dtype=np.float64)\n",
    "        maxima -= dftshift\n",
    "        shifts = shifts + old_div(maxima, upsample_factor)\n",
    "        CCmax = cross_correlation.max()\n",
    "        src_amp = _upsampled_dft(src_freq * src_freq.conj(),\n",
    "                                 1, upsample_factor)[0, 0]\n",
    "        src_amp /= normalization\n",
    "        target_amp = _upsampled_dft(target_freq * target_freq.conj(),\n",
    "                                    1, upsample_factor)[0, 0]\n",
    "        target_amp /= normalization\n",
    "\n",
    "    # If its only one row or column the shift along that dimension has no\n",
    "    # effect. We set to zero.\n",
    "    for dim in range(src_freq.ndim):\n",
    "        if shape[dim] == 1:\n",
    "            shifts[dim] = 0\n",
    "\n",
    "    return shifts, src_freq, _compute_phasediff(CCmax)\n",
    "\n",
    "#%%\n",
    "\n",
    "def apply_shifts_dft(src_freq, shifts, diffphase, is_freq=True, border_nan=True):\n",
    "    \"\"\"\n",
    "    adapted from SIMA (https://github.com/losonczylab) and the\n",
    "    scikit-image (http://scikit-image.org/) package.\n",
    "\n",
    "\n",
    "    Unless otherwise specified by LICENSE.txt files in individual\n",
    "    directories, all code is\n",
    "\n",
    "    Copyright (C) 2011, the scikit-image team\n",
    "    All rights reserved.\n",
    "\n",
    "    Redistribution and use in source and binary forms, with or without\n",
    "    modification, are permitted provided that the following conditions are\n",
    "    met:\n",
    "\n",
    "     1. Redistributions of source code must retain the above copyright\n",
    "        notice, this list of conditions and the following disclaimer.\n",
    "     2. Redistributions in binary form must reproduce the above copyright\n",
    "        notice, this list of conditions and the following disclaimer in\n",
    "        the documentation and/or other materials provided with the\n",
    "        distribution.\n",
    "     3. Neither the name of skimage nor the names of its contributors may be\n",
    "        used to endorse or promote products derived from this software without\n",
    "        specific prior written permission.\n",
    "\n",
    "    THIS SOFTWARE IS PROVIDED BY THE AUTHOR ``AS IS'' AND ANY EXPRESS OR\n",
    "    IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED\n",
    "    WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE\n",
    "    DISCLAIMED. IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR ANY DIRECT,\n",
    "    INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES\n",
    "    (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR\n",
    "    SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION)\n",
    "    HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT,\n",
    "    STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING\n",
    "    IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE\n",
    "    POSSIBILITY OF SUCH DAMAGE.\n",
    "    Args:\n",
    "        apply shifts using inverse dft\n",
    "        src_freq: ndarray\n",
    "            if is_freq it is fourier transform image else original image\n",
    "        shifts: shifts to apply\n",
    "        diffphase: comes from the register_translation output\n",
    "    \"\"\"\n",
    "\n",
    "    is3D = len(src_freq.shape) == 3\n",
    "    if not is_freq:\n",
    "        if is3D:\n",
    "            src_freq = np.fft.fftn(src_freq)\n",
    "        else:\n",
    "            src_freq = np.dstack([np.real(src_freq), np.imag(src_freq)])\n",
    "            src_freq = fftn(src_freq, flags=cv2.DFT_COMPLEX_OUTPUT + cv2.DFT_SCALE)\n",
    "            src_freq = src_freq[:, :, 0] + 1j * src_freq[:, :, 1]\n",
    "            src_freq = np.array(src_freq, dtype=np.complex128, copy=False)\n",
    "\n",
    "    if not is3D:\n",
    "        shifts = shifts[::-1]\n",
    "        nc, nr = np.shape(src_freq)\n",
    "        Nr = ifftshift(np.arange(-np.fix(nr/2.), np.ceil(nr/2.)))\n",
    "        Nc = ifftshift(np.arange(-np.fix(nc/2.), np.ceil(nc/2.)))\n",
    "        Nr, Nc = np.meshgrid(Nr, Nc)\n",
    "        Greg = src_freq * np.exp(1j * 2 * np.pi *\n",
    "                                 (-shifts[0] * 1. * Nr / nr - shifts[1] * 1. * Nc / nc))\n",
    "    else:\n",
    "        #shifts = np.array([*shifts[:-1][::-1],shifts[-1]])\n",
    "        shifts = np.array(list(shifts[:-1][::-1]) + [shifts[-1]])\n",
    "        nc, nr, nd = np.array(np.shape(src_freq), dtype=float)\n",
    "        Nr = ifftshift(np.arange(-np.fix(nr / 2.), np.ceil(nr / 2.)))\n",
    "        Nc = ifftshift(np.arange(-np.fix(nc / 2.), np.ceil(nc / 2.)))\n",
    "        Nd = ifftshift(np.arange(-np.fix(nd / 2.), np.ceil(nd / 2.)))\n",
    "        Nr, Nc, Nd = np.meshgrid(Nr, Nc, Nd)\n",
    "        Greg = src_freq * np.exp(-1j * 2 * np.pi *\n",
    "                                 (-shifts[0] * Nr / nr - shifts[1] * Nc / nc -\n",
    "                                  shifts[2] * Nd / nd))\n",
    "\n",
    "    Greg = Greg.dot(np.exp(1j * diffphase))\n",
    "    if is3D:\n",
    "        new_img = np.real(np.fft.ifftn(Greg))\n",
    "    else:\n",
    "        Greg = np.dstack([np.real(Greg), np.imag(Greg)])\n",
    "        new_img = ifftn(Greg)[:, :, 0]\n",
    "\n",
    "    if border_nan is not False:\n",
    "        max_w, max_h, min_w, min_h = 0, 0, 0, 0\n",
    "        max_h, max_w = np.ceil(np.maximum(\n",
    "            (max_h, max_w), shifts[:2])).astype(np.int)\n",
    "        min_h, min_w = np.floor(np.minimum(\n",
    "            (min_h, min_w), shifts[:2])).astype(np.int)\n",
    "        if is3D:\n",
    "            max_d = np.ceil(np.maximum(0, shifts[2])).astype(np.int)\n",
    "            min_d = np.floor(np.minimum(0, shifts[2])).astype(np.int)\n",
    "        if border_nan is True:\n",
    "            new_img[:max_h, :] = np.nan\n",
    "            if min_h < 0:\n",
    "                new_img[min_h:, :] = np.nan\n",
    "            new_img[:, :max_w] = np.nan\n",
    "            if min_w < 0:\n",
    "                new_img[:, min_w:] = np.nan\n",
    "            if is3D:\n",
    "                new_img[:, :, :max_d] = np.nan\n",
    "                if min_d < 0:\n",
    "                    new_img[:, :, min_d:] = np.nan\n",
    "        elif border_nan == 'min':\n",
    "            min_ = np.nanmin(new_img)\n",
    "            new_img[:max_h, :] = min_\n",
    "            if min_h < 0:\n",
    "                new_img[min_h:, :] = min_\n",
    "            new_img[:, :max_w] = min_\n",
    "            if min_w < 0:\n",
    "                new_img[:, min_w:] = min_\n",
    "            if is3D:\n",
    "                new_img[:, :, :max_d] = min_\n",
    "                if min_d < 0:\n",
    "                    new_img[:, :, min_d:] = min_\n",
    "        elif border_nan == 'copy':\n",
    "            new_img[:max_h] = new_img[max_h]\n",
    "            if min_h < 0:\n",
    "                new_img[min_h:] = new_img[min_h-1]\n",
    "            if max_w > 0:\n",
    "                new_img[:, :max_w] = new_img[:, max_w, np.newaxis]\n",
    "            if min_w < 0:\n",
    "                new_img[:, min_w:] = new_img[:, min_w-1, np.newaxis]\n",
    "            if is3D:\n",
    "                if max_d > 0:\n",
    "                    new_img[:, :, :max_d] = new_img[:, :, max_d, np.newaxis]\n",
    "                if min_d < 0:\n",
    "                    new_img[:, :, min_d:] = new_img[:, :, min_d-1, np.newaxis]\n",
    "\n",
    "    return new_img\n",
    "\n",
    "\n",
    "#%%\n",
    "def sliding_window(image, overlaps, strides):\n",
    "    \"\"\" efficiently and lazily slides a window across the image\n",
    "\n",
    "    Args: \n",
    "        img:ndarray 2D\n",
    "            image that needs to be slices\n",
    "\n",
    "        windowSize: tuple\n",
    "            dimension of the patch\n",
    "\n",
    "        strides: tuple\n",
    "            stride in each dimension\n",
    "\n",
    "     Returns:\n",
    "         iterator containing five items\n",
    "              dim_1, dim_2 coordinates in the patch grid\n",
    "              x, y: bottom border of the patch in the original matrix\n",
    "\n",
    "              patch: the patch\n",
    "     \"\"\"\n",
    "    windowSize = np.add(overlaps, strides)\n",
    "    range_1 = list(range(\n",
    "        0, image.shape[0] - windowSize[0], strides[0])) + [image.shape[0] - windowSize[0]]\n",
    "    range_2 = list(range(\n",
    "        0, image.shape[1] - windowSize[1], strides[1])) + [image.shape[1] - windowSize[1]]\n",
    "    for dim_1, x in enumerate(range_1):\n",
    "        for dim_2, y in enumerate(range_2):\n",
    "            # yield the current window\n",
    "            yield (dim_1, dim_2, x, y, image[x:x + windowSize[0], y:y + windowSize[1]])\n",
    "\n",
    "def sliding_window_3d(image, overlaps, strides):\n",
    "    \"\"\" efficiently and lazily slides a window across the image\n",
    "\n",
    "    Args: \n",
    "        img:ndarray 3D\n",
    "            image that needs to be slices\n",
    "\n",
    "        windowSize: tuple\n",
    "            dimension of the patch\n",
    "\n",
    "        strides: tuple\n",
    "            stride in each dimension\n",
    "\n",
    "     Returns:\n",
    "         iterator containing seven items\n",
    "              dim_1, dim_2, dim_3 coordinates in the patch grid\n",
    "              x, y, z: bottom border of the patch in the original matrix\n",
    "\n",
    "              patch: the patch\n",
    "     \"\"\"\n",
    "    windowSize = np.add(overlaps, strides)\n",
    "    range_1 = list(range(\n",
    "        0, image.shape[0] - windowSize[0], strides[0])) + [image.shape[0] - windowSize[0]]\n",
    "    range_2 = list(range(\n",
    "        0, image.shape[1] - windowSize[1], strides[1])) + [image.shape[1] - windowSize[1]]\n",
    "    range_3 = list(range(\n",
    "        0, image.shape[2] - windowSize[2], strides[2])) + [image.shape[2] - windowSize[2]]\n",
    "    for dim_1, x in enumerate(range_1):\n",
    "        for dim_2, y in enumerate(range_2):\n",
    "            for dim_3, z in enumerate(range_3):\n",
    "                # yield the current window\n",
    "                yield (dim_1, dim_2, dim_3, x, y, z, image[x:x + windowSize[0], y:y + windowSize[1], z:z + windowSize[2]])\n",
    "\n",
    "def iqr(a):\n",
    "    return np.percentile(a, 75) - np.percentile(a, 25)\n",
    "\n",
    "def create_weight_matrix_for_blending(img, overlaps, strides):\n",
    "    \"\"\" create a matrix that is used to normalize the intersection of the stiched patches\n",
    "\n",
    "    Args:\n",
    "        img: original image, ndarray\n",
    "\n",
    "        shapes, overlaps, strides:  tuples\n",
    "            shapes, overlaps and strides of the patches\n",
    "\n",
    "    Returns:\n",
    "        weight_mat: normalizing weight matrix\n",
    "    \"\"\"\n",
    "    shapes = np.add(strides, overlaps)\n",
    "\n",
    "    max_grid_1, max_grid_2 = np.max(\n",
    "        np.array([it[:2] for it in sliding_window(img, overlaps, strides)]), 0)\n",
    "\n",
    "    for grid_1, grid_2, _, _, _ in sliding_window(img, overlaps, strides):\n",
    "\n",
    "        weight_mat = np.ones(shapes)\n",
    "\n",
    "        if grid_1 > 0:\n",
    "            weight_mat[:overlaps[0], :] = np.linspace(\n",
    "                0, 1, overlaps[0])[:, None]\n",
    "        if grid_1 < max_grid_1:\n",
    "            weight_mat[-overlaps[0]:,\n",
    "                       :] = np.linspace(1, 0, overlaps[0])[:, None]\n",
    "        if grid_2 > 0:\n",
    "            weight_mat[:, :overlaps[1]] = weight_mat[:, :overlaps[1]\n",
    "                                                     ] * np.linspace(0, 1, overlaps[1])[None, :]\n",
    "        if grid_2 < max_grid_2:\n",
    "            weight_mat[:, -overlaps[1]:] = weight_mat[:, -\n",
    "                                                      overlaps[1]:] * np.linspace(1, 0, overlaps[1])[None, :]\n",
    "\n",
    "        yield weight_mat\n",
    "\n",
    "def high_pass_filter_space(img_orig, gSig_filt=None, freq=None, order=None):\n",
    "    \"\"\"\n",
    "    Function for high passing the image(s) with centered Gaussian if gSig_filt\n",
    "    is specified or Butterworth filter if freq and order are specified\n",
    "\n",
    "    Args:\n",
    "        img_orig: 2-d or 3-d array\n",
    "            input image/movie\n",
    "\n",
    "        gSig_filt:\n",
    "            size of the Gaussian filter \n",
    "\n",
    "        freq: float\n",
    "            cutoff frequency of the Butterworth filter\n",
    "\n",
    "        order: int\n",
    "            order of the Butterworth filter\n",
    "\n",
    "    Returns:\n",
    "        img: 2-d array or 3-d movie\n",
    "            image/movie after filtering            \n",
    "    \"\"\"\n",
    "    if freq is None or order is None:  # Gaussian\n",
    "        ksize = tuple([(3 * i) // 2 * 2 + 1 for i in gSig_filt])\n",
    "        ker = cv2.getGaussianKernel(ksize[0], gSig_filt[0])\n",
    "        ker2D = ker.dot(ker.T)\n",
    "        nz = np.nonzero(ker2D >= ker2D[:, 0].max())\n",
    "        zz = np.nonzero(ker2D < ker2D[:, 0].max())\n",
    "        ker2D[nz] -= ker2D[nz].mean()\n",
    "        ker2D[zz] = 0\n",
    "        if img_orig.ndim == 2:  # image\n",
    "            return cv2.filter2D(np.array(img_orig, dtype=np.float32),\n",
    "                                -1, ker2D, borderType=cv2.BORDER_REFLECT)\n",
    "        else:  # movie\n",
    "            return cm.movie(np.array([cv2.filter2D(np.array(img, dtype=np.float32),\n",
    "                                -1, ker2D, borderType=cv2.BORDER_REFLECT) for img in img_orig]))     \n",
    "    else:  # Butterworth\n",
    "        rows, cols = img_orig.shape[-2:]\n",
    "        xx, yy = np.meshgrid(np.arange(cols, dtype=np.float32) - cols / 2,\n",
    "                             np.arange(rows, dtype=np.float32) - rows / 2, sparse=True)\n",
    "        H = np.fft.ifftshift(1 - 1 / (1 + ((xx**2 + yy**2)/freq**2)**order))\n",
    "        if img_orig.ndim == 2:  # image\n",
    "            return cv2.idft(cv2.dft(img_orig, flags=cv2.DFT_COMPLEX_OUTPUT) *\n",
    "                            H[..., None])[..., 0] / (rows*cols)\n",
    "        else:  # movie\n",
    "            return cm.movie(np.array([cv2.idft(cv2.dft(img, flags=cv2.DFT_COMPLEX_OUTPUT) * \n",
    "                            H[..., None])[..., 0] for img in img_orig]) / (rows*cols))\n",
    "\n",
    "def tile_and_correct(img, template, strides, overlaps, max_shifts, newoverlaps=None, newstrides=None, upsample_factor_grid=4,\n",
    "                     upsample_factor_fft=10, show_movie=False, max_deviation_rigid=2, add_to_movie=0, shifts_opencv=False, gSig_filt=None,\n",
    "                     use_cuda=False, border_nan=True):\n",
    "    \"\"\" perform piecewise rigid motion correction iteration, by\n",
    "        1) dividing the FOV in patches\n",
    "        2) motion correcting each patch separately\n",
    "        3) upsampling the motion correction vector field\n",
    "        4) stiching back together the corrected subpatches\n",
    "\n",
    "    Args:\n",
    "        img: ndaarray 2D\n",
    "            image to correct\n",
    "\n",
    "        template: ndarray\n",
    "            reference image\n",
    "\n",
    "        strides: tuple\n",
    "            strides of the patches in which the FOV is subdivided\n",
    "\n",
    "        overlaps: tuple\n",
    "            amount of pixel overlaping between patches along each dimension\n",
    "\n",
    "        max_shifts: tuple\n",
    "            max shifts in x and y\n",
    "\n",
    "        newstrides:tuple\n",
    "            strides between patches along each dimension when upsampling the vector fields\n",
    "\n",
    "        newoverlaps:tuple\n",
    "            amount of pixel overlaping between patches along each dimension when upsampling the vector fields\n",
    "\n",
    "        upsample_factor_grid: int\n",
    "            if newshapes or newstrides are not specified this is inferred upsampling by a constant factor the cvector field\n",
    "\n",
    "        upsample_factor_fft: int\n",
    "            resolution of fractional shifts\n",
    "\n",
    "        show_movie: boolean whether to visualize the original and corrected frame during motion correction\n",
    "\n",
    "        max_deviation_rigid: int\n",
    "            maximum deviation in shifts of each patch from the rigid shift (should not be large)\n",
    "\n",
    "        add_to_movie: if movie is too negative the correction might have some issues. In this case it is good to add values so that it is non negative most of the times\n",
    "\n",
    "        filt_sig_size: tuple\n",
    "            standard deviation and size of gaussian filter to center filter data in case of one photon imaging data\n",
    "\n",
    "        use_cuda : bool, optional\n",
    "            Use skcuda.fft (if available). Default: False\n",
    "\n",
    "        border_nan : bool or string, optional\n",
    "            specifies how to deal with borders. (True, False, 'copy', 'min')\n",
    "\n",
    "    Returns:\n",
    "        (new_img, total_shifts, start_step, xy_grid)\n",
    "            new_img: ndarray, corrected image\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    img = img.astype(np.float64).copy()\n",
    "    template = template.astype(np.float64).copy()\n",
    "\n",
    "    if gSig_filt is not None:\n",
    "\n",
    "        img_orig = img.copy()\n",
    "        img = high_pass_filter_space(img_orig, gSig_filt)\n",
    "\n",
    "    img = img + add_to_movie\n",
    "    template = template + add_to_movie\n",
    "\n",
    "    # compute rigid shifts\n",
    "    rigid_shts, sfr_freq, diffphase = register_translation(\n",
    "        img, template, upsample_factor=upsample_factor_fft, max_shifts=max_shifts, use_cuda=use_cuda)\n",
    "\n",
    "    if max_deviation_rigid == 0:\n",
    "\n",
    "        if shifts_opencv:\n",
    "            if gSig_filt is not None:\n",
    "                img = img_orig\n",
    "\n",
    "            new_img = apply_shift_iteration(\n",
    "                img, (-rigid_shts[0], -rigid_shts[1]), border_nan=border_nan)\n",
    "\n",
    "        else:\n",
    "\n",
    "            if gSig_filt is not None:\n",
    "                raise Exception(\n",
    "                    'The use of FFT and filtering options have not been tested. Set opencv=True')\n",
    "\n",
    "            new_img = apply_shifts_dft(\n",
    "                sfr_freq, (-rigid_shts[0], -rigid_shts[1]), diffphase, border_nan=border_nan)\n",
    "\n",
    "        return new_img - add_to_movie, (-rigid_shts[0], -rigid_shts[1]), None, None\n",
    "    else:\n",
    "        # extract patches\n",
    "        templates = [\n",
    "            it[-1] for it in sliding_window(template, overlaps=overlaps, strides=strides)]\n",
    "        xy_grid = [(it[0], it[1]) for it in sliding_window(\n",
    "            template, overlaps=overlaps, strides=strides)]\n",
    "        num_tiles = np.prod(np.add(xy_grid[-1], 1))\n",
    "        imgs = [it[-1]\n",
    "                for it in sliding_window(img, overlaps=overlaps, strides=strides)]\n",
    "        dim_grid = tuple(np.add(xy_grid[-1], 1))\n",
    "\n",
    "        if max_deviation_rigid is not None:\n",
    "\n",
    "            lb_shifts = np.ceil(np.subtract(\n",
    "                rigid_shts, max_deviation_rigid)).astype(int)\n",
    "            ub_shifts = np.floor(\n",
    "                np.add(rigid_shts, max_deviation_rigid)).astype(int)\n",
    "\n",
    "        else:\n",
    "\n",
    "            lb_shifts = None\n",
    "            ub_shifts = None\n",
    "\n",
    "        # extract shifts for each patch\n",
    "        shfts_et_all = [register_translation(\n",
    "            a, b, c, shifts_lb=lb_shifts, shifts_ub=ub_shifts, max_shifts=max_shifts, use_cuda=use_cuda) for a, b, c in zip(\n",
    "            imgs, templates, [upsample_factor_fft] * num_tiles)]\n",
    "        shfts = [sshh[0] for sshh in shfts_et_all]\n",
    "        diffs_phase = [sshh[2] for sshh in shfts_et_all]\n",
    "        # create a vector field\n",
    "        shift_img_x = np.reshape(np.array(shfts)[:, 0], dim_grid)\n",
    "        shift_img_y = np.reshape(np.array(shfts)[:, 1], dim_grid)\n",
    "        diffs_phase_grid = np.reshape(np.array(diffs_phase), dim_grid)\n",
    "\n",
    "        if shifts_opencv:\n",
    "            if gSig_filt is not None:\n",
    "                img = img_orig\n",
    "\n",
    "            dims = img.shape\n",
    "            x_grid, y_grid = np.meshgrid(np.arange(0., dims[1]).astype(\n",
    "                np.float32), np.arange(0., dims[0]).astype(np.float32))\n",
    "            m_reg = cv2.remap(img, cv2.resize(shift_img_y.astype(np.float32), dims[::-1]) + x_grid,\n",
    "                              cv2.resize(shift_img_x.astype(np.float32), dims[::-1]) + y_grid,\n",
    "                              cv2.INTER_CUBIC, borderMode=cv2.BORDER_REPLICATE)\n",
    "                             # borderValue=add_to_movie)\n",
    "            total_shifts = [\n",
    "                    (-x, -y) for x, y in zip(shift_img_x.reshape(num_tiles), shift_img_y.reshape(num_tiles))]\n",
    "            return m_reg - add_to_movie, total_shifts, None, None\n",
    "\n",
    "        # create automatically upsample parameters if not passed\n",
    "        if newoverlaps is None:\n",
    "            newoverlaps = overlaps\n",
    "        if newstrides is None:\n",
    "            newstrides = tuple(\n",
    "                np.round(np.divide(strides, upsample_factor_grid)).astype(np.int))\n",
    "\n",
    "        newshapes = np.add(newstrides, newoverlaps)\n",
    "\n",
    "        imgs = [it[-1]\n",
    "                for it in sliding_window(img, overlaps=newoverlaps, strides=newstrides)]\n",
    "\n",
    "        xy_grid = [(it[0], it[1]) for it in sliding_window(\n",
    "            img, overlaps=newoverlaps, strides=newstrides)]\n",
    "\n",
    "        start_step = [(it[2], it[3]) for it in sliding_window(\n",
    "            img, overlaps=newoverlaps, strides=newstrides)]\n",
    "\n",
    "        dim_new_grid = tuple(np.add(xy_grid[-1], 1))\n",
    "\n",
    "        shift_img_x = cv2.resize(\n",
    "            shift_img_x, dim_new_grid[::-1], interpolation=cv2.INTER_CUBIC)\n",
    "        shift_img_y = cv2.resize(\n",
    "            shift_img_y, dim_new_grid[::-1], interpolation=cv2.INTER_CUBIC)\n",
    "        diffs_phase_grid_us = cv2.resize(\n",
    "            diffs_phase_grid, dim_new_grid[::-1], interpolation=cv2.INTER_CUBIC)\n",
    "\n",
    "        num_tiles = np.prod(dim_new_grid)\n",
    "\n",
    "        max_shear = np.percentile(\n",
    "            [np.max(np.abs(np.diff(ssshh, axis=xxsss))) for ssshh, xxsss in itertools.product(\n",
    "                [shift_img_x, shift_img_y], [0, 1])], 75)\n",
    "\n",
    "        total_shifts = [\n",
    "            (-x, -y) for x, y in zip(shift_img_x.reshape(num_tiles), shift_img_y.reshape(num_tiles))]\n",
    "        total_diffs_phase = [\n",
    "            dfs for dfs in diffs_phase_grid_us.reshape(num_tiles)]\n",
    "\n",
    "        if gSig_filt is not None:\n",
    "            raise Exception(\n",
    "                'The use of FFT and filtering options have not been tested. Set opencv=True')\n",
    "\n",
    "        imgs = [apply_shifts_dft(im, (\n",
    "            sh[0], sh[1]), dffphs, is_freq=False, border_nan=border_nan) for im, sh, dffphs in zip(\n",
    "            imgs, total_shifts, total_diffs_phase)]\n",
    "\n",
    "        normalizer = np.zeros_like(img) * np.nan\n",
    "        new_img = np.zeros_like(img) * np.nan\n",
    "\n",
    "        weight_matrix = create_weight_matrix_for_blending(\n",
    "            img, newoverlaps, newstrides)\n",
    "\n",
    "        if max_shear < 0.5:\n",
    "            for (x, y), (_, _), im, (_, _), weight_mat in zip(start_step, xy_grid, imgs, total_shifts, weight_matrix):\n",
    "\n",
    "                prev_val_1 = normalizer[x:x + newshapes[0], y:y + newshapes[1]]\n",
    "\n",
    "                normalizer[x:x + newshapes[0], y:y + newshapes[1]] = np.nansum(\n",
    "                    np.dstack([~np.isnan(im) * 1 * weight_mat, prev_val_1]), -1)\n",
    "                prev_val = new_img[x:x + newshapes[0], y:y + newshapes[1]]\n",
    "                new_img[x:x + newshapes[0], y:y + newshapes[1]\n",
    "                        ] = np.nansum(np.dstack([im * weight_mat, prev_val]), -1)\n",
    "\n",
    "            new_img = old_div(new_img, normalizer)\n",
    "\n",
    "        else:  # in case the difference in shift between neighboring patches is larger than 0.5 pixels we do not interpolate in the overlaping area\n",
    "            half_overlap_x = np.int(newoverlaps[0] / 2)\n",
    "            half_overlap_y = np.int(newoverlaps[1] / 2)\n",
    "            for (x, y), (idx_0, idx_1), im, (_, _), weight_mat in zip(start_step, xy_grid, imgs, total_shifts, weight_matrix):\n",
    "\n",
    "                if idx_0 == 0:\n",
    "                    x_start = x\n",
    "                else:\n",
    "                    x_start = x + half_overlap_x\n",
    "\n",
    "                if idx_1 == 0:\n",
    "                    y_start = y\n",
    "                else:\n",
    "                    y_start = y + half_overlap_y\n",
    "\n",
    "                x_end = x + newshapes[0]\n",
    "                y_end = y + newshapes[1]\n",
    "                new_img[x_start:x_end,\n",
    "                        y_start:y_end] = im[x_start - x:, y_start - y:]\n",
    "\n",
    "        if show_movie:\n",
    "            img = apply_shifts_dft(\n",
    "                sfr_freq, (-rigid_shts[0], -rigid_shts[1]), diffphase, border_nan=border_nan)\n",
    "            img_show = np.vstack([new_img, img])\n",
    "\n",
    "            img_show = cv2.resize(img_show, None, fx=1, fy=1)\n",
    "\n",
    "            cv2.imshow('frame', old_div(img_show, np.percentile(template, 99)))\n",
    "            cv2.waitKey(int(1. / 500 * 1000))\n",
    "\n",
    "        else:\n",
    "            try:\n",
    "                cv2.destroyAllWindows()\n",
    "            except:\n",
    "                pass\n",
    "        return new_img - add_to_movie, total_shifts, start_step, xy_grid\n",
    "\n",
    "#%%        \n",
    "def tile_and_correct_3d(img:np.ndarray, template:np.ndarray, strides:Tuple, overlaps:Tuple, max_shifts:Tuple, newoverlaps:Optional[Tuple]=None, newstrides:Optional[Tuple]=None, upsample_factor_grid:int=4,\n",
    "                     upsample_factor_fft:int=10, show_movie:bool=False, max_deviation_rigid:int=2, add_to_movie:int=0, shifts_opencv:bool=True, gSig_filt=None,\n",
    "                     use_cuda:bool=False, border_nan:bool=True):\n",
    "    \"\"\" perform piecewise rigid motion correction iteration, by\n",
    "        1) dividing the FOV in patches\n",
    "        2) motion correcting each patch separately\n",
    "        3) upsampling the motion correction vector field\n",
    "        4) stiching back together the corrected subpatches\n",
    "\n",
    "    Args:\n",
    "        img: ndaarray 3D\n",
    "            image to correct\n",
    "\n",
    "        template: ndarray\n",
    "            reference image\n",
    "\n",
    "        strides: tuple\n",
    "            strides of the patches in which the FOV is subdivided\n",
    "\n",
    "        overlaps: tuple\n",
    "            amount of pixel overlaping between patches along each dimension\n",
    "\n",
    "        max_shifts: tuple\n",
    "            max shifts in x, y, and z\n",
    "\n",
    "        newstrides:tuple\n",
    "            strides between patches along each dimension when upsampling the vector fields\n",
    "\n",
    "        newoverlaps:tuple\n",
    "            amount of pixel overlaping between patches along each dimension when upsampling the vector fields\n",
    "\n",
    "        upsample_factor_grid: int\n",
    "            if newshapes or newstrides are not specified this is inferred upsampling by a constant factor the cvector field\n",
    "\n",
    "        upsample_factor_fft: int\n",
    "            resolution of fractional shifts\n",
    "\n",
    "        show_movie: boolean whether to visualize the original and corrected frame during motion correction\n",
    "\n",
    "        max_deviation_rigid: int\n",
    "            maximum deviation in shifts of each patch from the rigid shift (should not be large)\n",
    "\n",
    "        add_to_movie: if movie is too negative the correction might have some issues. In this case it is good to add values so that it is non negative most of the times\n",
    "\n",
    "        filt_sig_size: tuple\n",
    "            standard deviation and size of gaussian filter to center filter data in case of one photon imaging data\n",
    "\n",
    "        use_cuda : bool, optional\n",
    "            Use skcuda.fft (if available). Default: False\n",
    "\n",
    "        border_nan : bool or string, optional\n",
    "            specifies how to deal with borders. (True, False, 'copy', 'min')\n",
    "\n",
    "    Returns:\n",
    "        (new_img, total_shifts, start_step, xyz_grid)\n",
    "            new_img: ndarray, corrected image\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    img = img.astype(np.float64).copy()\n",
    "    template = template.astype(np.float64).copy()\n",
    "\n",
    "    if gSig_filt is not None:\n",
    "\n",
    "        img_orig = img.copy()\n",
    "        img = high_pass_filter_space(img_orig, gSig_filt)\n",
    "\n",
    "    img = img + add_to_movie\n",
    "    template = template + add_to_movie\n",
    "\n",
    "    # compute rigid shifts\n",
    "    rigid_shts, sfr_freq, diffphase = register_translation_3d(\n",
    "        img, template, upsample_factor=upsample_factor_fft, max_shifts=max_shifts)\n",
    "\n",
    "    if max_deviation_rigid == 0: # if rigid shifts only\n",
    "\n",
    "#        if shifts_opencv:\n",
    "            # NOTE: opencv does not support 3D operations - skimage is used instead\n",
    " #       else:\n",
    "\n",
    "        if gSig_filt is not None:\n",
    "            raise Exception(\n",
    "                'The use of FFT and filtering options have not been tested. Set opencv=True')\n",
    "\n",
    "        new_img = apply_shifts_dft( # TODO: check\n",
    "            sfr_freq, (rigid_shts[0], rigid_shts[1], rigid_shts[2]), diffphase, border_nan=border_nan)\n",
    "\n",
    "        return new_img - add_to_movie, (-rigid_shts[0], -rigid_shts[1], -rigid_shts[2]), None, None\n",
    "    else:\n",
    "        # extract patches\n",
    "        templates = [\n",
    "            it[-1] for it in sliding_window_3d(template, overlaps=overlaps, strides=strides)]\n",
    "        xyz_grid = [(it[0], it[1], it[2]) for it in sliding_window_3d(\n",
    "            template, overlaps=overlaps, strides=strides)]\n",
    "        num_tiles = np.prod(np.add(xyz_grid[-1], 1))\n",
    "        imgs = [it[-1]\n",
    "                for it in sliding_window_3d(img, overlaps=overlaps, strides=strides)]\n",
    "        dim_grid = tuple(np.add(xyz_grid[-1], 1))\n",
    "\n",
    "        if max_deviation_rigid is not None:\n",
    "\n",
    "            lb_shifts = np.ceil(np.subtract(\n",
    "                rigid_shts, max_deviation_rigid)).astype(int)\n",
    "            ub_shifts = np.floor(\n",
    "                np.add(rigid_shts, max_deviation_rigid)).astype(int)\n",
    "\n",
    "        else:\n",
    "\n",
    "            lb_shifts = None\n",
    "            ub_shifts = None\n",
    "\n",
    "        # extract shifts for each patch\n",
    "        shfts_et_all = [register_translation_3d(\n",
    "            a, b, c, shifts_lb=lb_shifts, shifts_ub=ub_shifts, max_shifts=max_shifts) for a, b, c in zip(\n",
    "            imgs, templates, [upsample_factor_fft] * num_tiles)]\n",
    "        shfts = [sshh[0] for sshh in shfts_et_all]\n",
    "        diffs_phase = [sshh[2] for sshh in shfts_et_all]\n",
    "        # create a vector field\n",
    "        shift_img_x = np.reshape(np.array(shfts)[:, 0], dim_grid)\n",
    "        shift_img_y = np.reshape(np.array(shfts)[:, 1], dim_grid)\n",
    "        shift_img_z = np.reshape(np.array(shfts)[:, 2], dim_grid)\n",
    "        diffs_phase_grid = np.reshape(np.array(diffs_phase), dim_grid)\n",
    "\n",
    "        #  shifts_opencv doesn't make sense here- replace with shifts_skimage\n",
    "        if shifts_opencv:\n",
    "            if gSig_filt is not None:\n",
    "                img = img_orig\n",
    "\n",
    "            dims = img.shape\n",
    "            x_grid, y_grid, z_grid = np.meshgrid(np.arange(0., dims[1]).astype(\n",
    "                np.float32), np.arange(0., dims[0]).astype(np.float32),\n",
    "                np.arange(0., dims[2]).astype(np.float32))\n",
    "            m_reg = warp_sk(img, np.stack((resize_sk(shift_img_x.astype(np.float32), dims) + y_grid,\n",
    "                              resize_sk(shift_img_y.astype(np.float32), dims) + x_grid,\n",
    "                              resize_sk(shift_img_z.astype(np.float32), dims) + z_grid),axis=0),\n",
    "                              order=3, mode='constant')\n",
    "                             # borderValue=add_to_movie)\n",
    "            total_shifts = [\n",
    "                    (-x, -y, -z) for x, y, z in zip(shift_img_x.reshape(num_tiles), shift_img_y.reshape(num_tiles), shift_img_z.reshape(num_tiles))]\n",
    "            return m_reg - add_to_movie, total_shifts, None, None\n",
    "\n",
    "        # create automatically upsample parameters if not passed\n",
    "        if newoverlaps is None:\n",
    "            newoverlaps = overlaps\n",
    "        if newstrides is None:\n",
    "            newstrides = tuple(\n",
    "                np.round(np.divide(strides, upsample_factor_grid)).astype(np.int))\n",
    "\n",
    "        newshapes = np.add(newstrides, newoverlaps)\n",
    "\n",
    "        imgs = [it[-1]\n",
    "                for it in sliding_window_3d(img, overlaps=newoverlaps, strides=newstrides)]\n",
    "\n",
    "        xyz_grid = [(it[0], it[1], it[2]) for it in sliding_window_3d(\n",
    "            img, overlaps=newoverlaps, strides=newstrides)]\n",
    "\n",
    "        start_step = [(it[3], it[4], it[5]) for it in sliding_window_3d(\n",
    "            img, overlaps=newoverlaps, strides=newstrides)]\n",
    "\n",
    "        dim_new_grid = tuple(np.add(xyz_grid[-1], 1))\n",
    "\n",
    "        shift_img_x = resize_sk(\n",
    "            shift_img_x, dim_new_grid[::-1], order=3)\n",
    "        shift_img_y = resize_sk(\n",
    "            shift_img_y, dim_new_grid[::-1], order=3)\n",
    "        shift_img_z = resize_sk(\n",
    "            shift_img_z, dim_new_grid[::-1], order=3)\n",
    "        diffs_phase_grid_us = resize_sk(\n",
    "            diffs_phase_grid, dim_new_grid[::-1], order=3)\n",
    "\n",
    "        num_tiles = np.prod(dim_new_grid)\n",
    "\n",
    "        # what dimension shear should be looked at? shearing for 3d point scanning happens in y and z but no for plane-scanning\n",
    "        max_shear = np.percentile(\n",
    "            [np.max(np.abs(np.diff(ssshh, axis=xxsss))) for ssshh, xxsss in itertools.product(\n",
    "                [shift_img_x, shift_img_y], [0, 1])], 75)\n",
    "\n",
    "        total_shifts = [\n",
    "            (-x, -y, -z) for x, y, z in zip(shift_img_x.reshape(num_tiles), shift_img_y.reshape(num_tiles), shift_img_z.reshape(num_tiles))]\n",
    "        total_diffs_phase = [\n",
    "            dfs for dfs in diffs_phase_grid_us.reshape(num_tiles)]\n",
    "\n",
    "        if gSig_filt is not None:\n",
    "            raise Exception(\n",
    "                'The use of FFT and filtering options have not been tested. Set opencv=True')\n",
    "\n",
    "        imgs = [apply_shifts_dft(im, (\n",
    "            sh[0], sh[1], sh[2]), dffphs, is_freq=False, border_nan=border_nan) for im, sh, dffphs in zip(\n",
    "            imgs, total_shifts, total_diffs_phase)]\n",
    "\n",
    "        normalizer = np.zeros_like(img) * np.nan\n",
    "        new_img = np.zeros_like(img) * np.nan\n",
    "\n",
    "        weight_matrix = create_weight_matrix_for_blending(\n",
    "            img, newoverlaps, newstrides)\n",
    "\n",
    "        if max_shear < 0.5:\n",
    "            for (x, y, z), (_, _, _), im, (_, _, _), weight_mat in zip(start_step, xyz_grid, imgs, total_shifts, weight_matrix):\n",
    "\n",
    "                prev_val_1 = normalizer[x:x + newshapes[0], y:y + newshapes[1], z:z + newshapes[2]]\n",
    "\n",
    "                normalizer[x:x + newshapes[0], y:y + newshapes[1], z:z + newshapes[2]] = np.nansum(\n",
    "                    np.dstack([~np.isnan(im) * 1 * weight_mat, prev_val_1]), -1)\n",
    "                prev_val = new_img[x:x + newshapes[0], y:y + newshapes[1], z:z + newshapes[2]]\n",
    "                new_img[x:x + newshapes[0], y:y + newshapes[1], z:z + newshapes[2]\n",
    "                        ] = np.nansum(np.dstack([im * weight_mat, prev_val]), -1)\n",
    "\n",
    "            new_img = old_div(new_img, normalizer)\n",
    "\n",
    "        else:  # in case the difference in shift between neighboring patches is larger than 0.5 pixels we do not interpolate in the overlaping area\n",
    "            half_overlap_x = np.int(newoverlaps[0] / 2)\n",
    "            half_overlap_y = np.int(newoverlaps[1] / 2)\n",
    "            half_overlap_z = np.int(newoverlaps[2] / 2)\n",
    "            \n",
    "            for (x, y, z), (idx_0, idx_1, idx_2), im, (_, _, _), weight_mat in zip(start_step, xyz_grid, imgs, total_shifts, weight_matrix):\n",
    "\n",
    "                if idx_0 == 0:\n",
    "                    x_start = x\n",
    "                else:\n",
    "                    x_start = x + half_overlap_x\n",
    "\n",
    "                if idx_1 == 0:\n",
    "                    y_start = y\n",
    "                else:\n",
    "                    y_start = y + half_overlap_y\n",
    "\n",
    "                if idx_2 == 0:\n",
    "                    z_start = z\n",
    "                else:\n",
    "                    z_start = z + half_overlap_z\n",
    "\n",
    "                x_end = x + newshapes[0]\n",
    "                y_end = y + newshapes[1]\n",
    "                z_end = z + newshapes[2]\n",
    "                new_img[x_start:x_end,y_start:y_end,\n",
    "                        z_start:z_end] = im[x_start - x:, y_start - y:, z_start -z:]\n",
    "\n",
    "        if show_movie:\n",
    "            img = apply_shifts_dft(\n",
    "                sfr_freq, (-rigid_shts[0], -rigid_shts[1], -rigid_shts[2]), diffphase, border_nan=border_nan)\n",
    "            img_show = np.vstack([new_img, img])\n",
    "\n",
    "            img_show = resize_sk(img_show, None, fx=1, fy=1, fz=1)\n",
    "\n",
    "            cv2.imshow('frame', old_div(img_show, np.percentile(template, 99)))\n",
    "            cv2.waitKey(int(1. / 500 * 1000))\n",
    "\n",
    "        else:\n",
    "            try:\n",
    "                cv2.destroyAllWindows()\n",
    "            except:\n",
    "                pass\n",
    "        return new_img - add_to_movie, total_shifts, start_step, xyz_grid\n",
    "#%%\n",
    "\n",
    "def compute_flow_single_frame(frame, templ, pyr_scale=.5, levels=3, winsize=100, iterations=15, poly_n=5,\n",
    "                              poly_sigma=1.2 / 5, flags=0):\n",
    "    flow = cv2.calcOpticalFlowFarneback(\n",
    "        templ, frame, None, pyr_scale, levels, winsize, iterations, poly_n, poly_sigma, flags)\n",
    "    return flow\n",
    "#%%\n",
    "\n",
    "\n",
    "def compute_metrics_motion_correction(fname, final_size_x, final_size_y, swap_dim, pyr_scale=.5, levels=3,\n",
    "                                      winsize=100, iterations=15, poly_n=5, poly_sigma=1.2 / 5, flags=0,\n",
    "                                      play_flow=False, resize_fact_flow=.2, template=None,\n",
    "                                      opencv=True, resize_fact_play=3, fr_play=30, max_flow=1,\n",
    "                                      gSig_filt=None):\n",
    "    #todo: todocument\n",
    "    # cv2.OPTFLOW_FARNEBACK_GAUSSIAN\n",
    "    import scipy\n",
    "    vmin, vmax = -max_flow, max_flow\n",
    "    m = load(fname)\n",
    "    if gSig_filt is not None:\n",
    "        m = high_pass_filter_space(m, gSig_filt)\n",
    "    mi, ma = m.min(), m.max()\n",
    "    m_min = mi + (ma - mi) / 100\n",
    "    m_max = mi + (ma - mi) / 4\n",
    "\n",
    "    max_shft_x = np.int(np.ceil((np.shape(m)[1] - final_size_x) / 2))\n",
    "    max_shft_y = np.int(np.ceil((np.shape(m)[2] - final_size_y) / 2))\n",
    "    max_shft_x_1 = - ((np.shape(m)[1] - max_shft_x) - (final_size_x))\n",
    "    max_shft_y_1 = - ((np.shape(m)[2] - max_shft_y) - (final_size_y))\n",
    "    if max_shft_x_1 == 0:\n",
    "        max_shft_x_1 = None\n",
    "\n",
    "    if max_shft_y_1 == 0:\n",
    "        max_shft_y_1 = None\n",
    "    logging.info([max_shft_x, max_shft_x_1, max_shft_y, max_shft_y_1])\n",
    "    m = m[:, max_shft_x:max_shft_x_1, max_shft_y:max_shft_y_1]\n",
    "    if np.sum(np.isnan(m)) > 0:\n",
    "        logging.info(m.shape)\n",
    "        logging.warning('Movie contains NaN')\n",
    "        raise Exception('Movie contains NaN')\n",
    "\n",
    "    logging.debug('Local correlations..')\n",
    "    img_corr = m.local_correlations(eight_neighbours=True, swap_dim=swap_dim)\n",
    "    logging.debug(m.shape)\n",
    "    if template is None:\n",
    "        tmpl = bin_median(m)\n",
    "    else:\n",
    "        tmpl = template\n",
    "\n",
    "    logging.debug('Compute Smoothness.. ')\n",
    "    smoothness = np.sqrt(\n",
    "        np.sum(np.sum(np.array(np.gradient(np.mean(m, 0)))**2, 0)))\n",
    "    smoothness_corr = np.sqrt(\n",
    "        np.sum(np.sum(np.array(np.gradient(img_corr))**2, 0)))\n",
    "\n",
    "    logging.debug('Compute correlations.. ')\n",
    "    correlations = []\n",
    "    count = 0\n",
    "    for fr in m:\n",
    "        if count % 100 == 0:\n",
    "            logging.debug(count)\n",
    "\n",
    "        count += 1\n",
    "        correlations.append(scipy.stats.pearsonr(\n",
    "            fr.flatten(), tmpl.flatten())[0])\n",
    "\n",
    "    logging.info('Compute optical flow .. ')\n",
    "\n",
    "    m = m.resize(1, 1, resize_fact_flow)\n",
    "    norms = []\n",
    "    flows = []\n",
    "    count = 0\n",
    "    for fr in m:\n",
    "        if count % 100 == 0:\n",
    "            logging.debug(count)\n",
    "\n",
    "        count += 1\n",
    "        flow = cv2.calcOpticalFlowFarneback(\n",
    "            tmpl, fr, None, pyr_scale, levels, winsize, iterations, poly_n, poly_sigma, flags)\n",
    "\n",
    "        if play_flow:\n",
    "            if opencv:\n",
    "                dims = tuple(np.array(flow.shape[:-1]) * resize_fact_play)\n",
    "                vid_frame = np.concatenate([\n",
    "                    np.repeat(np.clip((cv2.resize(fr, dims)[..., None] - m_min) /\n",
    "                                      (m_max - m_min), 0, 1), 3, -1),\n",
    "                    np.transpose([cv2.resize(np.clip(flow[:, :, 1] / vmax, 0, 1), dims),\n",
    "                                  np.zeros(dims, np.float32),\n",
    "                                  cv2.resize(np.clip(flow[:, :, 1] / vmin, 0, 1), dims)],\n",
    "                                  (1, 2, 0)),\n",
    "                    np.transpose([cv2.resize(np.clip(flow[:, :, 0] / vmax, 0, 1), dims),\n",
    "                                  np.zeros(dims, np.float32),\n",
    "                                  cv2.resize(np.clip(flow[:, :, 0] / vmin, 0, 1), dims)],\n",
    "                                  (1, 2, 0))], 1).astype(np.float32)\n",
    "                cv2.putText(vid_frame, 'movie', (10, 20), fontFace=5, fontScale=0.8, color=(\n",
    "                    0, 255, 0), thickness=1)\n",
    "                cv2.putText(vid_frame, 'y_flow', (dims[0] + 10, 20), fontFace=5, fontScale=0.8, color=(\n",
    "                    0, 255, 0), thickness=1)\n",
    "                cv2.putText(vid_frame, 'x_flow', (2 * dims[0] + 10, 20), fontFace=5, fontScale=0.8, color=(\n",
    "                    0, 255, 0), thickness=1)\n",
    "                cv2.imshow('frame', vid_frame)\n",
    "                pl.pause(1 / fr_play)\n",
    "                if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                    break\n",
    "            else:\n",
    "                pl.subplot(1, 3, 1)\n",
    "                pl.cla()\n",
    "                pl.imshow(fr, vmin=m_min, vmax=m_max, cmap='gray')\n",
    "                pl.title('movie')\n",
    "                pl.subplot(1, 3, 3)\n",
    "                pl.cla()\n",
    "                pl.imshow(flow[:, :, 1], vmin=vmin, vmax=vmax)\n",
    "                pl.title('y_flow')\n",
    "                pl.subplot(1, 3, 2)\n",
    "                pl.cla()\n",
    "                pl.imshow(flow[:, :, 0], vmin=vmin, vmax=vmax)\n",
    "                pl.title('x_flow')\n",
    "                pl.pause(1 / fr_play)\n",
    "\n",
    "        n = np.linalg.norm(flow)\n",
    "        flows.append(flow)\n",
    "        norms.append(n)\n",
    "    if play_flow and opencv:\n",
    "        cv2.destroyAllWindows()\n",
    "\n",
    "    np.savez(fname[:-4] + '_metrics', flows=flows, norms=norms, correlations=correlations, smoothness=smoothness,\n",
    "             tmpl=tmpl, smoothness_corr=smoothness_corr, img_corr=img_corr)\n",
    "    return tmpl, correlations, flows, norms, smoothness\n",
    "\n",
    "\n",
    "#%%\n",
    "def motion_correct_batch_rigid(fname, max_shifts, dview=None, splits=56, num_splits_to_process=None, num_iter=1,\n",
    "                               template=None, shifts_opencv=False, save_movie_rigid=False, add_to_movie=None,\n",
    "                               nonneg_movie=False, gSig_filt=None, subidx=slice(None, None, 1), use_cuda=False,\n",
    "                               border_nan=True, var_name_hdf5='mov', is3D=False, indices=(slice(None), slice(None))):\n",
    "    \"\"\"\n",
    "    Function that perform memory efficient hyper parallelized rigid motion corrections while also saving a memory mappable file\n",
    "\n",
    "    Args:\n",
    "        fname: str\n",
    "            name of the movie to motion correct. It should not contain nans. All the loadable formats from CaImAn are acceptable\n",
    "\n",
    "        max_shifts: tuple\n",
    "            x and y (and z if 3D) maximum allowed shifts\n",
    "\n",
    "        dview: ipyparallel view\n",
    "            used to perform parallel computing\n",
    "\n",
    "        splits: int\n",
    "            number of batches in which the movies is subdivided\n",
    "\n",
    "        num_splits_to_process: int\n",
    "            number of batches to process. when not None, the movie is not saved since only a random subset of batches will be processed\n",
    "\n",
    "        num_iter: int\n",
    "            number of iterations to perform. The more iteration the better will be the template.\n",
    "\n",
    "        template: ndarray\n",
    "            if a good approximation of the template to register is available, it can be used\n",
    "\n",
    "        shifts_opencv: boolean\n",
    "             toggle the shifts applied with opencv, if yes faster but induces some smoothing\n",
    "\n",
    "        save_movie_rigid: boolean\n",
    "             toggle save movie\n",
    "\n",
    "        subidx: slice\n",
    "            Indices to slice\n",
    "\n",
    "        use_cuda : bool, optional\n",
    "            Use skcuda.fft (if available). Default: False\n",
    "\n",
    "        indices: tuple(slice), default: (slice(None), slice(None))\n",
    "           Use that to apply motion correction only on a part of the FOV\n",
    "\n",
    "    Returns:\n",
    "         fname_tot_rig: str\n",
    "\n",
    "         total_template:ndarray\n",
    "\n",
    "         templates:list\n",
    "              list of produced templates, one per batch\n",
    "\n",
    "         shifts: list\n",
    "              inferred rigid shifts to correct the movie\n",
    "\n",
    "    Raises:\n",
    "        Exception 'The movie contains nans. Nans are not allowed!'\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    dims, T =get_file_size(fname, var_name_hdf5=var_name_hdf5)\n",
    "    Ts = np.arange(T)[subidx].shape[0]\n",
    "    step = Ts // 10 if is3D else Ts // 50\n",
    "    corrected_slicer = slice(subidx.start, subidx.stop, step + 1)\n",
    "    m = load(fname, var_name_hdf5=var_name_hdf5, subindices=corrected_slicer)\n",
    "\n",
    "    if len(m.shape) < 3:\n",
    "        m = load(fname, var_name_hdf5=var_name_hdf5)\n",
    "        m = m[corrected_slicer]\n",
    "        logging.warning(\"Your original file was saved as a single page \" +\n",
    "                        \"file. Consider saving it in multiple smaller files\" +\n",
    "                        \"with size smaller than 4GB (if it is a .tif file)\")\n",
    "\n",
    "    if is3D:\n",
    "        m = m[:, indices[0], indices[1], indices[2]]\n",
    "    else:\n",
    "        m = m[:, indices[0], indices[1]]\n",
    "\n",
    "    if template is None:\n",
    "        if gSig_filt is not None:\n",
    "            m = cm.movie(\n",
    "                np.array([high_pass_filter_space(m_, gSig_filt) for m_ in m]))\n",
    "        if is3D:     \n",
    "            # TODO - motion_correct_3d needs to be implemented in movies.py\n",
    "            template = bin_median_3d(m) # motion_correct_3d has not been implemented yet - instead initialize to just median image\n",
    "#            template = caiman.motion_correction.bin_median_3d(\n",
    "#                    m.motion_correct_3d(max_shifts[2], max_shifts[1], max_shifts[0], template=None)[0])\n",
    "        else:\n",
    "            if not m.flags['WRITEABLE']:\n",
    "                m = m.copy()\n",
    "            template = bin_median(\n",
    "                    m.motion_correct(max_shifts[1], max_shifts[0], template=None)[0])\n",
    "\n",
    "    new_templ = template\n",
    "    if add_to_movie is None:\n",
    "        add_to_movie = -np.min(template)\n",
    "\n",
    "    if np.isnan(add_to_movie):\n",
    "        logging.error('The movie contains NaNs. NaNs are not allowed!')\n",
    "        raise Exception('The movie contains NaNs. NaNs are not allowed!')\n",
    "    else:\n",
    "        logging.debug('Adding to movie ' + str(add_to_movie))\n",
    "\n",
    "    save_movie = False\n",
    "    fname_tot_rig = None\n",
    "    res_rig:List = []\n",
    "    for iter_ in range(num_iter):\n",
    "        logging.debug(iter_)\n",
    "        old_templ = new_templ.copy()\n",
    "        if iter_ == num_iter - 1:\n",
    "            save_movie = save_movie_rigid\n",
    "            logging.debug('saving!')\n",
    "\n",
    "\n",
    "        if isinstance(fname, tuple):\n",
    "            base_name=os.path.split(fname[0])[-1][:-4] + '_rig_'\n",
    "        else:\n",
    "            base_name=os.path.split(fname)[-1][:-4] + '_rig_'\n",
    "\n",
    "        fname_tot_rig, res_rig = motion_correction_piecewise(fname, splits, strides=None, overlaps=None,\n",
    "                                                             add_to_movie=add_to_movie, template=old_templ, max_shifts=max_shifts, max_deviation_rigid=0,\n",
    "                                                             dview=dview, save_movie=save_movie, base_name=base_name, subidx = subidx,\n",
    "                                                             num_splits=num_splits_to_process, shifts_opencv=shifts_opencv, nonneg_movie=nonneg_movie, gSig_filt=gSig_filt,\n",
    "                                                             use_cuda=use_cuda, border_nan=border_nan, var_name_hdf5=var_name_hdf5, is3D=is3D,\n",
    "                                                             indices=indices)\n",
    "        if is3D:\n",
    "            new_templ = np.nanmedian(np.stack([r[-1] for r in res_rig]), 0)           \n",
    "        else:\n",
    "            new_templ = np.nanmedian(np.dstack([r[-1] for r in res_rig]), -1)\n",
    "        if gSig_filt is not None:\n",
    "            new_templ = high_pass_filter_space(new_templ, gSig_filt)\n",
    "\n",
    "#        logging.debug((old_div(np.linalg.norm(new_templ - old_templ), np.linalg.norm(old_templ))))\n",
    "\n",
    "    total_template = new_templ\n",
    "    templates = []\n",
    "    shifts:List = []\n",
    "    for rr in res_rig:\n",
    "        shift_info, idxs, tmpl = rr\n",
    "        templates.append(tmpl)\n",
    "        shifts += [sh[0] for sh in shift_info[:len(idxs)]]\n",
    " #       shifts += [[sh[0][0], sh[0][1]] for sh in shift_info[:len(idxs)]]\n",
    " #       if is3D:\n",
    " #           shifts += [[sh[0][0], sh[0][1], sh[0][2]] for sh in shift_info[:len(idxs)]]            \n",
    " #       else:\n",
    " #           shifts += [[sh[0][0], sh[0][1]] for sh in shift_info[:len(idxs)]]\n",
    "\n",
    "    return fname_tot_rig, total_template, templates, shifts\n",
    "\n",
    "def motion_correct_batch_pwrigid(fname, max_shifts, strides, overlaps, add_to_movie, newoverlaps=None, newstrides=None,\n",
    "                                 dview=None, upsample_factor_grid=4, max_deviation_rigid=3,\n",
    "                                 splits=56, num_splits_to_process=None, num_iter=1,\n",
    "                                 template=None, shifts_opencv=False, save_movie=False, nonneg_movie=False, gSig_filt=None,\n",
    "                                 use_cuda=False, border_nan=True, var_name_hdf5='mov', is3D=False,\n",
    "                                 indices=(slice(None), slice(None))):\n",
    "    \"\"\"\n",
    "    Function that perform memory efficient hyper parallelized rigid motion corrections while also saving a memory mappable file\n",
    "\n",
    "    Args:\n",
    "        fname: str\n",
    "            name of the movie to motion correct. It should not contain nans. All the loadable formats from CaImAn are acceptable\n",
    "\n",
    "        strides: tuple\n",
    "            strides of patches along x and y (and z if 3D)\n",
    "\n",
    "        overlaps:\n",
    "            overlaps of patches along x and y (and z if 3D). example: If strides = (64,64) and overlaps (32,32) patches will be (96,96)\n",
    "\n",
    "        newstrides: tuple\n",
    "            overlaps after upsampling\n",
    "\n",
    "        newoverlaps: tuple\n",
    "            strides after upsampling\n",
    "\n",
    "        max_shifts: tuple\n",
    "            x and y maximum allowed shifts (and z if 3D)\n",
    "\n",
    "        dview: ipyparallel view\n",
    "            used to perform parallel computing\n",
    "\n",
    "        splits: int\n",
    "            number of batches in which the movies is subdivided\n",
    "\n",
    "        num_splits_to_process: int\n",
    "            number of batches to process. when not None, the movie is not saved since only a random subset of batches will be processed\n",
    "\n",
    "        num_iter: int\n",
    "            number of iterations to perform. The more iteration the better will be the template.\n",
    "\n",
    "        template: ndarray\n",
    "            if a good approximation of the template to register is available, it can be used\n",
    "\n",
    "        shifts_opencv: boolean\n",
    "             toggle the shifts applied with opencv, if yes faster but induces some smoothing\n",
    "\n",
    "        save_movie_rigid: boolean\n",
    "             toggle save movie\n",
    "\n",
    "        use_cuda : bool, optional\n",
    "            Use skcuda.fft (if available). Default: False\n",
    "\n",
    "        indices: tuple(slice), default: (slice(None), slice(None))\n",
    "           Use that to apply motion correction only on a part of the FOV\n",
    "\n",
    "    Returns:\n",
    "        fname_tot_rig: str\n",
    "\n",
    "        total_template:ndarray\n",
    "\n",
    "        templates:list\n",
    "            list of produced templates, one per batch\n",
    "\n",
    "        shifts: list\n",
    "            inferred rigid shifts to corrrect the movie\n",
    "\n",
    "    Raises:\n",
    "        Exception 'You need to initialize the template with a good estimate. See the motion'\n",
    "                        '_correct_batch_rigid function'\n",
    "    \"\"\"\n",
    "    if template is None:\n",
    "        raise Exception('You need to initialize the template with a good estimate. See the motion'\n",
    "                        '_correct_batch_rigid function')\n",
    "    else:\n",
    "        new_templ = template\n",
    "\n",
    "    if np.isnan(add_to_movie):\n",
    "        logging.error('The template contains NaNs. NaNs are not allowed!')\n",
    "        raise Exception('The template contains NaNs. NaNs are not allowed!')\n",
    "    else:\n",
    "        logging.debug('Adding to movie ' + str(add_to_movie))\n",
    "\n",
    "    for iter_ in range(num_iter):\n",
    "        logging.debug(iter_)\n",
    "        old_templ = new_templ.copy()\n",
    "\n",
    "        if iter_ == num_iter - 1:\n",
    "            save_movie = save_movie\n",
    "            if save_movie:\n",
    "\n",
    "                if isinstance(fname, tuple):\n",
    "                    logging.debug(f'saving mmap of {fname[0]} to {fname[-1]}')\n",
    "                else:\n",
    "                    logging.debug(f'saving mmap of {fname}')\n",
    "\n",
    "        if isinstance(fname, tuple):\n",
    "            base_name=os.path.split(fname[0])[-1][:-4] + '_els_'\n",
    "        else:\n",
    "            base_name=os.path.split(fname)[-1][:-4] + '_els_'\n",
    "\n",
    "        fname_tot_els, res_el = motion_correction_piecewise(fname, splits, strides, overlaps,\n",
    "                                                            add_to_movie=add_to_movie, template=old_templ, max_shifts=max_shifts,\n",
    "                                                            max_deviation_rigid=max_deviation_rigid,\n",
    "                                                            newoverlaps=newoverlaps, newstrides=newstrides,\n",
    "                                                            upsample_factor_grid=upsample_factor_grid, order='F', dview=dview, save_movie=save_movie,\n",
    "                                                            base_name=base_name, num_splits=num_splits_to_process,\n",
    "                                                            shifts_opencv=shifts_opencv, nonneg_movie=nonneg_movie, gSig_filt=gSig_filt,\n",
    "                                                            use_cuda=use_cuda, border_nan=border_nan, var_name_hdf5=var_name_hdf5, is3D=is3D,\n",
    "                                                            indices=indices)\n",
    "\n",
    "        new_templ = np.nanmedian(np.dstack([r[-1] for r in res_el]), -1)\n",
    "        if gSig_filt is not None:\n",
    "            new_templ = high_pass_filter_space(new_templ, gSig_filt)\n",
    "\n",
    "    total_template = new_templ\n",
    "    templates = []\n",
    "    x_shifts = []\n",
    "    y_shifts = []\n",
    "    z_shifts = []\n",
    "    coord_shifts = []\n",
    "    for rr in res_el:\n",
    "        shift_info_chunk, idxs_chunk, tmpl_chunk = rr\n",
    "        templates.append(tmpl_chunk)\n",
    "        for shift_info, _ in zip(shift_info_chunk, idxs_chunk):\n",
    "            if is3D:\n",
    "                total_shift, _, xyz_grid = shift_info\n",
    "                x_shifts.append(np.array([sh[0] for sh in total_shift]))\n",
    "                y_shifts.append(np.array([sh[1] for sh in total_shift]))\n",
    "                z_shifts.append(np.array([sh[2] for sh in total_shift]))\n",
    "                coord_shifts.append(xyz_grid)\n",
    "            else:\n",
    "                total_shift, _, xy_grid = shift_info\n",
    "                x_shifts.append(np.array([sh[0] for sh in total_shift]))\n",
    "                y_shifts.append(np.array([sh[1] for sh in total_shift]))\n",
    "                coord_shifts.append(xy_grid)\n",
    "\n",
    "    return fname_tot_els, total_template, templates, x_shifts, y_shifts, z_shifts, coord_shifts\n",
    "\n",
    "\n",
    "#%% in parallel\n",
    "def tile_and_correct_wrapper(params):\n",
    "    \"\"\"Does motion correction on specified image frames\n",
    "\n",
    "    Returns:\n",
    "    shift_info:\n",
    "    idxs:\n",
    "    mean_img: mean over all frames of corrected image (to get individ frames, use out_fname to write them to disk)\n",
    "\n",
    "    Notes:\n",
    "    Also writes corrected frames to the mmap file specified by out_fname (if not None)\n",
    "\n",
    "    \"\"\"\n",
    "    # todo todocument\n",
    "\n",
    "\n",
    "    try:\n",
    "        cv2.setNumThreads(0)\n",
    "    except:\n",
    "        pass  # 'Open CV is naturally single threaded'\n",
    "\n",
    "    img_name, out_fname, idxs, shape_mov, template, strides, overlaps, max_shifts,\\\n",
    "        add_to_movie, max_deviation_rigid, upsample_factor_grid, newoverlaps, newstrides, \\\n",
    "        shifts_opencv, nonneg_movie, gSig_filt, is_fiji, use_cuda, border_nan, var_name_hdf5, \\\n",
    "        is3D, indices = params\n",
    "\n",
    "\n",
    "    if isinstance(img_name,tuple):\n",
    "        name, extension = os.path.splitext(img_name[0])[:2]\n",
    "    else:\n",
    "        name, extension = os.path.splitext(img_name)[:2]\n",
    "    extension = extension.lower()\n",
    "    shift_info = []\n",
    "\n",
    "    imgs = load(img_name, subindices=idxs, var_name_hdf5=var_name_hdf5,is3D=is3D)\n",
    "    imgs = imgs[(slice(None),) + indices]\n",
    "    mc = np.zeros(imgs.shape, dtype=np.float32)\n",
    "    if not imgs[0].shape == template.shape:\n",
    "        template = template[indices]\n",
    "    for count, img in enumerate(imgs):\n",
    "        if count % 10 == 0:\n",
    "            logging.debug(count)\n",
    "        if is3D:\n",
    "            mc[count], total_shift, start_step, xyz_grid = tile_and_correct_3d(img, template, strides, overlaps, max_shifts,\n",
    "                                                                       add_to_movie=add_to_movie, newoverlaps=newoverlaps,\n",
    "                                                                       newstrides=newstrides,\n",
    "                                                                       upsample_factor_grid=upsample_factor_grid,\n",
    "                                                                       upsample_factor_fft=10, show_movie=False,\n",
    "                                                                       max_deviation_rigid=max_deviation_rigid,\n",
    "                                                                       shifts_opencv=shifts_opencv, gSig_filt=gSig_filt,\n",
    "                                                                       use_cuda=use_cuda, border_nan=border_nan)\n",
    "            shift_info.append([tuple(-np.array(total_shift)), start_step, xyz_grid])\n",
    "            \n",
    "        else:\n",
    "            mc[count], total_shift, start_step, xy_grid = tile_and_correct(img, template, strides, overlaps, max_shifts,\n",
    "                                                                       add_to_movie=add_to_movie, newoverlaps=newoverlaps,\n",
    "                                                                       newstrides=newstrides,\n",
    "                                                                       upsample_factor_grid=upsample_factor_grid,\n",
    "                                                                       upsample_factor_fft=10, show_movie=False,\n",
    "                                                                       max_deviation_rigid=max_deviation_rigid,\n",
    "                                                                       shifts_opencv=shifts_opencv, gSig_filt=gSig_filt,\n",
    "                                                                       use_cuda=use_cuda, border_nan=border_nan)\n",
    "            shift_info.append([total_shift, start_step, xy_grid])\n",
    "\n",
    "    if out_fname is not None:\n",
    "        outv = np.memmap(out_fname, mode='r+', dtype=np.float32,\n",
    "                         shape=prepare_shape(shape_mov), order='F')\n",
    "        if nonneg_movie:\n",
    "            bias = np.float32(add_to_movie)\n",
    "        else:\n",
    "            bias = 0\n",
    "        outv[:, idxs] = np.reshape(\n",
    "            mc.astype(np.float32), (len(imgs), -1), order='F').T + bias\n",
    "    new_temp = np.nanmean(mc, 0)\n",
    "    new_temp[np.isnan(new_temp)] = np.nanmin(new_temp)\n",
    "    return shift_info, idxs, new_temp\n",
    "\n",
    "def motion_correction_piecewise(fname, splits, strides, overlaps, add_to_movie=0, template=None,\n",
    "                                max_shifts=(12, 12), max_deviation_rigid=3, newoverlaps=None, newstrides=None,\n",
    "                                upsample_factor_grid=4, order='F', dview=None, save_movie=True,\n",
    "                                base_name=None, subidx = None, num_splits=None, shifts_opencv=False, nonneg_movie=False, gSig_filt=None,\n",
    "                                use_cuda=False, border_nan=True, var_name_hdf5='mov', is3D=False,\n",
    "                                indices=(slice(None), slice(None))):\n",
    "    \"\"\"\n",
    "\n",
    "    \"\"\"\n",
    "    # todo todocument\n",
    "    if isinstance(fname,tuple):\n",
    "        name, extension = os.path.splitext(fname[0])[:2]\n",
    "    else:\n",
    "        name, extension = os.path.splitext(fname)[:2]\n",
    "    extension = extension.lower()\n",
    "    is_fiji = False\n",
    "\n",
    "    dims, T = get_file_size(fname, var_name_hdf5=var_name_hdf5)\n",
    "    z = np.zeros(dims)\n",
    "    dims = z[indices].shape\n",
    "    logging.debug('Number of Splits: {}'.format(splits))\n",
    "    if type(splits) is int:\n",
    "        if subidx is None:\n",
    "            rng = range(T)\n",
    "        else:\n",
    "            rng = range(T)[subidx]\n",
    "\n",
    "        idxs = np.array_split(list(rng), splits)\n",
    "\n",
    "    else:\n",
    "        idxs = splits\n",
    "        save_movie = False\n",
    "    if template is None:\n",
    "        raise Exception('Not implemented')\n",
    "    \n",
    "    shape_mov = (np.prod(dims), T)\n",
    "#    if is3D:\n",
    "#        shape_mov = (d1 * d2 * d3, T)\n",
    "#    else:\n",
    "#        shape_mov = (d1 * d2, T)\n",
    "    if num_splits is not None:\n",
    "        idxs = np.array(idxs)[np.random.randint(0, len(idxs), num_splits)]\n",
    "        save_movie = False\n",
    "        #logging.warning('**** MOVIE NOT SAVED BECAUSE num_splits is not None ****')\n",
    "\n",
    "    if save_movie:\n",
    "        if base_name is None:\n",
    "            base_name = os.path.split(fname)[1][:-4]\n",
    "        fname_tot:Optional[str] = memmap_frames_filename(base_name, dims, T, order)\n",
    "        if isinstance(fname,tuple):\n",
    "            fname_tot = os.path.join(os.path.split(fname[0])[0], fname_tot)\n",
    "        else:\n",
    "            fname_tot = os.path.join(os.path.split(fname)[0], fname_tot)\n",
    "\n",
    "        np.memmap(fname_tot, mode='w+', dtype=np.float32,\n",
    "                  shape=prepare_shape(shape_mov), order=order)\n",
    "        logging.info('Saving file as {}'.format(fname_tot))\n",
    "    else:\n",
    "        fname_tot = None\n",
    "\n",
    "    pars = []\n",
    "    for idx in idxs:\n",
    "        logging.debug('Processing: frames: {}'.format(idx))\n",
    "        pars.append([fname, fname_tot, idx, shape_mov, template, strides, overlaps, max_shifts, np.array(\n",
    "            add_to_movie, dtype=np.float32), max_deviation_rigid, upsample_factor_grid,\n",
    "            newoverlaps, newstrides, shifts_opencv, nonneg_movie, gSig_filt, is_fiji,\n",
    "            use_cuda, border_nan, var_name_hdf5, is3D, indices])\n",
    "\n",
    "    if dview is not None:\n",
    "        logging.info('** Starting parallel motion correction **')\n",
    "        if HAS_CUDA and use_cuda:\n",
    "            res = dview.map(tile_and_correct_wrapper,pars)\n",
    "            dview.map(close_cuda_process, range(len(pars)))\n",
    "        elif 'multiprocessing' in str(type(dview)):\n",
    "            res = dview.map_async(tile_and_correct_wrapper, pars).get(4294967)\n",
    "        else:\n",
    "            res = dview.map_sync(tile_and_correct_wrapper, pars)\n",
    "        logging.info('** Finished parallel motion correction **')\n",
    "    else:\n",
    "        res = list(map(tile_and_correct_wrapper, pars))\n",
    "\n",
    "    return fname_tot, res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_iter(file_name, subindices=None, var_name_hdf5: str = 'mov', outtype=np.float32):\n",
    "    \"\"\"\n",
    "    load iterator over movie from file. Supports a variety of formats. tif, hdf5, avi.\n",
    "    Args:\n",
    "        file_name: string\n",
    "            name of file. Possible extensions are tif, avi and hdf5\n",
    "        subindices: iterable indexes\n",
    "            for loading only a portion of the movie\n",
    "        var_name_hdf5: str\n",
    "            if loading from hdf5 name of the variable to load\n",
    "        outtype: The data type for the movie\n",
    "    Returns:\n",
    "        iter: iterator over movie\n",
    "    Raises:\n",
    "        Exception 'Subindices not implemented'\n",
    "        Exception 'sima module unavailable'\n",
    "        Exception 'Unknown file type'\n",
    "        Exception 'File not found!'\n",
    "    \"\"\"\n",
    "    if os.path.exists(file_name):\n",
    "        extension = os.path.splitext(file_name)[1].lower()\n",
    "        print('BOOM extension:', extension)\n",
    "        if extension in ('.hdf5', '.h5', '.nwb', '.mat'):\n",
    "            with h5py.File(file_name, \"r\") as f:\n",
    "                Y = f['data']\n",
    "                if subindices is None:\n",
    "                    for y in Y:\n",
    "                        yield y.astype(outtype)\n",
    "                else:\n",
    "                    if type(subindices) is slice:\n",
    "                        subindices = range(subindices.start,\n",
    "                                           len(Y) if subindices.stop is None else subindices.stop,\n",
    "                                           1 if subindices.step is None else subindices.step)\n",
    "                    for ind in subindices:\n",
    "                        yield Y[ind].astype(outtype)\n",
    "        else:  # fall back to memory inefficient version\n",
    "            for y in load(file_name, var_name_hdf5=var_name_hdf5,\n",
    "                          subindices=subindices, outtype=outtype):\n",
    "                yield y\n",
    "    else:\n",
    "        logging.error(f\"File request:[{file_name}] not found!\")\n",
    "        raise Exception('File not found!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class timeseries(np.ndarray):\n",
    "    \"\"\"\n",
    "    Class representing a time series.\n",
    "    \"\"\"\n",
    "\n",
    "    def __new__(cls, input_arr, fr=30, start_time=0, file_name=None, meta_data=None):\n",
    "        \"\"\"\n",
    "            Class representing a time series.\n",
    "            Example of usage\n",
    "            Args:\n",
    "                input_arr: np.ndarray\n",
    "                fr: frame rate\n",
    "                start_time: time beginning movie\n",
    "                meta_data: dictionary including any custom meta data\n",
    "            Raises:\n",
    "                Exception 'You need to specify the frame rate'\n",
    "            \"\"\"\n",
    "        if fr is None:\n",
    "            raise Exception('You need to specify the frame rate')\n",
    "\n",
    "        obj = np.asarray(input_arr).view(cls)\n",
    "        # add the new attribute to the created instance\n",
    "\n",
    "        obj.start_time = np.double(start_time)\n",
    "        obj.fr = np.double(fr)\n",
    "        if type(file_name) is list:\n",
    "            obj.file_name = file_name\n",
    "        else:\n",
    "            obj.file_name = [file_name]\n",
    "\n",
    "        if type(meta_data) is list:\n",
    "            obj.meta_data = meta_data\n",
    "        else:\n",
    "            obj.meta_data = [meta_data]\n",
    "\n",
    "        return obj\n",
    "\n",
    "    @property\n",
    "    def time(self):\n",
    "        return np.linspace(self.start_time, 1 / self.fr * self.shape[0], self.shape[0])\n",
    "\n",
    "    def __array_prepare__(self, out_arr, context=None):\n",
    "        # todo: todocument\n",
    "\n",
    "        frRef = None\n",
    "        startRef = None\n",
    "        if context is not None:\n",
    "            inputs = context[1]\n",
    "            for inp in inputs:\n",
    "                if type(inp) is timeseries:\n",
    "                    if frRef is None:\n",
    "                        frRef = inp.fr\n",
    "                    else:\n",
    "                        if not (frRef - inp.fr) == 0:\n",
    "                            raise ValueError(\n",
    "                                'Frame rates of input vectors do not match.'\n",
    "                                ' You cannot perform operations on time series with different frame rates.')\n",
    "                    if startRef is None:\n",
    "                        startRef = inp.start_time\n",
    "                    else:\n",
    "                        if not (startRef - inp.start_time) == 0:\n",
    "                            warnings.warn('start_time of input vectors do not match: ignore if this is desired.',\n",
    "                                          UserWarning)\n",
    "\n",
    "        # then just call the parent\n",
    "        return np.ndarray.__array_prepare__(self, out_arr, context)\n",
    "\n",
    "    def __array_finalize__(self, obj):\n",
    "        # see InfoArray.__array_finalize__ for comments\n",
    "        if obj is None:\n",
    "            return\n",
    "\n",
    "        self.start_time = getattr(obj, 'start_time', None)\n",
    "        self.fr = getattr(obj, 'fr', None)\n",
    "        self.file_name = getattr(obj, 'file_name', None)\n",
    "        self.meta_data = getattr(obj, 'meta_data', None)\n",
    "\n",
    "    def save(self,\n",
    "             file_name,\n",
    "             to32=True,\n",
    "             order='F',\n",
    "             imagej=False,\n",
    "             bigtiff=True,\n",
    "             excitation_lambda=488.0,\n",
    "             compress=0,\n",
    "             q_max=99.75,\n",
    "             q_min=1,\n",
    "             var_name_hdf5='mov',\n",
    "             sess_desc='some_description',\n",
    "             identifier='some identifier',\n",
    "             imaging_plane_description='some imaging plane description',\n",
    "             emission_lambda=520.0,\n",
    "             indicator='OGB-1',\n",
    "             location='brain',\n",
    "             starting_time=0.,\n",
    "             experimenter='Dr Who',\n",
    "             lab_name=None,\n",
    "             institution=None,\n",
    "             experiment_description='Experiment Description',\n",
    "             session_id='Session ID'):\n",
    "        \"\"\"\n",
    "        Save the timeseries in single precision. Supported formats include\n",
    "        TIFF, NPZ, AVI, MAT, HDF5/H5, MMAP, and NWB\n",
    "        Args:\n",
    "            file_name: str\n",
    "                name of file. Possible formats are tif, avi, npz, mmap and hdf5\n",
    "            to32: Bool\n",
    "                whether to transform to 32 bits\n",
    "            order: 'F' or 'C'\n",
    "                C or Fortran order\n",
    "            var_name_hdf5: str\n",
    "                Name of hdf5 file subdirectory\n",
    "            q_max, q_min: float in [0, 100]\n",
    "                percentile for maximum/minimum clipping value if saving as avi\n",
    "                (If set to None, no automatic scaling to the dynamic range [0, 255] is performed)\n",
    "        Raises:\n",
    "            Exception 'Extension Unknown'\n",
    "        \"\"\"\n",
    "        name, extension = os.path.splitext(file_name)[:2]\n",
    "        extension = extension.lower()\n",
    "        logging.debug(\"Parsing extension \" + str(extension))\n",
    "\n",
    "        if extension in ['.tif', '.tiff', '.btf']:\n",
    "            with tifffile.TiffWriter(file_name, bigtiff=bigtiff, imagej=imagej) as tif:\n",
    "                if \"%4d%02d%02d\" % tuple(map(int, tifffile.__version__.split('.'))) >= '20200813':\n",
    "                    def foo(i):\n",
    "                        if i % 200 == 0:\n",
    "                            logging.debug(str(i) + ' frames saved')\n",
    "                        curfr = self[i].copy()\n",
    "                        if to32 and not ('float32' in str(self.dtype)):\n",
    "                            curfr = curfr.astype(np.float32)\n",
    "                        return curfr             \n",
    "                    tif.save([foo(i) for i in range(self.shape[0])], compress=compress)\n",
    "                else:\n",
    "                    for i in range(self.shape[0]):\n",
    "                        if i % 200 == 0:\n",
    "                            logging.debug(str(i) + ' frames saved')\n",
    "                        curfr = self[i].copy()\n",
    "                        if to32 and not ('float32' in str(self.dtype)):\n",
    "                            curfr = curfr.astype(np.float32)\n",
    "                        tif.save(curfr, compress=compress)\n",
    "        elif extension == '.npz':\n",
    "            if to32 and not ('float32' in str(self.dtype)):\n",
    "                input_arr = self.astype(np.float32)\n",
    "            else:\n",
    "                input_arr = np.array(self)\n",
    "\n",
    "            np.savez(file_name,\n",
    "                     input_arr=input_arr,\n",
    "                     start_time=self.start_time,\n",
    "                     fr=self.fr,\n",
    "                     meta_data=self.meta_data,\n",
    "                     file_name=self.file_name)\n",
    "        elif extension in ('.avi', '.mkv'):\n",
    "            codec = None\n",
    "            try:\n",
    "                codec = cv2.FOURCC('I', 'Y', 'U', 'V')\n",
    "            except AttributeError:\n",
    "                codec = cv2.VideoWriter_fourcc(*'IYUV')\n",
    "            if q_max is None or q_min is None:\n",
    "                data = self.astype(np.uint8)\n",
    "            else:\n",
    "                if q_max < 100:\n",
    "                    maxmov = np.nanpercentile(self[::max(1, len(self) // 100)], q_max)\n",
    "                else:\n",
    "                    maxmov = np.nanmax(self)\n",
    "                if q_min > 0:\n",
    "                    minmov = np.nanpercentile(self[::max(1, len(self) // 100)], q_min)\n",
    "                else:\n",
    "                    minmov = np.nanmin(self)\n",
    "                data = 255 * (self - minmov) / (maxmov - minmov)\n",
    "                np.clip(data, 0, 255, data)\n",
    "                data = data.astype(np.uint8)\n",
    "                \n",
    "            y, x = data[0].shape\n",
    "            vw = cv2.VideoWriter(file_name, codec, self.fr, (x, y), isColor=True)\n",
    "            for d in data:\n",
    "                vw.write(cv2.cvtColor(d, cv2.COLOR_GRAY2BGR))\n",
    "            vw.release()\n",
    "\n",
    "        elif extension == '.mat':\n",
    "            if self.file_name[0] is not None:\n",
    "                f_name = self.file_name\n",
    "            else:\n",
    "                f_name = ''\n",
    "\n",
    "            if to32 and not ('float32' in str(self.dtype)):\n",
    "                input_arr = self.astype(np.float32)\n",
    "            else:\n",
    "                input_arr = np.array(self)\n",
    "\n",
    "            if self.meta_data[0] is None:\n",
    "                savemat(\n",
    "                    file_name, {\n",
    "                        'input_arr': np.rollaxis(input_arr, axis=0, start=3),\n",
    "                        'start_time': self.start_time,\n",
    "                        'fr': self.fr,\n",
    "                        'meta_data': [],\n",
    "                        'file_name': f_name\n",
    "                    })\n",
    "            else:\n",
    "                savemat(\n",
    "                    file_name, {\n",
    "                        'input_arr': np.rollaxis(input_arr, axis=0, start=3),\n",
    "                        'start_time': self.start_time,\n",
    "                        'fr': self.fr,\n",
    "                        'meta_data': self.meta_data,\n",
    "                        'file_name': f_name\n",
    "                    })\n",
    "\n",
    "        elif extension in ('.hdf5', '.h5'):\n",
    "            with h5py.File(file_name, \"w\") as f:\n",
    "                if to32 and not ('float32' in str(self.dtype)):\n",
    "                    input_arr = self.astype(np.float32)\n",
    "                else:\n",
    "                    input_arr = np.array(self)\n",
    "\n",
    "                dset = f.create_dataset(var_name_hdf5, data=input_arr)\n",
    "                dset.attrs[\"fr\"] = self.fr\n",
    "                dset.attrs[\"start_time\"] = self.start_time\n",
    "                try:\n",
    "                    dset.attrs[\"file_name\"] = [a.encode('utf8') for a in self.file_name]\n",
    "                except:\n",
    "                    logging.warning('No file saved')\n",
    "                if self.meta_data[0] is not None:\n",
    "                    logging.debug(\"Metadata for saved file: \" + str(self.meta_data))\n",
    "                    dset.attrs[\"meta_data\"] = cpk.dumps(self.meta_data)\n",
    "        elif extension == '.mmap':\n",
    "            base_name = name\n",
    "\n",
    "            T = self.shape[0]\n",
    "            dims = self.shape[1:]\n",
    "            if to32 and not ('float32' in str(self.dtype)):\n",
    "                input_arr = self.astype(np.float32)\n",
    "            else:\n",
    "                input_arr = np.array(self)\n",
    "\n",
    "            input_arr = np.transpose(input_arr, list(range(1, len(dims) + 1)) + [0])\n",
    "            input_arr = np.reshape(input_arr, (np.prod(dims), T), order='F')\n",
    "\n",
    "            fname_tot = memmap_frames_filename(base_name, dims, T, order)\n",
    "            fname_tot = os.path.join(os.path.split(file_name)[0], fname_tot)\n",
    "            big_mov = np.memmap(fname_tot,\n",
    "                                mode='w+',\n",
    "                                dtype=np.float32,\n",
    "                                shape=(np.uint64(np.prod(dims)), np.uint64(T)),\n",
    "                                order=order)\n",
    "\n",
    "            big_mov[:] = np.asarray(input_arr, dtype=np.float32)\n",
    "            big_mov.flush()\n",
    "            del big_mov, input_arr\n",
    "            return fname_tot\n",
    "        elif extension == '.nwb':\n",
    "            if to32 and not ('float32' in str(self.dtype)):\n",
    "                input_arr = self.astype(np.float32)\n",
    "            else:\n",
    "                input_arr = np.array(self)\n",
    "            # Create NWB file\n",
    "            nwbfile = NWBFile(sess_desc,\n",
    "                              identifier,\n",
    "                              datetime.now(tzlocal()),\n",
    "                              experimenter=experimenter,\n",
    "                              lab=lab_name,\n",
    "                              institution=institution,\n",
    "                              experiment_description=experiment_description,\n",
    "                              session_id=session_id)\n",
    "            # Get the device\n",
    "            device = Device('imaging_device')\n",
    "            nwbfile.add_device(device)\n",
    "            # OpticalChannel\n",
    "            optical_channel = OpticalChannel('OpticalChannel', 'main optical channel', emission_lambda=emission_lambda)\n",
    "            imaging_plane = nwbfile.create_imaging_plane(name='ImagingPlane',\n",
    "                                                         optical_channel=optical_channel,\n",
    "                                                         description=imaging_plane_description,\n",
    "                                                         device=device,\n",
    "                                                         excitation_lambda=excitation_lambda,\n",
    "                                                         imaging_rate=self.fr,\n",
    "                                                         indicator=indicator,\n",
    "                                                         location=location)\n",
    "            # Images\n",
    "            image_series = TwoPhotonSeries(name=var_name_hdf5,\n",
    "                                           dimension=self.shape[1:],\n",
    "                                           data=input_arr,\n",
    "                                           imaging_plane=imaging_plane,\n",
    "                                           starting_frame=[0],\n",
    "                                           starting_time=starting_time,\n",
    "                                           rate=self.fr)\n",
    "\n",
    "            nwbfile.add_acquisition(image_series)\n",
    "\n",
    "            with NWBHDF5IO(file_name, 'w') as io:\n",
    "                io.write(nwbfile)\n",
    "\n",
    "            return file_name\n",
    "\n",
    "        else:\n",
    "            logging.error(\"Extension \" + str(extension) + \" unknown\")\n",
    "            raise Exception('Extension Unknown')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:514: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "<>:514: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "<ipython-input-5-c6ce1b9cd38d>:514: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "  if type(subindices).__module__ is 'numpy':\n"
     ]
    }
   ],
   "source": [
    "#https://github.com/flatironinstitute/CaImAn/blob/master/caiman/base/movies.py\n",
    "\n",
    "class movie(timeseries):\n",
    "    \"\"\"\n",
    "    Class representing a movie. This class subclasses timeseries,\n",
    "    that in turn subclasses ndarray\n",
    "    movie(input_arr, fr=None,start_time=0,file_name=None, meta_data=None)\n",
    "    Example of usage:\n",
    "        input_arr = 3d ndarray\n",
    "        fr=33; # 33 Hz\n",
    "        start_time=0\n",
    "        m=movie(input_arr, start_time=0,fr=33);\n",
    "    See https://docs.scipy.org/doc/numpy/user/basics.subclassing.html for\n",
    "    notes on objects that are descended from ndarray\n",
    "    \"\"\"\n",
    "\n",
    "    def __new__(cls, input_arr, **kwargs):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            input_arr:  np.ndarray, 3D, (time,height,width)\n",
    "            fr: frame rate\n",
    "            start_time: time beginning movie, if None it is assumed 0\n",
    "            meta_data: dictionary including any custom meta data\n",
    "            file_name: name associated with the file (e.g. path to the original file)\n",
    "        \"\"\"\n",
    "        if isinstance(input_arr, movie):\n",
    "            return input_arr\n",
    "\n",
    "        if (type(input_arr) is np.ndarray) or \\\n",
    "           (type(input_arr) is h5py._hl.dataset.Dataset) or \\\n",
    "           ('mmap' in str(type(input_arr))) or \\\n",
    "           ('tifffile' in str(type(input_arr))):\n",
    "            return super().__new__(cls, input_arr, **kwargs)  \n",
    "            #return super(movie, cls).__new__(cls, input_arr, **kwargs)\n",
    "        else:\n",
    "            raise Exception('Input must be an ndarray, use load instead!')\n",
    "\n",
    "    def apply_shifts_online(self, xy_shifts, save_base_name=None):\n",
    "        # This function is unused.\n",
    "        # todo: todocument\n",
    "\n",
    "        if save_base_name is None:\n",
    "            return movie(apply_shift_online(self, xy_shifts, save_base_name=save_base_name), fr=self.fr)\n",
    "        else:\n",
    "            return apply_shift_online(self, xy_shifts, save_base_name=save_base_name)\n",
    "\n",
    "    def calc_min(self) -> 'movie':\n",
    "        # todo: todocument\n",
    "\n",
    "        tmp = []\n",
    "        bins = np.linspace(0, self.shape[0], 10).round(0)\n",
    "        for i in range(9):\n",
    "            tmp.append(np.nanmin(self[np.int(bins[i]):np.int(bins[i + 1]), :, :]).tolist() + 1)\n",
    "        minval = np.ndarray(1)\n",
    "        minval[0] = np.nanmin(tmp)\n",
    "        return movie(input_arr=minval)\n",
    "\n",
    "    def motion_correct(self,\n",
    "                       max_shift_w=5,\n",
    "                       max_shift_h=5,\n",
    "                       num_frames_template=None,\n",
    "                       template=None,\n",
    "                       method: str = 'opencv',\n",
    "                       remove_blanks: bool = False,\n",
    "                       interpolation: str = 'cubic') -> Tuple[Any, Tuple, Any, Any]:\n",
    "        \"\"\"\n",
    "        Extract shifts and motion corrected movie automatically,\n",
    "        for more control consider the functions extract_shifts and apply_shifts\n",
    "        Disclaimer, it might change the object itself.\n",
    "        Args:\n",
    "            max_shift_w,max_shift_h: maximum pixel shifts allowed when correcting\n",
    "                                     in the width and height direction\n",
    "            template: if a good template for frame by frame correlation exists\n",
    "                      it can be passed. If None it is automatically computed\n",
    "            method: depends on what is installed 'opencv' or 'skimage'. 'skimage'\n",
    "                    is an order of magnitude slower\n",
    "            num_frames_template: if only a subset of the movies needs to be loaded\n",
    "                                 for efficiency/speed reasons\n",
    "        Returns:\n",
    "            self: motion corected movie, it might change the object itself\n",
    "            shifts : tuple, contains x & y shifts and correlation with template\n",
    "            xcorrs: cross correlation of the movies with the template\n",
    "            template: the computed template\n",
    "        \"\"\"\n",
    "\n",
    "        if template is None:   # if template is not provided it is created\n",
    "            if num_frames_template is None:\n",
    "                num_frames_template = old_div(10e7, (self.shape[1] * self.shape[2]))\n",
    "\n",
    "            frames_to_skip = int(np.maximum(1, old_div(self.shape[0], num_frames_template)))\n",
    "\n",
    "            # sometimes it is convenient to only consider a subset of the\n",
    "            # movie when computing the median\n",
    "            submov = self[::frames_to_skip, :].copy()\n",
    "            templ = submov.bin_median()                                        # create template with portion of movie\n",
    "            shifts, xcorrs = submov.extract_shifts(max_shift_w=max_shift_w,\n",
    "                                                   max_shift_h=max_shift_h,\n",
    "                                                   template=templ,\n",
    "                                                   method=method)\n",
    "            submov.apply_shifts(shifts, interpolation=interpolation, method=method)\n",
    "            template = submov.bin_median()\n",
    "            del submov\n",
    "            m = self.copy()\n",
    "            shifts, xcorrs = m.extract_shifts(max_shift_w=max_shift_w,\n",
    "                                              max_shift_h=max_shift_h,\n",
    "                                              template=template,\n",
    "                                              method=method)\n",
    "            m = m.apply_shifts(shifts, interpolation=interpolation, method=method)\n",
    "            template = (m.bin_median())\n",
    "            del m\n",
    "        else:\n",
    "            template = template - np.percentile(template, 8)\n",
    "\n",
    "        # now use the good template to correct\n",
    "        shifts, xcorrs = self.extract_shifts(max_shift_w=max_shift_w,\n",
    "                                             max_shift_h=max_shift_h,\n",
    "                                             template=template,\n",
    "                                             method=method)\n",
    "        self = self.apply_shifts(shifts, interpolation=interpolation, method=method)\n",
    "\n",
    "        if remove_blanks:\n",
    "            max_h, max_w = np.max(shifts, axis=0)\n",
    "            min_h, min_w = np.min(shifts, axis=0)\n",
    "            self.crop(crop_top=max_h,\n",
    "                      crop_bottom=-min_h + 1,\n",
    "                      crop_left=max_w,\n",
    "                      crop_right=-min_w,\n",
    "                      crop_begin=0,\n",
    "                      crop_end=0)\n",
    "\n",
    "        return self, shifts, xcorrs, template\n",
    "\n",
    "    def motion_correct_3d(self,\n",
    "                          max_shift_z=5,\n",
    "                          max_shift_w=5,\n",
    "                          max_shift_h=5,\n",
    "                          num_frames_template=None,\n",
    "                          template=None,\n",
    "                          method='opencv',\n",
    "                          remove_blanks=False,\n",
    "                          interpolation='cubic'):\n",
    "        \"\"\"\n",
    "        Extract shifts and motion corrected movie automatically,\n",
    "        for more control consider the functions extract_shifts and apply_shifts\n",
    "        Disclaimer, it might change the object itself.\n",
    "        Args:\n",
    "            max_shift,z,max_shift_w,max_shift_h: maximum pixel shifts allowed when \n",
    "                    correcting in the axial, width, and height directions\n",
    "            template: if a good template for frame by frame correlation exists\n",
    "                      it can be passed. If None it is automatically computed\n",
    "            method: depends on what is installed 'opencv' or 'skimage'. 'skimage'\n",
    "                    is an order of magnitude slower\n",
    "            num_frames_template: if only a subset of the movies needs to be loaded\n",
    "                                 for efficiency/speed reasons\n",
    "        Returns:\n",
    "            self: motion corected movie, it might change the object itself\n",
    "            shifts : tuple, contains x, y, and z shifts and correlation with template\n",
    "            xcorrs: cross correlation of the movies with the template\n",
    "            template: the computed template\n",
    "        \"\"\"\n",
    "\n",
    "        if template is None:   # if template is not provided it is created\n",
    "            if num_frames_template is None:\n",
    "                num_frames_template = old_div(10e7, (self.shape[1] * self.shape[2]))\n",
    "\n",
    "            frames_to_skip = int(np.maximum(1, old_div(self.shape[0], num_frames_template)))\n",
    "\n",
    "            # sometimes it is convenient to only consider a subset of the\n",
    "            # movie when computing the median\n",
    "            submov = self[::frames_to_skip, :].copy()\n",
    "            templ = submov.bin_median_3d()                                     # create template with portion of movie\n",
    "            shifts, xcorrs = submov.extract_shifts_3d(\n",
    "                max_shift_z=max_shift_z,                                       # NOTE: extract_shifts_3d has not been implemented yet - use skimage\n",
    "                max_shift_w=max_shift_w,\n",
    "                max_shift_h=max_shift_h,\n",
    "                template=templ,\n",
    "                method=method)\n",
    "            submov.apply_shifts_3d(                                            # NOTE: apply_shifts_3d has not been implemented yet\n",
    "                shifts, interpolation=interpolation, method=method)\n",
    "            template = submov.bin_median_3d()\n",
    "            del submov\n",
    "            m = self.copy()\n",
    "            shifts, xcorrs = m.extract_shifts_3d(max_shift_z=max_shift_z,\n",
    "                                                 max_shift_w=max_shift_w,\n",
    "                                                 max_shift_h=max_shift_h,\n",
    "                                                 template=template,\n",
    "                                                 method=method)\n",
    "            m = m.apply_shifts_3d(shifts, interpolation=interpolation, method=method)\n",
    "            template = (m.bin_median_3d())\n",
    "            del m\n",
    "        else:\n",
    "            template = template - np.percentile(template, 8)\n",
    "\n",
    "        # now use the good template to correct\n",
    "        shifts, xcorrs = self.extract_shifts_3d(max_shift_z=max_shift_z,\n",
    "                                                max_shift_w=max_shift_w,\n",
    "                                                max_shift_h=max_shift_h,\n",
    "                                                template=template,\n",
    "                                                method=method)\n",
    "        self = self.apply_shifts_3d(shifts, interpolation=interpolation, method=method)\n",
    "\n",
    "        if remove_blanks:\n",
    "            max_z, max_h, max_w = np.max(shifts, axis=0)\n",
    "            min_z, min_h, min_w = np.min(shifts, axis=0)\n",
    "            self.crop(\n",
    "                crop_top=max_z,\n",
    "                crop_bottom=min_z,             # NOTE: edge boundaries for z dimension need to be tested\n",
    "                crop_left=max_h,\n",
    "                crop_right=-min_h + 1,\n",
    "                crop_begin=max_w,\n",
    "                crop_end=-min_w)\n",
    "\n",
    "        return self, shifts, xcorrs, template\n",
    "    \n",
    "    def bin_median(self, window: int = 10) -> np.ndarray:\n",
    "        \"\"\" compute median of 3D array in along axis o by binning values\n",
    "        Args:\n",
    "            mat: ndarray\n",
    "                input 3D matrix, time along first dimension\n",
    "            window: int\n",
    "                number of frames in a bin\n",
    "        Returns:\n",
    "            img:\n",
    "                median image\n",
    "        \"\"\"\n",
    "        T, d1, d2 = np.shape(self)\n",
    "        num_windows = np.int(old_div(T, window))\n",
    "        num_frames = num_windows * window\n",
    "        return np.nanmedian(np.nanmean(np.reshape(self[:num_frames], (window, num_windows, d1, d2)), axis=0), axis=0)\n",
    "\n",
    "def load(file_name: Union[str, List[str]],\n",
    "         fr: float = 30,\n",
    "         start_time: float = 0,\n",
    "         meta_data: Dict = None,\n",
    "         subindices=None,\n",
    "         shape: Tuple[int, int] = None,\n",
    "         var_name_hdf5: str = 'mov',\n",
    "         in_memory: bool = False,\n",
    "         is_behavior: bool = False,\n",
    "         bottom=0,\n",
    "         top=0,\n",
    "         left=0,\n",
    "         right=0,\n",
    "         channel=None,\n",
    "         outtype=np.float32,\n",
    "         is3D: bool = False) -> Any:\n",
    "    \"\"\"\n",
    "    load movie from file. Supports a variety of formats. tif, hdf5, npy and memory mapped. Matlab is experimental.\n",
    "    Args:\n",
    "        file_name: string or List[str]\n",
    "            name of file. Possible extensions are tif, avi, npy, (npz and hdf5 are usable only if saved by calblitz)\n",
    "        fr: float\n",
    "            frame rate\n",
    "        start_time: float\n",
    "            initial time for frame 1\n",
    "        meta_data: dict\n",
    "            dictionary containing meta information about the movie\n",
    "        subindices: iterable indexes\n",
    "            for loading only portion of the movie\n",
    "        shape: tuple of two values\n",
    "            dimension of the movie along x and y if loading from a two dimensional numpy array\n",
    "        var_name_hdf5: str\n",
    "            if loading from hdf5 name of the variable to load\n",
    "        in_memory: (undocumented)\n",
    "        is_behavior: (undocumented)\n",
    "        bottom,top,left,right: (undocumented)\n",
    "        channel: (undocumented)\n",
    "        outtype: The data type for the movie\n",
    "    Returns:\n",
    "        mov: caiman.movie\n",
    "    Raises:\n",
    "        Exception 'Subindices not implemented'\n",
    "    \n",
    "        Exception 'Subindices not implemented'\n",
    "    \n",
    "        Exception 'sima module unavailable'\n",
    "    \n",
    "        Exception 'Unknown file type'\n",
    "    \n",
    "        Exception 'File not found!'\n",
    "    \"\"\"\n",
    "    # case we load movie from file\n",
    "    if max(top, bottom, left, right) > 0 and type(file_name) is str:\n",
    "        file_name = [file_name]        # type: ignore # mypy doesn't like that this changes type\n",
    "\n",
    "    if type(file_name) is list:\n",
    "        if shape is not None:\n",
    "            logging.error('shape not supported for multiple movie input')\n",
    "\n",
    "        return load_movie_chain(file_name,\n",
    "                                fr=fr,\n",
    "                                start_time=start_time,\n",
    "                                meta_data=meta_data,\n",
    "                                subindices=subindices,\n",
    "                                bottom=bottom,\n",
    "                                top=top,\n",
    "                                left=left,\n",
    "                                right=right,\n",
    "                                channel=channel,\n",
    "                                outtype=outtype,\n",
    "                                var_name_hdf5=var_name_hdf5,\n",
    "                                is3D=is3D)\n",
    "\n",
    "    elif isinstance(file_name,tuple):\n",
    "        print('**** PROCESSING AS SINGLE FRAMES *****')\n",
    "        if shape is not None:\n",
    "            logging.error('shape not supported for multiple movie input')\n",
    "        else:\n",
    "            return load_movie_chain(tuple([iidd for iidd in np.array(file_name)[subindices]]),\n",
    "                     fr=fr, start_time=start_time,\n",
    "                     meta_data=meta_data, subindices=None,\n",
    "                     bottom=bottom, top=top, left=left, right=right,\n",
    "                     channel = channel, outtype=outtype)\n",
    "\n",
    "    if max(top, bottom, left, right) > 0:\n",
    "        logging.error('top bottom etc... not supported for single movie input')\n",
    "\n",
    "    if channel is not None:\n",
    "        logging.error('channel not supported for single movie input')\n",
    "\n",
    "    if os.path.exists(file_name):\n",
    "        _, extension = os.path.splitext(file_name)[:2]\n",
    "\n",
    "        extension = extension.lower()\n",
    "        if extension == '.mat':\n",
    "            logging.warning('Loading a *.mat file. x- and y- dimensions ' +\n",
    "                            'might have been swapped.')\n",
    "            byte_stream, file_opened = scipy.io.matlab.mio._open_file(file_name, appendmat=False)\n",
    "            mjv, mnv = scipy.io.matlab.mio.get_matfile_version(byte_stream)\n",
    "            if mjv == 2:\n",
    "                extension = '.h5'\n",
    "\n",
    "        if extension in ['.tif', '.tiff', '.btf']:  # load tif file\n",
    "            with tifffile.TiffFile(file_name) as tffl:\n",
    "                multi_page = True if tffl.series[0].shape[0] > 1 else False\n",
    "                if len(tffl.pages) == 1:\n",
    "                    logging.warning('Your tif file is saved a single page' +\n",
    "                                    'file. Performance will be affected')\n",
    "                    multi_page = False\n",
    "                if subindices is not None:\n",
    "                    # if isinstance(subindices, (list, tuple)): # is list or tuple:\n",
    "                    if isinstance(subindices, list):  # is list or tuple:\n",
    "                        if multi_page:\n",
    "                            if len(tffl.series[0].shape) < 4:\n",
    "                                input_arr = tffl.asarray(key=subindices[0])[:, subindices[1], subindices[2]]\n",
    "                            else:  # 3D\n",
    "                                shape = tffl.series[0].shape\n",
    "                                ts = np.arange(shape[0])[subindices[0]]\n",
    "                                input_arr = tffl.asarray(key=np.ravel(ts[:, None] * shape[1] +\n",
    "                                                                      np.arange(shape[1]))\n",
    "                                                         ).reshape((len(ts),) + shape[1:])[\n",
    "                                    :, subindices[1], subindices[2], subindices[3]]\n",
    "                        else:\n",
    "                            input_arr = tffl.asarray()[tuple(subindices)]\n",
    "\n",
    "                    else:\n",
    "                        if multi_page:\n",
    "                            if len(tffl.series[0].shape) < 4:\n",
    "                                input_arr = tffl.asarray(key=subindices)\n",
    "                            else:  # 3D\n",
    "                                shape = tffl.series[0].shape\n",
    "                                ts = np.arange(shape[0])[subindices]\n",
    "                                input_arr = tffl.asarray(key=np.ravel(ts[:, None] * shape[1] +\n",
    "                                                                      np.arange(shape[1]))\n",
    "                                                         ).reshape((len(ts),) + shape[1:])\n",
    "                        else:\n",
    "                            input_arr = tffl.asarray()\n",
    "                            input_arr = input_arr[subindices]\n",
    "\n",
    "                else:\n",
    "                    input_arr = tffl.asarray()\n",
    "\n",
    "                input_arr = np.squeeze(input_arr)\n",
    "\n",
    "        elif extension in ('.avi', '.mkv'):      # load video file\n",
    "            cap = cv2.VideoCapture(file_name)\n",
    "\n",
    "            try:\n",
    "                length = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "                width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "                height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "            except:\n",
    "                logging.info('Roll back to opencv 2')\n",
    "                length = int(cap.get(cv2.cv.CV_CAP_PROP_FRAME_COUNT))\n",
    "                width = int(cap.get(cv2.cv.CV_CAP_PROP_FRAME_WIDTH))\n",
    "                height = int(cap.get(cv2.cv.CV_CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "            cv_failed = False\n",
    "            dims = [length, height, width]                     # type: ignore # a list in one block and a tuple in another\n",
    "            if length == 0 or width == 0 or height == 0:       #CV failed to load\n",
    "                cv_failed = True\n",
    "            if subindices is not None:\n",
    "                if type(subindices) is not list:\n",
    "                    subindices = [subindices]\n",
    "                for ind, sb in enumerate(subindices):\n",
    "                    if type(sb) is range:\n",
    "                        subindices[ind] = np.r_[sb]\n",
    "                        dims[ind] = subindices[ind].shape[0]\n",
    "                    elif type(sb) is slice:\n",
    "                        if sb.start is None:\n",
    "                            sb = slice(0, sb.stop, sb.step)\n",
    "                        if sb.stop is None:\n",
    "                            sb = slice(sb.start, dims[ind], sb.step)\n",
    "                        subindices[ind] = np.r_[sb]\n",
    "                        dims[ind] = subindices[ind].shape[0]\n",
    "                    elif type(sb) is np.ndarray:\n",
    "                        dims[ind] = sb.shape[0]\n",
    "\n",
    "                start_frame = subindices[0][0]\n",
    "            else:\n",
    "                subindices = [np.r_[range(dims[0])]]\n",
    "                start_frame = 0\n",
    "            if not cv_failed:\n",
    "                input_arr = np.zeros((dims[0], height, width), dtype=np.uint8)\n",
    "                counter = 0\n",
    "                cap.set(1, start_frame)\n",
    "                current_frame = start_frame\n",
    "                while True and counter < dims[0]:\n",
    "                    # Capture frame-by-frame\n",
    "                    if current_frame != subindices[0][counter]:\n",
    "                        current_frame = subindices[0][counter]\n",
    "                        cap.set(1, current_frame)\n",
    "                    ret, frame = cap.read()\n",
    "                    if not ret:\n",
    "                        break\n",
    "                    input_arr[counter] = frame[:, :, 0]\n",
    "                    counter += 1\n",
    "                    current_frame += 1\n",
    "\n",
    "                if len(subindices) > 1:\n",
    "                    input_arr = input_arr[:, subindices[1]]\n",
    "                if len(subindices) > 2:\n",
    "                    input_arr = input_arr[:, :, subindices[2]]\n",
    "            else:      #use pims to load movie\n",
    "                import pims\n",
    "\n",
    "                def rgb2gray(rgb):\n",
    "                    return np.dot(rgb[..., :3], [0.299, 0.587, 0.114])\n",
    "\n",
    "                pims_movie = pims.Video(file_name)\n",
    "                length = len(pims_movie)\n",
    "                height, width = pims_movie.frame_shape[0:2]    #shape is (h,w,channels)\n",
    "                input_arr = np.zeros((length, height, width), dtype=np.uint8)\n",
    "                for i in range(len(pims_movie)):               #iterate over frames\n",
    "                    input_arr[i] = rgb2gray(pims_movie[i])\n",
    "\n",
    "            # When everything done, release the capture\n",
    "            cap.release()\n",
    "            cv2.destroyAllWindows()\n",
    "\n",
    "        elif extension == '.npy':      # load npy file\n",
    "            if fr is None:\n",
    "                fr = 30\n",
    "            if in_memory:\n",
    "                input_arr = np.load(file_name)\n",
    "            else:\n",
    "                input_arr = np.load(file_name, mmap_mode='r')\n",
    "\n",
    "            if subindices is not None:\n",
    "                input_arr = input_arr[subindices]\n",
    "\n",
    "            if input_arr.ndim == 2:\n",
    "                if shape is not None:\n",
    "                    _, T = np.shape(input_arr)\n",
    "                    d1, d2 = shape\n",
    "                    input_arr = np.transpose(np.reshape(input_arr, (d1, d2, T), order='F'), (2, 0, 1))\n",
    "                else:\n",
    "                    input_arr = input_arr[np.newaxis, :, :]\n",
    "\n",
    "        elif extension == '.mat':      # load npy file\n",
    "            input_arr = loadmat(file_name)['data']\n",
    "            input_arr = np.rollaxis(input_arr, 2, -3)\n",
    "            if subindices is not None:\n",
    "                input_arr = input_arr[subindices]\n",
    "\n",
    "        elif extension == '.npz':      # load movie from saved file\n",
    "            if subindices is not None:\n",
    "                raise Exception('Subindices not implemented')\n",
    "            with np.load(file_name) as f:\n",
    "                return movie(**f).astype(outtype)\n",
    "\n",
    "        elif extension in ('.hdf5', '.h5', '.nwb'):\n",
    "            if is_behavior:\n",
    "                with h5py.File(file_name, \"r\") as f:\n",
    "                    kk = list(f.keys())\n",
    "                    kk.sort(key=lambda x: np.int(x.split('_')[-1]))\n",
    "                    input_arr = []\n",
    "                    for trial in kk:\n",
    "                        logging.info('Loading ' + trial)\n",
    "                        input_arr.append(np.array(f[trial]['mov']))\n",
    "\n",
    "                    input_arr = np.vstack(input_arr)\n",
    "\n",
    "            else:\n",
    "                with h5py.File(file_name, \"r\") as f:\n",
    "                    fkeys = list(f.keys())\n",
    "                    if len(fkeys) == 1:\n",
    "                        var_name_hdf5 = fkeys[0]\n",
    "\n",
    "                    if extension == '.nwb':\n",
    "                        try:\n",
    "                            fgroup = f[var_name_hdf5]['data']\n",
    "                        except:\n",
    "                            fgroup = f['acquisition'][var_name_hdf5]['data']\n",
    "                    else:\n",
    "                        fgroup = f[var_name_hdf5]\n",
    "\n",
    "                    if var_name_hdf5 in f or var_name_hdf5 in f['acquisition']:\n",
    "                        if subindices is None:\n",
    "                            images = np.array(fgroup).squeeze()\n",
    "                            #if images.ndim > 3:\n",
    "                            #    images = images[:, 0]\n",
    "                        else:\n",
    "                            if type(subindices).__module__ is 'numpy':\n",
    "                                subindices = subindices.tolist()\n",
    "                            if len(fgroup.shape) > 3:\n",
    "                                images = np.array(fgroup[subindices]).squeeze()\n",
    "                            else:\n",
    "                                images = np.array(fgroup[subindices]).squeeze()\n",
    "\n",
    "                        #input_arr = images\n",
    "                        return movie(images.astype(outtype))\n",
    "                    else:\n",
    "                        logging.debug('KEYS:' + str(f.keys()))\n",
    "                        raise Exception('Key not found in hdf5 file')\n",
    "\n",
    "        elif extension == '.mmap':\n",
    "\n",
    "            filename = os.path.split(file_name)[-1]\n",
    "            Yr, dims, T = load_memmap(\n",
    "                os.path.join(                  # type: ignore # same dims typing issue as above\n",
    "                    os.path.split(file_name)[0], filename))\n",
    "            images = np.reshape(Yr.T, [T] + list(dims), order='F')\n",
    "            if subindices is not None:\n",
    "                images = images[subindices]\n",
    "\n",
    "            if in_memory:\n",
    "                logging.debug('loading mmap file in memory')\n",
    "                images = np.array(images).astype(outtype)\n",
    "\n",
    "            logging.debug('mmap')\n",
    "            return movie(images, fr=fr)\n",
    "\n",
    "        elif extension == '.sbx':\n",
    "            logging.debug('sbx')\n",
    "            if subindices is not None:\n",
    "                return movie(sbxreadskip(file_name[:-4], subindices), fr=fr).astype(outtype)\n",
    "            else:\n",
    "                return movie(sbxread(file_name[:-4], k=0, n_frames=np.inf), fr=fr).astype(outtype)\n",
    "\n",
    "        elif extension == '.sima':\n",
    "            if not HAS_SIMA:\n",
    "                raise Exception(\"sima module unavailable\")\n",
    "\n",
    "            dataset = sima.ImagingDataset.load(file_name)\n",
    "            frame_step = 1000\n",
    "            if subindices is None:\n",
    "                input_arr = np.empty(\n",
    "                    (dataset.sequences[0].shape[0], dataset.sequences[0].shape[2], dataset.sequences[0].shape[3]),\n",
    "                    dtype=outtype)\n",
    "                for nframe in range(0, dataset.sequences[0].shape[0], frame_step):\n",
    "                    input_arr[nframe:nframe + frame_step] = np.array(\n",
    "                        dataset.sequences[0][nframe:nframe + frame_step, 0, :, :, 0]).astype(outtype).squeeze()\n",
    "            else:\n",
    "                input_arr = np.array(dataset.sequences[0])[subindices, :, :, :, :].squeeze()\n",
    "\n",
    "        else:\n",
    "            raise Exception('Unknown file type')\n",
    "    else:\n",
    "        logging.error(f\"File request:[{file_name}] not found!\")\n",
    "        raise Exception('File not found!')\n",
    "\n",
    "    return movie(input_arr.astype(outtype),\n",
    "                 fr=fr,\n",
    "                 start_time=start_time,\n",
    "                 file_name=os.path.split(file_name)[-1],\n",
    "                 meta_data=meta_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_file_size(file_name, var_name_hdf5='mov'):\n",
    "    \"\"\" Computes the dimensions of a file or a list of files without loading\n",
    "    it/them in memory. An exception is thrown if the files have FOVs with\n",
    "    different sizes\n",
    "        Args:\n",
    "            file_name: str/filePath or various list types\n",
    "                locations of file(s)\n",
    "            var_name_hdf5: 'str'\n",
    "                if loading from hdf5 name of the dataset to load\n",
    "        Returns:\n",
    "            dims: list\n",
    "                dimensions of FOV\n",
    "            T: list\n",
    "                number of timesteps in each file\n",
    "    \"\"\"\n",
    "    if isinstance(file_name, pathlib.Path):\n",
    "        # We want to support these as input, but str has a broader set of operations that we'd like to use, so let's just convert.\n",
    "\t# (specifically, filePath types don't support subscripting)\n",
    "        file_name = str(file_name)\n",
    "    if isinstance(file_name, str):\n",
    "        if os.path.exists(file_name):\n",
    "            _, extension = os.path.splitext(file_name)[:2]\n",
    "            extension = extension.lower()\n",
    "            if extension == '.mat':\n",
    "                byte_stream, file_opened = scipy.io.matlab.mio._open_file(file_name, appendmat=False)\n",
    "                mjv, mnv = scipy.io.matlab.mio.get_matfile_version(byte_stream)\n",
    "                if mjv == 2:\n",
    "                    extension = '.h5'\n",
    "            if extension in ['.tif', '.tiff', '.btf']:\n",
    "                tffl = tifffile.TiffFile(file_name)\n",
    "                siz = tffl.series[0].shape\n",
    "                T, dims = siz[0], siz[1:]\n",
    "            elif extension in ('.avi', '.mkv'):\n",
    "                cap = cv2.VideoCapture(file_name)\n",
    "                dims = [0, 0]\n",
    "                try:\n",
    "                    T = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "                    dims[1] = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "                    dims[0] = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "                except():\n",
    "                    print('Roll back to opencv 2')\n",
    "                    T = int(cap.get(cv2.cv.CV_CAP_PROP_FRAME_COUNT))\n",
    "                    dims[1] = int(cap.get(cv2.cv.CV_CAP_PROP_FRAME_WIDTH))\n",
    "                    dims[0] = int(cap.get(cv2.cv.CV_CAP_PROP_FRAME_HEIGHT))\n",
    "            elif extension == '.mmap':\n",
    "                filename = os.path.split(file_name)[-1]\n",
    "                Yr, dims, T = load_memmap(os.path.join(\n",
    "                        os.path.split(file_name)[0], filename))\n",
    "            elif extension in ('.h5', '.hdf5', '.nwb'):\n",
    "                with h5py.File(file_name, \"r\") as f:\n",
    "                    kk = list(f.keys())\n",
    "                    if len(kk) == 1:\n",
    "                        siz = f[kk[0]].shape\n",
    "                    elif var_name_hdf5 in f:\n",
    "                        if extension == '.nwb':\n",
    "                            siz = f[var_name_hdf5]['data'].shape\n",
    "                        else:\n",
    "                            siz = f[var_name_hdf5].shape\n",
    "                    elif var_name_hdf5 in f['acquisition']:\n",
    "                        siz = f['acquisition'][var_name_hdf5]['data'].shape\n",
    "                    else:\n",
    "                        logging.error('The file does not contain a variable' +\n",
    "                                      'named {0}'.format(var_name_hdf5))\n",
    "                        raise Exception('Variable not found. Use one of the above')\n",
    "                T, dims = siz[0], siz[1:]\n",
    "            elif extension in ('.sbx'):\n",
    "                from ...base.movies import loadmat_sbx\n",
    "                info = loadmat_sbx(file_name[:-4]+ '.mat')['info']\n",
    "                dims = tuple((info['sz']).astype(int))\n",
    "                # Defining number of channels/size factor\n",
    "                if info['channels'] == 1:\n",
    "                    info['nChan'] = 2\n",
    "                    factor = 1\n",
    "                elif info['channels'] == 2:\n",
    "                    info['nChan'] = 1\n",
    "                    factor = 2\n",
    "                elif info['channels'] == 3:\n",
    "                    info['nChan'] = 1\n",
    "                    factor = 2\n",
    "            \n",
    "                # Determine number of frames in whole file\n",
    "                T = int(os.path.getsize(\n",
    "                    file_name[:-4] + '.sbx') / info['recordsPerBuffer'] / info['sz'][1] * factor / 4 - 1)\n",
    "                \n",
    "            else:\n",
    "                raise Exception('Unknown file type')\n",
    "            dims = tuple(dims)\n",
    "        else:\n",
    "            raise Exception('File not found!')\n",
    "    elif isinstance(file_name, tuple):\n",
    "        from ...base.movies import load\n",
    "        dims = load(file_name[0], var_name_hdf5=var_name_hdf5).shape\n",
    "        T = len(file_name)\n",
    "\n",
    "    elif isinstance(file_name, list):\n",
    "        if len(file_name) == 1:\n",
    "            dims, T = get_file_size(file_name[0], var_name_hdf5=var_name_hdf5)\n",
    "        else:\n",
    "            dims, T = zip(*[get_file_size(fn, var_name_hdf5=var_name_hdf5)\n",
    "                for fn in file_name])\n",
    "    else:\n",
    "        raise Exception('Unknown input type')\n",
    "    return dims, T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BOOM extension: .h5\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-f74df23759c8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     18\u001b[0m                   border_nan=border_nan)\n\u001b[0;32m     19\u001b[0m \u001b[0mstart\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m \u001b[0mmc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmotion_correct\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msave_movie\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m \u001b[0mend\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'time to motion correct: '\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mend\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-2-7a1a388b5be8>\u001b[0m in \u001b[0;36mmotion_correct\u001b[1;34m(self, template, save_movie)\u001b[0m\n\u001b[0;32m    233\u001b[0m                                     np.max(np.abs(self.y_shifts_els))))\n\u001b[0;32m    234\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 235\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmotion_correct_rigid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtemplate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtemplate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msave_movie\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msave_movie\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    236\u001b[0m             \u001b[0mb0\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mceil\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshifts_rig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    237\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mborder_to_0\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mb0\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-2-7a1a388b5be8>\u001b[0m in \u001b[0;36mmotion_correct_rigid\u001b[1;34m(self, template, save_movie)\u001b[0m\n\u001b[0;32m    267\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    268\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mfname_cur\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfname\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 269\u001b[1;33m             _fname_tot_rig, _total_template_rig, _templates_rig, _shifts_rig = motion_correct_batch_rigid(\n\u001b[0m\u001b[0;32m    270\u001b[0m                 \u001b[0mfname_cur\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    271\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax_shifts\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-2-7a1a388b5be8>\u001b[0m in \u001b[0;36mmotion_correct_batch_rigid\u001b[1;34m(fname, max_shifts, dview, splits, num_splits_to_process, num_iter, template, shifts_opencv, save_movie_rigid, add_to_movie, nonneg_movie, gSig_filt, subidx, use_cuda, border_nan, var_name_hdf5, is3D, indices)\u001b[0m\n\u001b[0;32m   2760\u001b[0m                 \u001b[0mm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2761\u001b[0m             template = bin_median(\n\u001b[1;32m-> 2762\u001b[1;33m                     m.motion_correct(max_shifts[1], max_shifts[0], template=None)[0])\n\u001b[0m\u001b[0;32m   2763\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2764\u001b[0m     \u001b[0mnew_templ\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtemplate\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-5-c6ce1b9cd38d>\u001b[0m in \u001b[0;36mmotion_correct\u001b[1;34m(self, max_shift_w, max_shift_h, num_frames_template, template, method, remove_blanks, interpolation)\u001b[0m\n\u001b[0;32m     93\u001b[0m             \u001b[1;31m# movie when computing the median\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     94\u001b[0m             \u001b[0msubmov\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mframes_to_skip\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 95\u001b[1;33m             \u001b[0mtempl\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msubmov\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbin_median\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m                                        \u001b[1;31m# create template with portion of movie\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     96\u001b[0m             shifts, xcorrs = submov.extract_shifts(max_shift_w=max_shift_w,\n\u001b[0;32m     97\u001b[0m                                                    \u001b[0mmax_shift_h\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_shift_h\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-5-c6ce1b9cd38d>\u001b[0m in \u001b[0;36mbin_median\u001b[1;34m(self, window)\u001b[0m\n\u001b[0;32m    224\u001b[0m                 \u001b[0mmedian\u001b[0m \u001b[0mimage\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    225\u001b[0m         \"\"\"\n\u001b[1;32m--> 226\u001b[1;33m         \u001b[0mT\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0md1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0md2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    227\u001b[0m         \u001b[0mnum_windows\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mold_div\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwindow\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    228\u001b[0m         \u001b[0mnum_frames\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnum_windows\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mwindow\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: too many values to unpack (expected 3)"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "max_shifts = (6, 6)  # maximum allowed rigid shift in pixels (view the movie to get a sense of motion)\n",
    "strides =  (48, 48)  # create a new patch every x pixels for pw-rigid correction\n",
    "overlaps = (24, 24)  # overlap between pathes (size of patch strides+overlaps)\n",
    "num_frames_split = 100  # length in frames of each chunk of the movie (to be processed in parallel)\n",
    "max_deviation_rigid = 3   # maximum deviation allowed for patch with respect to rigid shifts\n",
    "pw_rigid = True  # flag for performing rigid or piecewise rigid motion correction\n",
    "shifts_opencv = True  # flag for correcting motion using bicubic interpolation (otherwise FFT interpolation is used)\n",
    "border_nan = 'copy'  # replicate values along the boundary (if True, fill in with NaN)\n",
    "\n",
    "fname='//ZMN-HIVE/User-Data/Maria/check_registration/control/fish17_6dpf_medium_aligned.h5'\n",
    "\n",
    "mc = MotionCorrect(fname,max_shifts=max_shifts,\n",
    "                  strides=strides, overlaps=overlaps,\n",
    "                  max_deviation_rigid=max_deviation_rigid, \n",
    "                  shifts_opencv=shifts_opencv, nonneg_movie=True,\n",
    "                  border_nan=border_nan)\n",
    "start=time.time()\n",
    "mc.motion_correct(save_movie=True)\n",
    "end=time.time()\n",
    "print('time to motion correct: ', end-start)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
